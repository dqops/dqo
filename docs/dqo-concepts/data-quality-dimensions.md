---
title: How to measure data quality dimensions - list of data quality checks
---

# How to measure data quality dimensions - list of data quality checks
This guide provides the definition of data quality dimensions. Read this guide to learn the mapping of data quality checks to data quality dimensions. 

## What is a data quality dimension?

Data quality dimension is a term adopted by the data quality field to identify these aspects of data that can be measured 
and through which its quality can be quantified. While different experts have proposed different data quality dimensions
and there is no standardization of their names or descriptions, almost all of them include some version of accuracy, completeness, 
consistency, timeliness, uniqueness, and validity.

DQOps additionally uses Integrity, Availability, and Reasonableness data quality dimensions
because they identify issues that affect unstructured data in data lakes.

### Data quality dimension types
The following table explains data quality dimensions supported by DQOps, showing both the definition of the dimension, 
and examples of typical data quality issues.

| Data quality dimension name                | Data quality dimension definition                                                                                                                                                                                                                                                                            | Potential data quality issues                                                                                                                                                                                            |
|:-------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [**Accuracy**](#data-accuracy)             | The degree of closeness of data values to real values, often measured by comparison with a known source of correct information (the source of truth).                                                                                                                                                        | The data in a downstream data source does not match the original data from an upstream data source. <br/>Aggregated values computed in values do not match similar values from a different data source (financial data). |
| [**Availability**](#data-availability)     | The degree to which the data source is available for usage with no access issues.                                                                                                                                                                                                                            | The table is missing.<br/>Credentials to the data source expired. <br/> Table is physically corrupted due to an unrecoverable hard disk failure.                                                                         |
| [**Completeness**](#data-completeness)     | The degree to which all required<br/>- records in the dataset,<br/>- data values<br/>are present with no missing information.                                                                                                                                                                                | Required columns are empty. <br/> Tables are empty or too small. <br/> The percentage of null values exceeds an accepted threshold.                                                                                      |
| [**Consistency**](#data-consistency)       | The degree to which data values of two sets of attributes<br/>- within a record,<br/>- within a data file,<br/>- between data files,<br/>- within a record at different points in time<br/>comply with a rule.<br/>This dimension confirms that the quality of values is consistent across the time periods. | An abnormal value outside regular boundaries is found using anomaly detection. <br/>The aggregated value (sum, min, max, avg) for one time period differs too much from an earlier period (yesterday, last month, etc.). |
| [**Integrity**](#data-integrity)           | The degree to which relational data is structurally correct.                                                                                                                                                                                                                                                 | Lookup by a foreign key value did not find a matching record in a dimension or dictionary table.                                                                                                                         |
| [**Reasonableness**](#data-reasonableness) | The degree to which data values have are reasonable and make sense.                                                                                                                                                                                                                                          | A sum of values in an aggregable column is within an accepted range. For example, the total revenue per day is within reasonable boundaries.                                                                             |
| [**Timeliness**](#data-timeliness)         | The degree to which the period between the time of creation of the real value and the time that the dataset is available is appropriate (the data is fresh).                                                                                                                                                 | The data is not up-to-date. The most recent record is not older than an accepted delay.                                                                                                                                  |
| [**Uniqueness**](#data-uniqueness)         | The degree to which records occur only once in a data set and are not duplicated.                                                                                                                                                                                                                            | Duplicate values found in a key column that must contain only unique values.                                                                                                                                             |
| [**Validity**](#data-validity)             | The degree to which data values comply with pre-defined business rules such as the format, patterns, type, and range. E.g. zip codes. e-mails                                                                                                                                                                | Invalid phone format. Values not matching regular expression patterns.                                                                                                                                                   |

The list of data quality checks for each data quality dimension is found in sections below.

### How data quality dimensions are measured
DQOps measures data quality by calculating a [data quality KPI score](definition-of-data-quality-kpis.md).
It is as a percentage of passed [data quality checks](definition-of-data-quality-checks/index.md) out of all executed checks.
The data quality KPI is represented as a percentage value. The following formula calculates the score.

![Data quality KPI formula simple](https://dqops.com/docs/images/concepts/data-quality-kpis/data-quality-kpi-formula-simple-min.png){ loading=lazy }

The data quality KPI is calculated by grouping data quality check results by the data quality dimension.
The following image shows a [data quality KPI dashboard](types-of-data-quality-dashboards.md#data-quality-kpis) from DQOps, 
showing the results for each measured data quality dimension.

![Data quality KPIs divided by data quality dimensions](https://dqops.com/docs/images/concepts/data-quality-dimensions/data-quality-dimension-kpi-per-dimension-min.png){ loading=lazy; width="1200px" }

### Best practices for monitoring data quality dimensions
Selecting data quality dimensions is one of the steps in the process of defining business needs for data quality monitoring.
This is usually done by the Data Owner who understands the purpose of the data, the data model, and the business processes
in their area of responsibility.

Before you can select data quality dimensions that are relevant for your organization, you must first identify current goals
and scope in terms of data quality monitoring. This will make it easier to come up with the metrics to measure its quality.

Next, you need to identify the data elements that are critical or required for a specific business process that needs to
be monitored. This data is typically referred to as critical data elements (CDEs). The Data Owner should also collect and
define the expectations of data consumers regarding the condition of the data, that ensure its suitability for particular purposes.

It is also a good idea to review the list of previous data quality issues that the Data Owner would like to eliminate in the future.

Only after completing the previous steps, you can assess data quality dimensions that are important for your organization.
For example, if the data must arrive on time and without delays - the organization should prioritize timeliness. If it is more
important that the data arrives in a certain format - the organization should prioritize validity.

You can learn more about defining data quality requirements and how to set up the whole data quality monitoring process in our eBook
["A step-by-step guide to improve data quality"](https://dqops.com/best-practices-for-effective-data-quality-improvement/).

## The purpose of data quality dimensions
Measuring data quality dimensions ensures data meets its purpose, establishes benchmarks for improvement, and builds trust in data-driven decisions.
By quantifying key aspects, you can identify and prioritize improvements, ensuring reliable insights and data-driven decision making. 
It also helps track progress and justify data quality investments, fostering a shared understanding across the organization.

In short, measuring data quality dimensions transforms a vague concept like "good data" into concrete,
actionable metrics that are essential for ensuring the trustworthiness of your data-driven processes.

### Assess data current status
Measuring data quality dimensions allows you to assess data fitness for use by uncovering issues
and determining its suitability for specific purposes.
Data quality dimensions help identify problems like missing values (completeness), misspellings and wrong values (validity), inconsistencies and data anomalies (consistency),
and outdated information (timeliness).  

You can also use these dimensions to determine if your data is good enough for a particular task, 
such as basic reporting versus complex predictive modeling, since different use cases may have varying requirements across data quality dimensions.

The following image shows the data quality KPI scores divided by data sources, schemas, and tables. 
When a data quality dimension is selected on the dashboard, the results are filtered to show the scores only for that dimension.

![Data quality KPIs divided by data quality dimensions](https://dqops.com/docs/images/concepts/data-quality-dimensions/data-quality-kpi-per-data-source-and-table-min.png){ loading=lazy }

### Establish benchmark and track improvements
Data quality dimensions provide measurable attributes, transforming data quality assessments from subjective judgments to quantifiable metrics.
This allows you to monitor progress over time and track whether your data cleansing initiatives,
governance policies, or operational changes are positively impacting the quality of your data.

The following image shows the data quality KPI calculated for each data quality dimension. 
The initial scores (the benchmark) can be calculated during the [data profiling phase](definition-of-data-quality-kpis.md#profile-tables).

![Data quality KPI per data quality dimension with effort](https://dqops.com/docs/images/concepts/data-quality-dimensions/data-quality-issues-per-dimension-to-measure-effort-min.png){ loading=lazy }

We can also track data quality improvement for each data quality dimension over time. 
The following chart shows the data quality KPIs for each day of the month and data quality dimension.

![Data quality KPI score per data quality dimension daily chart](https://dqops.com/docs/images/concepts/data-quality-dimensions/data-quality-kpi-chart-per-data-quality-dimension-min.png){ loading=lazy }

### Facilitate data-driven decision making
Measuring data quality dimensions empowers data-driven decision making in two key ways. 
First, high-quality data builds trust in the insights and visualizations derived from it. 
You can be confident that your conclusions are based on reliable information, not flawed data. 

Second, understanding the strengths and limitations of your data across various dimensions allows you to make informed business decisions. 
Data quality insights guide your actions and prevent you from basing critical choices on potentially inaccurate information.

### Prioritize data quality effort
By measuring data quality dimensions, you can identify the areas where data quality issues have the biggest impact.
This allows you to focus your resources on making improvements that will yield the greatest benefits.
Additionally, tracking changes in data quality over time helps you demonstrate the return on investment (ROI) of data quality initiatives.
This can be crucial for justifying continued investment in maintaining and improving data quality.

The best method to prioritize the data cleansing process is to filter data quality results by a data quality dimension with a low KPI score. 
Then, cleanse the tables with the lowest data quality score or those whose KPI score has dropped since the previous month.

![Priority of tables to fix data quality issues guided by the data quality KPI score](https://dqops.com/docs/images/concepts/data-quality-dimensions/prioritize-tables-by-data-quality-kpi-score-min.png){ loading=lazy }

### Enhance trust and collaboration
Clearly defined and measured data quality dimensions establish transparent standards and
build trust among data consumers and those who manage it.  
This creates a common vocabulary for discussing data quality, making collaboration between data producers and users more effective.
Everyone involved has a clear understanding of what constitutes high-quality data, which fosters better communication and collaboration.

## Data quality dimensions reference
The following chapters describe every data quality dimension in detail and include a list of data quality checks that measure that dimension.

## Data Accuracy

### Data accuracy definition
The following table provides an overview of the accuracy data quality dimension.

| Dimension     | Description                                                                                                                                                                                         | How DQOps measures data accuracy                                                     |
|---------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|
| **Accuracy**  | The data accuracy dimension measures how much the data matches the source of truth. <br/> Simply speaking, it is about comparing tables. <br/> This process is also called **data reconciliation**. | DQOps detects data accuracy issues by comparing data across tables and data sources. |

### Table accuracy checks
The following table lists data quality checks that detect accuracy issues on tables.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*total_row_count_match_percent*](../checks/table/accuracy/total-row-count-match-percent.md)|[accuracy](../categories-of-data-quality-checks/how-to-detect-accuracy-data-quality-issues.md)|A table-level check that compares the row count of the current (tested) table with the row count of another table that is referenced. This check ensures that the difference between the row counts is below the maximum accepted percentage of difference. This check runs an SQL query with an INNER JOIN clause to join another (referenced) table that must be defined in the same database.|:material-check-bold:|
|[*row_count_match*](../checks/table/comparisons/row-count-match.md)|[comparisons](../categories-of-data-quality-checks/how-to-reconcile-data-and-detect-differences.md)|Table level comparison check that compares the row count of the current (parent) table with the row count of the reference table.|:material-check-bold:|
|[*column_count_match*](../checks/table/comparisons/column-count-match.md)|[comparisons](../categories-of-data-quality-checks/how-to-reconcile-data-and-detect-differences.md)|Table level comparison check that compares the column count of the current (parent) table with the column count of the reference table.|:material-check-bold:|

### Column accuracy checks
The following table lists data quality checks that detect accuracy issues on columns.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*total_sum_match_percent*](../checks/column/accuracy/total-sum-match-percent.md)|[accuracy](../categories-of-data-quality-checks/how-to-detect-accuracy-data-quality-issues.md)|A column-level check that ensures that the difference between the sum of all values in the tested column and the sum of values in another column in a referenced table is below a maximum accepted percentage of difference. This check runs an SQL query with an INNER JOIN clause to join another (referenced) table that must be defined in the same database.|:material-check-bold:|
|[*total_min_match_percent*](../checks/column/accuracy/total-min-match-percent.md)|[accuracy](../categories-of-data-quality-checks/how-to-detect-accuracy-data-quality-issues.md)|A column-level check that ensures that the difference between the minimum value in the tested column and the minimum value in another column in a referenced table is below a maximum accepted percentage of difference. This check runs an SQL query with an INNER JOIN clause to join another (referenced) table that must be defined in the same database.|:material-check-bold:|
|[*total_max_match_percent*](../checks/column/accuracy/total-max-match-percent.md)|[accuracy](../categories-of-data-quality-checks/how-to-detect-accuracy-data-quality-issues.md)|A column-level check that ensures that the difference between the maximum value in the tested column and the maximum value in another column in a referenced table is below a maximum accepted percentage of difference. This check runs an SQL query with an INNER JOIN clause to join another (referenced) table that must be defined in the same database.|:material-check-bold:|
|[*total_average_match_percent*](../checks/column/accuracy/total-average-match-percent.md)|[accuracy](../categories-of-data-quality-checks/how-to-detect-accuracy-data-quality-issues.md)|A column-level check that ensures that the difference between the average value in the tested column and the average value of another column in the referenced table is below the maximum accepted percentage of difference. This check runs an SQL query with an INNER JOIN clause to join another (referenced) table that must be defined in the same database.|:material-check-bold:|
|[*total_not_null_count_match_percent*](../checks/column/accuracy/total-not-null-count-match-percent.md)|[accuracy](../categories-of-data-quality-checks/how-to-detect-accuracy-data-quality-issues.md)|A column-level check that ensures that the difference between the count of null values in the tested column and the count of null values in another column in a referenced table is below a maximum accepted percentage of difference. This check runs an SQL query with an INNER JOIN clause to join another (referenced) table that must be defined in the same database.|:material-check-bold:|
|[*sum_match*](../checks/column/comparisons/sum-match.md)|[comparisons](../categories-of-data-quality-checks/how-to-reconcile-data-and-detect-differences.md)|A column-level check that ensures that compares the sum of the values in the tested column to the sum of values in a reference column from the reference table. Compares the sum of values for each group of data. The data is grouped using a GROUP BY clause and groups are matched between the tested (parent) table and the reference table (the source of truth).|:material-check-bold:|
|[*min_match*](../checks/column/comparisons/min-match.md)|[comparisons](../categories-of-data-quality-checks/how-to-reconcile-data-and-detect-differences.md)|A column-level check that ensures that compares the minimum value in the tested column to the minimum value in a reference column from the reference table. Compares the minimum values for each group of data. The data is grouped using a GROUP BY clause and groups are matched between the tested (parent) table and the reference table (the source of truth).|:material-check-bold:|
|[*max_match*](../checks/column/comparisons/max-match.md)|[comparisons](../categories-of-data-quality-checks/how-to-reconcile-data-and-detect-differences.md)|A column-level check that ensures that compares the maximum value in the tested column to maximum value in a reference column from the reference table. Compares the maximum values for each group of data. The data is grouped using a GROUP BY clause and groups are matched between the tested (parent) table and the reference table (the source of truth).|:material-check-bold:|
|[*mean_match*](../checks/column/comparisons/mean-match.md)|[comparisons](../categories-of-data-quality-checks/how-to-reconcile-data-and-detect-differences.md)|A column-level check that ensures that compares the mean (average) of the values in the tested column to the mean (average) of values in a reference column from the reference table. Compares the mean (average) value for each group of data. The data is grouped using a GROUP BY clause and groups are matched between the tested (parent) table and the reference table (the source of truth).|:material-check-bold:|
|[*not_null_count_match*](../checks/column/comparisons/not-null-count-match.md)|[comparisons](../categories-of-data-quality-checks/how-to-reconcile-data-and-detect-differences.md)|A column-level check that ensures that compares the count of not null values in the tested column to the count of not null values in a reference column from the reference table. Compares the count of not null values for each group of data. The data is grouped using a GROUP BY clause and groups are matched between the tested (parent) table and the reference table (the source of truth).|:material-check-bold:|
|[*null_count_match*](../checks/column/comparisons/null-count-match.md)|[comparisons](../categories-of-data-quality-checks/how-to-reconcile-data-and-detect-differences.md)|A column-level check that ensures that compares the count of null values in the tested column to the count of null values in a reference column from the reference table. Compares the count of null values for each group of data. The data is grouped using a GROUP BY clause and groups are matched between the tested (parent) table and the reference table (the source of truth).|:material-check-bold:|

## Data Availability

### Data availability definition
The following table provides an overview of the availability data quality dimension.

| Dimension        | Description                                                                                                                                                          | How DQOps measures data availability                                                                                                                             |
|------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Availability** | The data availability dimension shows how reliable the data source is regarding accessibility.<br/> Simply speaking, the table can be queried during business hours. | DQOps detects data availability issues by running a simple SQL query as part of the default configuration of [data observability](data-observability.md) checks. |

### Table availability checks
The following table lists data quality checks that detect availability issues on tables.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*table_availability*](../checks/table/availability/table-availability.md)|[availability](../categories-of-data-quality-checks/how-to-table-availability-issues-and-downtimes.md)|A table-level check that ensures a query can be successfully executed on a table without server errors. It also verifies that the table exists and is accessible (queryable). The actual value (the result of the check) indicates the number of failures. If the table is accessible and a simple query can be executed without errors, the result will be 0.0. A sensor result (the actual value) of 1.0 indicates that there is a failure. Any value greater than 1.0 is stored only in the check result table and represents the number of consecutive failures in the following days.|:material-check-bold:|

## Data Completeness

### Data completeness definition
The following table provides an overview of the completeness data quality dimension.

| Dimension        | Description                                                                                                                      | How DQOps measures data completeness                                                                                                                                                                                                                                                                                                               |
|------------------|----------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Completeness** | The data completeness dimension identifies missing data.<br/> Simply speaking, tables are empty, or columns contain null values. | DQOps detects data completeness issues by running a row count query to detect empty or too small tables.<br/>The column completeness is measured by detecting null values or values that are probably null values, but a null placeholder text was found in a column. <br/> Common null placeholder values are 'n/a', 'null', 'undefined', 'None'. |

### Table completeness checks
The following table lists data quality checks that detect completeness issues on tables.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*column_count*](../checks/table/schema/column-count.md)|[schema](../categories-of-data-quality-checks/how-to-detect-table-schema-changes.md)|A table-level check that retrieves the metadata of the monitored table from the data source, counts the number of columns and compares it to an expected number of columns.|:material-check-bold:|
|[*row_count*](../checks/table/volume/row-count.md)|[volume](../categories-of-data-quality-checks/how-to-detect-data-volume-issues-and-changes.md)|This check detects empty or too-small tables. It captures the row count of a tested table. This check raises a data quality issue when the row count is below a minimum accepted value. The default value of the rule parameter **min_count** is 1 (row), which detects empty tables. When the data grouping is configured, this check will count rows using a GROUP BY clause and verify that each data grouping has an expected minimum number of rows.|:material-check-bold:|

### Column completeness checks
The following table lists data quality checks that detect completeness issues on columns.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*nulls_count*](../checks/column/nulls/nulls-count.md)|[nulls](../categories-of-data-quality-checks/how-to-detect-empty-or-incomplete-columns-with-nulls.md)|Detects incomplete columns that contain any *null* values. Counts the number of rows having a null value. Raises a data quality issue when the count of null values is above a *max_count* threshold.|:material-check-bold:|
|[*nulls_percent*](../checks/column/nulls/nulls-percent.md)|[nulls](../categories-of-data-quality-checks/how-to-detect-empty-or-incomplete-columns-with-nulls.md)|Detects incomplete columns that contain any *null* values. Measures the percentage of rows having a null value. Raises a data quality issue when the percentage of null values is above a *max_percent* threshold. Configure this check to accept a given percentage of null values by setting the *max_percent* parameter.|:material-check-bold:|
|[*nulls_percent_anomaly*](../checks/column/nulls/nulls-percent-anomaly.md)|[nulls](../categories-of-data-quality-checks/how-to-detect-empty-or-incomplete-columns-with-nulls.md)|Detects day-to-day anomalies in the percentage of *null* values. Measures the percentage of rows having a *null* value. Raises a data quality issue when the rate of null values increases or decreases too much.|:material-check-bold:|
|[*not_nulls_count*](../checks/column/nulls/not-nulls-count.md)|[nulls](../categories-of-data-quality-checks/how-to-detect-empty-or-incomplete-columns-with-nulls.md)|Detects empty columns that contain only *null* values. Counts the number of rows that have non-null values. Raises a data quality issue when the count of non-null values is below *min_count*. The default value of the *min_count* parameter is 1, but DQOps supports setting a higher number to assert that a column has at least that many non-null values.|:material-check-bold:|
|[*not_nulls_percent*](../checks/column/nulls/not-nulls-percent.md)|[nulls](../categories-of-data-quality-checks/how-to-detect-empty-or-incomplete-columns-with-nulls.md)|Detects incomplete columns that contain too few non-null values. Measures the percentage of rows that have non-null values. Raises a data quality issue when the percentage of non-null values is below *min_percentage*. The default value of the *min_percentage* parameter is 100.0, but DQOps supports setting a lower value to accept some nulls.| |
|[*nulls_percent_change*](../checks/column/nulls/nulls-percent-change.md)|[nulls](../categories-of-data-quality-checks/how-to-detect-empty-or-incomplete-columns-with-nulls.md)|Detects relative increases or decreases in the percentage of null values since the last measured percentage. Measures the percentage of null values for each day. Raises a data quality issue when the change in the percentage of null values is above *max_percent* of the previous percentage.| |
|[*nulls_percent_change_1_day*](../checks/column/nulls/nulls-percent-change-1-day.md)|[nulls](../categories-of-data-quality-checks/how-to-detect-empty-or-incomplete-columns-with-nulls.md)|Detects relative increases or decreases in the percentage of null values since the previous day. Measures the percentage of null values for each day. Raises a data quality issue when the change in the percentage of null values is above *max_percent* of the previous percentage.| |
|[*nulls_percent_change_7_days*](../checks/column/nulls/nulls-percent-change-7-days.md)|[nulls](../categories-of-data-quality-checks/how-to-detect-empty-or-incomplete-columns-with-nulls.md)|Detects relative increases or decreases in the percentage of null values since the last week (seven days ago). Measures the percentage of null values for each day. Raises a data quality issue when the change in the percentage of null values is above *max_percent* of the previous percentage.| |
|[*nulls_percent_change_30_days*](../checks/column/nulls/nulls-percent-change-30-days.md)|[nulls](../categories-of-data-quality-checks/how-to-detect-empty-or-incomplete-columns-with-nulls.md)|Detects relative increases or decreases in the percentage of null values since the last month (30 days ago). Measures the percentage of null values for each day. Raises a data quality issue when the change in the percentage of null values is above *max_percent* of the previous percentage.| |
|[*column_exists*](../checks/column/schema/column-exists.md)|[schema](../categories-of-data-quality-checks/how-to-detect-table-schema-changes.md)|A column-level check that reads the metadata of the monitored table and verifies if the column still exists in the data source. The data quality sensor returns a value of 1.0 when the column is found or 0.0 when the column is not found.|:material-check-bold:|
|[*empty_text_found*](../checks/column/whitespace/empty-text-found.md)|[whitespace](../categories-of-data-quality-checks/how-to-detect-blank-and-whitespace-values.md)|This check detects empty texts that are not null. Empty texts have a length of zero. The database treats them as values different than nulls, and some databases allow the storage of both null and empty values. This check counts empty texts and raises a data quality issue when the number of empty values exceeds a *max_count* parameter value.|:material-check-bold:|
|[*whitespace_text_found*](../checks/column/whitespace/whitespace-text-found.md)|[whitespace](../categories-of-data-quality-checks/how-to-detect-blank-and-whitespace-values.md)|This check detects empty texts containing only spaces and other whitespace characters. This check counts whitespace-only texts and raises a data quality issue when their count exceeds a *max_count* parameter value.|:material-check-bold:|
|[*null_placeholder_text_found*](../checks/column/whitespace/null-placeholder-text-found.md)|[whitespace](../categories-of-data-quality-checks/how-to-detect-blank-and-whitespace-values.md)|This check detects text values that are well-known equivalents (placeholders) of a null value, such as *null*, *None*, *n/a*. This check counts null placeholder values and raises a data quality issue when their count exceeds a *max_count* parameter value.|:material-check-bold:|
|[*empty_text_percent*](../checks/column/whitespace/empty-text-percent.md)|[whitespace](../categories-of-data-quality-checks/how-to-detect-blank-and-whitespace-values.md)|This check detects empty texts that are not null. Empty texts have a length of zero. This check measures the percentage of empty texts and raises a data quality issue when the rate of empty values exceeds a *max_percent* parameter value.| |
|[*whitespace_text_percent*](../checks/column/whitespace/whitespace-text-percent.md)|[whitespace](../categories-of-data-quality-checks/how-to-detect-blank-and-whitespace-values.md)|This check detects empty texts containing only spaces and other whitespace characters. This check measures the percentage of whitespace-only texts and raises a data quality issue when their rate exceeds a *max_percent* parameter value.| |
|[*null_placeholder_text_percent*](../checks/column/whitespace/null-placeholder-text-percent.md)|[whitespace](../categories-of-data-quality-checks/how-to-detect-blank-and-whitespace-values.md)|This check detects text values that are well-known equivalents (placeholders) of a null value, such as *null*, *None*, *n/a*. This check measures the percentage of null placeholder values and raises a data quality issue when their rate exceeds a *max_percent* parameter value.| |

## Data Consistency

### Data consistency definition
The following table provides an overview of the consistency data quality dimension.

| Dimension       | Description                                                                                                                                                                                                                                                                                                                                    | How DQOps measures data consistency                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
|-----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Consistency** | The data consistency dimension ensures that the data stays consistent across different time periods.<br/> Simply speaking, there are no anomalies detected by time series analysis.<br/>The Britannica Dictionary provides the simplest definition of consistency, which says: _"the quality or fact of staying the same at different times"_. | Data consistency is the most misunderstood data quality dimension. Every data quality vendor uses a different definition. According to some definitions, data consistency refers to the accuracy and uniformity of data stored across multiple data sources. However, this definition is too close to data accuracy, which is measured by comparing tables across data sources (data reconciliation). </br><br/> Other versions define data consistency as representing data in the same format across time or different systems. This definition is also too close to the data validity dimension, which validates whether the data is in the right format. <br/><br/>DQOps has chosen to follow a dictionary definition of consistency, which perfectly fits into the modern approach to data quality monitoring. DQOps uses time series anomaly detection, which is known as Data Observability. DQOps uses anomaly detection and data comparison within the same table to compare measures across time periods. For example, the daily row count today is close to the daily row count from yesterday. |

### Table consistency checks
The following table lists data quality checks that detect consistency issues on tables.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*column_count_changed*](../checks/table/schema/column-count-changed.md)|[schema](../categories-of-data-quality-checks/how-to-detect-table-schema-changes.md)|A table-level check that detects if the number of columns in the table has changed since the last time the check (checkpoint) was run. This check retrieves the metadata of the monitored table from the data source, counts the number of columns and compares it to the last known number of columns that was captured and is stored in the data quality check results database.|:material-check-bold:|
|[*column_list_changed*](../checks/table/schema/column-list-changed.md)|[schema](../categories-of-data-quality-checks/how-to-detect-table-schema-changes.md)|A table-level check that detects if the list of columns has changed since the last time the check was run. This check will retrieve the metadata of a tested table and calculate a hash of the column names. The hash will not depend on the order of columns, only on the column names. A data quality issue will be detected if new columns were added or columns that existed during the previous test were dropped.| |
|[*column_list_or_order_changed*](../checks/table/schema/column-list-or-order-changed.md)|[schema](../categories-of-data-quality-checks/how-to-detect-table-schema-changes.md)|A table-level check that detects if the list of columns and the order of columns have changed since the last time the check was run. This check will retrieve the metadata of a tested table and calculate a hash of the column names. The hash will depend on the order of columns. A data quality issue will be detected if new columns were added, columns that existed during the previous test were dropped or the columns were reordered.| |
|[*column_types_changed*](../checks/table/schema/column-types-changed.md)|[schema](../categories-of-data-quality-checks/how-to-detect-table-schema-changes.md)|A table-level check that detects if the column names or column types have changed since the last time the check was run. This check calculates a hash of the column names and all the components of the column&#x27;s data type: the data type name, length, scale, precision and nullability. A data quality issue will be detected if the hash of the column data types has changed. This check does not depend on the order of columns, the columns can be reordered as long as all columns are still present and the data types match since the last time they were tested.| |
|[*row_count_anomaly*](../checks/table/volume/row-count-anomaly.md)|[volume](../categories-of-data-quality-checks/how-to-detect-data-volume-issues-and-changes.md)|This check detects anomalies in the day-to-day changes to the table volume (the row count). It captures the row count for each day and compares the row count change (increase or decrease) since the previous day. This check raises a data quality issue when the change is in the top **anomaly_percent** percentage of the biggest day-to-day changes.|:material-check-bold:|
|[*row_count_change*](../checks/table/volume/row-count-change.md)|[volume](../categories-of-data-quality-checks/how-to-detect-data-volume-issues-and-changes.md)|This check compares the current table volume (the row count) to the last known row count. It raises a data quality issue when the change in row count (increase or decrease) exceeds a maximum accepted percentage of change.|:material-check-bold:|
|[*row_count_change_1_day*](../checks/table/volume/row-count-change-1-day.md)|[volume](../categories-of-data-quality-checks/how-to-detect-data-volume-issues-and-changes.md)|This check compares the current table volume (the row count) to the row count from the previous day. It raises a data quality issue when the change in row count (increase or decrease) since yesterday exceeds a maximum accepted percentage of change.| |
|[*row_count_change_7_days*](../checks/table/volume/row-count-change-7-days.md)|[volume](../categories-of-data-quality-checks/how-to-detect-data-volume-issues-and-changes.md)|This check compares the current table volume (the row count) to the row count seven days ago. This check compares the table volume to a value a week ago to overcome weekly seasonability and to compare Mondays to Mondays, Tuesdays to Tuesdays, etc. It raises a data quality issue when the change in row count (increase or decrease) since a week ago exceeds a maximum accepted percentage of change.| |
|[*row_count_change_30_days*](../checks/table/volume/row-count-change-30-days.md)|[volume](../categories-of-data-quality-checks/how-to-detect-data-volume-issues-and-changes.md)|This check compares the current table volume (the row count) to the row count 30 days ago. This check compares the table volume to a month ago value to overcome monthly seasonability. It raises a data quality issue when the change in row count (increase or decrease) since a value 30 days ago exceeds a maximum accepted percentage of change.| |

### Column consistency checks
The following table lists data quality checks that detect consistency issues on columns.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*sum_anomaly*](../checks/column/anomaly/sum-anomaly.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check calculates a sum of values in a numeric column and detects anomalies in a time series of previous sums. It raises a data quality issue when the sum is in the top *anomaly_percent* percentage of the most outstanding values in the time series. This data quality check uses a 90-day time window and requires a history of at least 30 days.|:material-check-bold:|
|[*mean_anomaly*](../checks/column/anomaly/mean-anomaly.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check calculates a mean (average) of values in a numeric column and detects anomalies in a time series of previous averages. It raises a data quality issue when the mean is in the top *anomaly_percent* percentage of the most outstanding values in the time series. This data quality check uses a 90-day time window and requires a history of at least 30 days.|:material-check-bold:|
|[*median_anomaly*](../checks/column/anomaly/median-anomaly.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check calculates a median of values in a numeric column and detects anomalies in a time series of previous medians. It raises a data quality issue when the median is in the top *anomaly_percent* percentage of the most outstanding values in the time series. This data quality check uses a 90-day time window and requires a history of at least 30 days.|:material-check-bold:|
|[*min_anomaly*](../checks/column/anomaly/min-anomaly.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check finds a minimum value in a numeric column and detects anomalies in a time series of previous minimum values. It raises a data quality issue when the current minimum value is in the top *anomaly_percent* percentage of the most outstanding values in the time series (it is a new minimum value, far from the previous one). This data quality check uses a 90-day time window and requires a history of at least 30 days.|:material-check-bold:|
|[*max_anomaly*](../checks/column/anomaly/max-anomaly.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check finds a maximum value in a numeric column and detects anomalies in a time series of previous maximum values. It raises a data quality issue when the current maximum value is in the top *anomaly_percent* percentage of the most outstanding values in the time series (it is a new maximum value, far from the previous one). This data quality check uses a 90-day time window and requires a history of at least 30 days.|:material-check-bold:|
|[*mean_change*](../checks/column/anomaly/mean-change.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the mean (average) of numeric values has changed more than *max_percent* from the last measured mean.| |
|[*mean_change_1_day*](../checks/column/anomaly/mean-change-1-day.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the mean (average) of numeric values has changed more than *max_percent* from the mean value measured one day ago (yesterday).| |
|[*mean_change_7_days*](../checks/column/anomaly/mean-change-7-days.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the mean (average) value of numeric values has changed more than *max_percent* from the mean value measured seven days ago. This check aims to overcome a weekly seasonability and compare Mondays to Mondays, Tuesdays to Tuesdays, etc.| |
|[*mean_change_30_days*](../checks/column/anomaly/mean-change-30-days.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the mean (average) of numeric values has changed more than *max_percent* from the mean value measured thirty days ago. This check aims to overcome a monthly seasonability and compare a value to a similar value a month ago.| |
|[*median_change*](../checks/column/anomaly/median-change.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the median of numeric values has changed more than *max_percent* from the last measured median.| |
|[*median_change_1_day*](../checks/column/anomaly/median-change-1-day.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the median of numeric values has changed more than *max_percent* from the median value measured one day ago (yesterday).| |
|[*median_change_7_days*](../checks/column/anomaly/median-change-7-days.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the median of numeric values has changed more than *max_percent* from the median value measured seven days ago. This check aims to overcome a weekly seasonability and compare Mondays to Mondays, Tuesdays to Tuesdays, etc.| |
|[*median_change_30_days*](../checks/column/anomaly/median-change-30-days.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the median of numeric values has changed more than *max_percent* from the median value measured thirty days ago. This check aims to overcome a monthly seasonability and compare a value to a similar value a month ago.| |
|[*sum_change*](../checks/column/anomaly/sum-change.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the sum of numeric values has changed more than *max_percent* from the last measured sum.| |
|[*sum_change_1_day*](../checks/column/anomaly/sum-change-1-day.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the sum of numeric values has changed more than *max_percent* from the sum measured one day ago (yesterday).| |
|[*sum_change_7_days*](../checks/column/anomaly/sum-change-7-days.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the sum of numeric values has changed more than *max_percent* from the sum measured seven days ago. This check aims to overcome a weekly seasonability and compare Mondays to Mondays, Tuesdays to Tuesdays, etc.| |
|[*sum_change_30_days*](../checks/column/anomaly/sum-change-30-days.md)|[anomaly](../categories-of-data-quality-checks/how-to-detect-anomaly-data-quality-issues.md)|This check detects that the sum of numeric values has changed more than *max_percent* from the sum measured thirty days ago. This check aims to overcome a monthly seasonability and compare a value to a similar value a month ago.| |
|[*detected_datatype_in_text*](../checks/column/datatype/detected-datatype-in-text.md)|[datatype](../categories-of-data-quality-checks/how-to-detect-data-type-changes.md)|A column-level check that scans all values in a text column and detects the data type of all values in a monitored column. The actual_value returned from the sensor can be one of seven codes: 1 - integers, 2 - floats, 3 - dates, 4 - datetimes, 5 - timestamps, 6 - booleans, 7 - strings, 8 - mixed data types. The check compares the data type detected in all non-null columns to an expected data type. The rule compares the value using equals and requires values in the range 1..8, which are the codes of detected data types.|:material-check-bold:|
|[*detected_datatype_in_text_changed*](../checks/column/datatype/detected-datatype-in-text-changed.md)|[datatype](../categories-of-data-quality-checks/how-to-detect-data-type-changes.md)|A column-level check that scans all values in a text column, finds the right data type and detects when the desired data type changes. The actual_value returned from the sensor can be one of seven codes: 1 - integers, 2 - floats, 3 - dates, 4 - datetimes, 5 - timestamps, 6 - booleans, 7 - strings, 8 - mixed data types. The check compares the data type detected during the current run to the last known data type detected during a previous run. For daily monitoring checks, it compares the value to yesterday&#x27;s value (or an earlier date). For partitioned checks, it compares the current data type to the data type in the previous daily or monthly partition. The last partition with data is used for comparison.|:material-check-bold:|
|[*column_type_changed*](../checks/column/schema/column-type-changed.md)|[schema](../categories-of-data-quality-checks/how-to-detect-table-schema-changes.md)|A column-level check that detects if the data type of the column has changed since the last retrieval. This check calculates the hash of all the components of the column&#x27;s data type: the data type name, length, scale, precision and nullability. A data quality issue will be detected if the hash of the column&#x27;s data types has changed.|:material-check-bold:|
|[*distinct_count_anomaly*](../checks/column/uniqueness/distinct-count-anomaly.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check monitors the count of distinct values and detects anomalies in the changes of the distinct count. It monitors a 90-day time window. The check is configured by setting a desired percentage of anomalies to identify as data quality issues.|:material-check-bold:|
|[*distinct_percent_anomaly*](../checks/column/uniqueness/distinct-percent-anomaly.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check monitors the percentage of distinct values and detects anomalies in the changes in this percentage. It monitors a 90-day time window. The check is configured by setting a desired percentage of anomalies to identify as data quality issues.| |
|[*distinct_count_change*](../checks/column/uniqueness/distinct-count-change.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check monitors the count of distinct values and compares it to the last known value. It raises a data quality issue when the change exceeds an accepted threshold.| |
|[*distinct_count_change_1_day*](../checks/column/uniqueness/distinct-count-change-1-day.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check monitors the count of distinct values and compares it to the measure from the previous day. It raises a data quality issue when the change exceeds an accepted threshold.| |
|[*distinct_count_change_7_days*](../checks/column/uniqueness/distinct-count-change-7-days.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check monitors the count of distinct values and compares it to the measure seven days ago to overcome the weekly seasonability impact. It raises a data quality issue when the change exceeds an accepted threshold.| |
|[*distinct_count_change_30_days*](../checks/column/uniqueness/distinct-count-change-30-days.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check monitors the count of distinct values and compares it to the measure thirty days ago to overcome the monthly seasonability impact. It raises a data quality issue when the change exceeds an accepted threshold.| |
|[*distinct_percent_change*](../checks/column/uniqueness/distinct-percent-change.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check monitors the percentage of distinct values and compares it to the last known value. It raises a data quality issue when the change exceeds an accepted threshold.| |
|[*distinct_percent_change_1_day*](../checks/column/uniqueness/distinct-percent-change-1-day.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check monitors the percentage of distinct values and compares it to the measure from the previous day. It raises a data quality issue when the change exceeds an accepted threshold.| |
|[*distinct_percent_change_7_days*](../checks/column/uniqueness/distinct-percent-change-7-days.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check monitors the percentage of distinct values and compares it to the measure seven days ago to overcome the weekly seasonability impact. It raises a data quality issue when the change exceeds an accepted threshold.| |
|[*distinct_percent_change_30_days*](../checks/column/uniqueness/distinct-percent-change-30-days.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check monitors the percentage of distinct values and compares it to the measure thirty days ago to overcome the monthly seasonability impact. It raises a data quality issue when the change exceeds an accepted threshold.| |
|[*text_surrounded_by_whitespace_found*](../checks/column/whitespace/text-surrounded-by-whitespace-found.md)|[whitespace](../categories-of-data-quality-checks/how-to-detect-blank-and-whitespace-values.md)|This check detects text values that contain additional whitespace characters before or after the text. This check counts text values surrounded by whitespace characters (on any side) and raises a data quality issue when their count exceeds a *max_count* parameter value. Whitespace-surrounded texts should be trimmed before loading to another table.| |
|[*text_surrounded_by_whitespace_percent*](../checks/column/whitespace/text-surrounded-by-whitespace-percent.md)|[whitespace](../categories-of-data-quality-checks/how-to-detect-blank-and-whitespace-values.md)|This check detects text values that contain additional whitespace characters before or after the text. This check measures the percentage of text value surrounded by whitespace characters (on any side) and raises a data quality issue when their rate exceeds a *max_percent* parameter value.| |

## Data Integrity

### Data integrity definition
The following table provides an overview of the integrity data quality dimension.

| Dimension     | Description                                                                                              | How DQOps measures data integrity                                                                                                                                                                                                                                                                                                                                                                                                                                        |
|---------------|----------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Integrity** | The data integrity dimension ensures that relational data is structurally valid and no keys are missing. | Traditional OLTP databases such as Oracle or SQL Server can enforce data integrity with foreign key constraints. <br/>This simple and reliable method is unavailable for non-transactional data platforms, such as data lakes that store data in S3 or similar buckets.<br/> DQOps measures data integrity by running value lookup joins that join the tested table and a reference table using a left outer join to identify missing records that do not match the key. |

### Column integrity checks
The following table lists data quality checks that detect integrity issues on columns.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*lookup_key_not_found*](../checks/column/integrity/lookup-key-not-found.md)|[integrity](../categories-of-data-quality-checks/how-to-detect-data-referential-integrity-issues.md)|This check detects invalid values that are not present in a dictionary table. The lookup uses an outer join query within the same database. This check counts the number of values not found in the dictionary table. It raises a data quality issue when too many missing keys are discovered.|:material-check-bold:|
|[*lookup_key_found_percent*](../checks/column/integrity/lookup-key-found-percent.md)|[integrity](../categories-of-data-quality-checks/how-to-detect-data-referential-integrity-issues.md)|This check detects invalid values that are not present in a dictionary table. The lookup uses an outer join query within the same database. This check measures the percentage of valid keys found in the dictionary table. It raises a data quality issue when a percentage of valid keys is below a minimum accepted threshold.| |

## Data Reasonableness

### Data reasonableness definition
The following table provides an overview of the reasonableness data quality dimension.

| Dimension          | Description                                                                                                     | How DQOps measures data reasonableness                                                                                                                                                                                                                                                            |
|--------------------|-----------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Reasonableness** | The data reasonableness dimension verifies if the data makes sense and the values are within reasonable ranges. | DQOps uses data quality range checks to assess the reasonableness of data.<br/> For example, you can validate that the prices in the product table are within reasonable ranges.<br/> You can validate the length of text fields or aggregated values such as a sum, mean, median, or percentile. |

### Table reasonableness checks
The following table lists data quality checks that detect reasonableness issues on tables.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*sql_aggregate_expression_on_table*](../checks/table/custom_sql/sql-aggregate-expression-on-table.md)|[custom_sql](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-with-custom-sql.md)|A table-level check that calculates a given SQL aggregate expression on a table and verifies if the value is within a range of accepted values.| |

### Column reasonableness checks
The following table lists data quality checks that detect reasonableness issues on columns.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*expected_text_values_in_use_count*](../checks/column/accepted_values/expected-text-values-in-use-count.md)|[accepted_values](../categories-of-data-quality-checks/how-to-validate-accepted-values-in-columns.md)|A column-level check that counts unique values in a text column and counts how many values out of a list of expected string values were found in the column. The check raises a data quality issue when the threshold for the maximum number of missing has been exceeded (too many expected values were not found in the column). This check is useful for analysing columns with a low number of unique values, such as status codes, to detect whether all status codes are used in any row.| |
|[*expected_texts_in_top_values_count*](../checks/column/accepted_values/expected-texts-in-top-values-count.md)|[accepted_values](../categories-of-data-quality-checks/how-to-validate-accepted-values-in-columns.md)|A column-level check that counts how many expected text values are among the TOP most popular values in the column. The check will first count the number of occurrences of each column&#x27;s value and will pick the TOP X most popular values (configurable by the &#x27;top&#x27; parameter). Then, it will compare the list of most popular values to the given list of expected values that should be most popular. This check will verify how many supposed most popular values (provided in the &#x27;expected_values&#x27; list) were not found in the top X most popular values in the column. This check is helpful in analyzing string columns with frequently occurring values, such as country codes for countries with the most customers.| |
|[*expected_numbers_in_use_count*](../checks/column/accepted_values/expected-numbers-in-use-count.md)|[accepted_values](../categories-of-data-quality-checks/how-to-validate-accepted-values-in-columns.md)|A column-level check that counts unique values in a numeric column and counts how many values out of a list of expected numeric values were found in the column. The check raises a data quality issue when the threshold for the maximum number of missing has been exceeded (too many expected values were not found in the column). This check is useful for analysing columns with a low number of unique values, such as status codes, to detect whether all status codes are used in any row.| |
|[*true_percent*](../checks/column/bool/true-percent.md)|[bool](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-bool-fields.md)|This check measures the percentage of **true** values in a boolean column. It raises a data quality issue when the measured percentage is outside the accepted range.|:material-check-bold:|
|[*false_percent*](../checks/column/bool/false-percent.md)|[bool](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-bool-fields.md)|This check measures the percentage of **false** values in a boolean column. It raises a data quality issue when the measured percentage is outside the accepted range.|:material-check-bold:|
|[*sql_aggregate_expression_on_column*](../checks/column/custom_sql/sql-aggregate-expression-on-column.md)|[custom_sql](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-with-custom-sql.md)|A column-level check that calculates a given SQL aggregate expression on a column and verifies if the value is within a range of accepted values.| |
|[*number_in_range_percent*](../checks/column/numeric/number-in-range-percent.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check verifies that values in a numeric column are within an accepted range. It measures the percentage of values within the valid range and raises a data quality issue when the rate of valid values is below a minimum accepted percentage.| |
|[*integer_in_range_percent*](../checks/column/numeric/integer-in-range-percent.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check verifies that numeric values are within a range of accepted values. It measures the percentage of values in the range and raises a data quality issue when the percentage of valid values is below an accepted rate.| |
|[*min_in_range*](../checks/column/numeric/min-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds a minimum value in a numeric column. It verifies that the minimum value is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*max_in_range*](../checks/column/numeric/max-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds a maximum value in a numeric column. It verifies that the maximum value is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*sum_in_range*](../checks/column/numeric/sum-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check calculates a sum of numeric values. It verifies that the sum is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*mean_in_range*](../checks/column/numeric/mean-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check calculates a mean (average) value in a numeric column. It verifies that the average value is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*median_in_range*](../checks/column/numeric/median-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds a median value in a numeric column. It verifies that the median value is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*percentile_in_range*](../checks/column/numeric/percentile-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds a requested percentile value of numeric values. The percentile is configured as a value in the range [0, 1]. This check verifies that the given percentile is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*percentile_10_in_range*](../checks/column/numeric/percentile-10-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds the 10th percentile value in a numeric column. The 10th percentile is a value greater than 10% of the smallest values and smaller than the remaining 90% of other values. This check verifies that the 10th percentile is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*percentile_25_in_range*](../checks/column/numeric/percentile-25-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds the 25th percentile value in a numeric column. The 10th percentile is a value greater than 25% of the smallest values and smaller than the remaining 75% of other values. This check verifies that the 25th percentile is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*percentile_75_in_range*](../checks/column/numeric/percentile-75-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds the 75th percentile value in a numeric column. The 75th percentile is a value greater than 75% of the smallest values and smaller than the remaining 25% of other values. This check verifies that the 75th percentile is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*percentile_90_in_range*](../checks/column/numeric/percentile-90-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds the 90th percentile value in a numeric column. The 90th percentile is a value greater than 90% of the smallest values and smaller than the remaining 10% of other values. This check verifies that the 90th percentile is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*sample_stddev_in_range*](../checks/column/numeric/sample-stddev-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check calculates the standard deviation of numeric values. It verifies that the standard deviation is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*population_stddev_in_range*](../checks/column/numeric/population-stddev-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check calculates the population standard deviation of numeric values. It verifies that the population standard deviation is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*sample_variance_in_range*](../checks/column/numeric/sample-variance-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check calculates a sample variance of numeric values. It verifies that the sample variance is within the range of accepted values and raises a data quality issue when it is not within a valid range.| |
|[*population_variance_in_range*](../checks/column/numeric/population-variance-in-range.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check calculates a population variance of numeric values. It verifies that the population variance is within the range of accepted values and raises a data quality issue when it is not within a valid range.o| |
|[*text_min_length*](../checks/column/text/text-min-length.md)|[text](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-text-fields.md)|This check finds the length of the shortest text in a column. DQOps validates the shortest length using a range rule. DQOps raises an issue when the minimum text length is outside a range of accepted values.|:material-check-bold:|
|[*text_max_length*](../checks/column/text/text-max-length.md)|[text](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-text-fields.md)|This check finds the length of the longest text in a column. DQOps validates the maximum length using a range rule. DQOps raises an issue when the maximum text length is outside a range of accepted values.|:material-check-bold:|
|[*text_mean_length*](../checks/column/text/text-mean-length.md)|[text](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-text-fields.md)|This check calculates the average text length in a column. DQOps validates the mean length using a range rule. DQOps raises an issue when the mean text length is outside a range of accepted values.| |
|[*text_length_below_min_length*](../checks/column/text/text-length-below-min-length.md)|[text](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-text-fields.md)|This check finds texts that are shorter than the minimum accepted text length. It counts the number of texts that are too short and raises a data quality issue when too many invalid texts are found.| |
|[*text_length_below_min_length_percent*](../checks/column/text/text-length-below-min-length-percent.md)|[text](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-text-fields.md)|This check finds texts that are shorter than the minimum accepted text length. It measures the percentage of too short texts and raises a data quality issue when too many invalid texts are found.| |
|[*text_length_above_max_length*](../checks/column/text/text-length-above-max-length.md)|[text](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-text-fields.md)|This check finds texts that are longer than the maximum accepted text length. It counts the number of texts that are too long and raises a data quality issue when too many invalid texts are found.| |
|[*text_length_above_max_length_percent*](../checks/column/text/text-length-above-max-length-percent.md)|[text](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-text-fields.md)|This check finds texts that are longer than the maximum accepted text length. It measures the percentage of texts that are too long and raises a data quality issue when too many invalid texts are found.| |
|[*text_length_in_range_percent*](../checks/column/text/text-length-in-range-percent.md)|[text](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-text-fields.md)|This check verifies that the minimum and maximum lengths of text values are in the range of accepted values. It measures the percentage of texts with a valid length and raises a data quality issue when an insufficient number of texts have a valid length.| |

## Data Timeliness

### Data timeliness definition
The following table provides an overview of the timeliness data quality dimension.

| Dimension      | Description                                                                                                                 | How DQOps measures data timeliness                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
|----------------|-----------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Timeliness** | The data timeliness dimension verifies if the data source contains fresh data and if the data processing lag is acceptable. | DQOps captures the most recent timestamps from the monitored table and measures the time between now and the timestamp of the most recent record. <br/> The data timeliness dimension is divided into: <br/>- **data freshness** tracks how old the data is<br/>- **data staleness** tracks when the data was loaded for the last time<br/>- **ingestion delay** measures the time between the most recent record and the time when it was loaded, showing the time consumed by data processing. <br/> Check out the [data timeliness formula](../categories-of-data-quality-checks/how-to-detect-timeliness-and-freshness-issues.md#freshness-staleness-and-ingestion-delay-compared) to see how they differ. |

### Table timeliness checks
The following table lists data quality checks that detect timeliness issues on tables.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*data_freshness*](../checks/table/timeliness/data-freshness.md)|[timeliness](../categories-of-data-quality-checks/how-to-detect-timeliness-and-freshness-issues.md)|A table-level check that calculates the time difference between the most recent row in the table and the current time. The timestamp column that is used for comparison is defined as the timestamp_columns.event_timestamp_column on the table configuration. This check is also known as &quot;Data Freshness&quot;.|:material-check-bold:|
|[*data_staleness*](../checks/table/timeliness/data-staleness.md)|[timeliness](../categories-of-data-quality-checks/how-to-detect-timeliness-and-freshness-issues.md)|A table-level check that calculates the time difference between the last timestamp when any data was loaded into a table and the current time. This check can only be use when a data pipeline, ETL process, or trigger in the data warehouse is filling an extra column with the timestamp when the data loading job was loaded. The ingestion column used for comparison is defined as the timestamp_columns.ingestion_timestamp_column on the table configuration. This check is also known as &quot;Data Staleness&quot;.| |
|[*data_ingestion_delay*](../checks/table/timeliness/data-ingestion-delay.md)|[timeliness](../categories-of-data-quality-checks/how-to-detect-timeliness-and-freshness-issues.md)|A table-level check that calculates the time difference between the most recent row in the table and the most recent timestamp when the last row was loaded into the data warehouse or data lake. To identify the most recent row, the check finds the maximum value of the timestamp column that should contain the last modification timestamp from the source. The timestamp when the row was loaded is identified by the most recent (maximum) value a timestamp column that was filled by the data pipeline, for example: &quot;loaded_at&quot;, &quot;updated_at&quot;, etc. This check requires that the data pipeline is filling an extra column with the timestamp when the data loading job has been executed. The names of both columns used for comparison should be specified in the &quot;timestamp_columns&quot; configuration entry on the table.| |
|[*reload_lag*](../checks/table/timeliness/reload-lag.md)|[timeliness](../categories-of-data-quality-checks/how-to-detect-timeliness-and-freshness-issues.md)|A table-level check that calculates the maximum difference in days between ingestion timestamp and event timestamp values on any row. This check should be executed only as a partitioned check because this check finds the longest delay between the time that the row was created in the data source and the timestamp when the row was loaded into its daily or monthly partition. This check detects that a daily or monthly partition was reloaded, setting also the most recent timestamps in the created_at, loaded_at, inserted_at or other similar columns filled by the data pipeline or an ETL process during data loading.|:material-check-bold:|

## Data Uniqueness

### Data uniqueness definition
The following table provides an overview of the uniqueness data quality dimension.

| Dimension      | Description                                                                          | How DQOps measures data uniqueness                                                         |
|----------------|--------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------|
| **Uniqueness** | The data uniqueness dimension verifies that no records are duplicate in the dataset. | DQOps measures the number and the percentage of distinct and duplicate values in a column. |

### Column uniqueness checks
The following table lists data quality checks that detect uniqueness issues on columns.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*distinct_count*](../checks/column/uniqueness/distinct-count.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check counts distinct values and verifies if the distinct count is within an accepted range. It raises a data quality issue when the distinct count is below or above the accepted range.|:material-check-bold:|
|[*distinct_percent*](../checks/column/uniqueness/distinct-percent.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check measures the percentage of distinct values in all non-null values. It verifies that the percentage of distinct values meets a minimum value. The default value of 100% distinct values ensures the column has no duplicate values.|:material-check-bold:|
|[*duplicate_count*](../checks/column/uniqueness/duplicate-count.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check counts duplicate values. It raises a data quality issue when the number of duplicates is above a minimum accepted value. The default configuration detects duplicate values by enforcing that the *min_count* of duplicates is zero.|:material-check-bold:|
|[*duplicate_percent*](../checks/column/uniqueness/duplicate-percent.md)|[uniqueness](../categories-of-data-quality-checks/how-to-detect-data-uniqueness-issues-and-duplicates.md)|This check measures the percentage of duplicate values in all non-null values. It raises a data quality issue when the percentage of duplicates is above an accepted threshold. The default threshold is 0% duplicate values.| |

## Data Validity

### Data validity definition
The following table provides an overview of the validity data quality dimension.

| Dimension    | Description                                                                                                                                                                                                | How DQOps measures data validity                                                                                                                                                                                                                                                                                                                                      |
|--------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Validity** | The data validity dimension verifies that the values conform to agreed data formats and low cardinality columns (columns containing only known values) store only values from an accepted data dictionary. | DQOps uses regular expressions to validate values that should match a pattern, such as an email or a phone number.<br/> Columns that should contain only values from a data dictionary use an **IN** SQL condition.<br/> DQOps provides several built-in dictionaries, such as country and currency codes.<br/> The other dictionaries can be uploaded as a CSV file. |

### Table validity checks
The following table lists data quality checks that detect validity issues on tables.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*sql_condition_failed_on_table*](../checks/table/custom_sql/sql-condition-failed-on-table.md)|[custom_sql](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-with-custom-sql.md)|A table-level check that uses a custom SQL expression on each row to verify (assert) that all rows pass a custom condition defined as an SQL condition. Use the {alias} token to reference the tested table. This data quality check can be used to compare columns on the same table. For example, the condition can verify that the value in the *col_price* column is higher than the *col_tax* column using an SQL expression: &#x60;{alias}.col_price &gt; {alias}.col_tax&#x60;. Use an SQL expression that returns a *true* value for valid values and a *false* one for invalid values, because it is an assertion.|:material-check-bold:|
|[*sql_condition_passed_percent_on_table*](../checks/table/custom_sql/sql-condition-passed-percent-on-table.md)|[custom_sql](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-with-custom-sql.md)|A table-level check that ensures that a minimum percentage of rows passed a custom SQL condition (expression). Measures the percentage of rows passing the condition. Raises a data quality issue when the percent of valid rows is below the *min_percent* parameter.| |
|[*import_custom_result_on_table*](../checks/table/custom_sql/import-custom-result-on-table.md)|[custom_sql](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-with-custom-sql.md)|A table-level check that uses a custom SQL SELECT statement to retrieve a result of running a custom data quality check that was hardcoded in the data pipeline, and the result was stored in a separate table. The SQL query that is configured in this external data quality results importer must be a complete SELECT statement that queries a dedicated table (created by the data engineers) that stores the results of custom data quality checks. The SQL query must return a *severity* column with values: 0 - data quality check passed, 1 - warning issue, 2 - error severity issue, 3 - fatal severity issue.| |

### Column validity checks
The following table lists data quality checks that detect validity issues on columns.

| Data quality check name | Check category | Description | Standard check |
|-------------------------|----------------|-------------|----------------|
|[*text_found_in_set_percent*](../checks/column/accepted_values/text-found-in-set-percent.md)|[accepted_values](../categories-of-data-quality-checks/how-to-validate-accepted-values-in-columns.md)|A column-level check that calculates the percentage of rows for which the tested text column contains a value from a set of expected values. Columns with null values are also counted as a passing value (the sensor assumes that a &#x27;null&#x27; is also an expected and accepted value). The check raises a data quality issue when the percentage of rows with a not null column value that is not expected (not one of the values in the expected_values set) is below the expected threshold. For example, 99% of rows should have values from the defined domain. This data quality check is useful for checking text columns that have a small number of unique values, and all the values should come from a set of expected values. For example, testing country, state, currency, gender, type, and department columns whose expected values are known.|:material-check-bold:|
|[*number_found_in_set_percent*](../checks/column/accepted_values/number-found-in-set-percent.md)|[accepted_values](../categories-of-data-quality-checks/how-to-validate-accepted-values-in-columns.md)|A column-level check that calculates the percentage of rows for which the tested numeric column contains a value from a set of expected values. Columns with null values are also counted as a passing value (the sensor assumes that a &#x27;null&#x27; is also an expected and accepted value). The check raises a data quality issue when the percentage of rows with a not null column value that is not expected (not one of the values in the expected_values set) is below the expected threshold. For example, 99% of rows should have values from the defined domain. This data quality check is useful for checking numeric columns that store numeric codes (such as status codes) to see if the only values found in the column are from the set of expected values.|:material-check-bold:|
|[*text_valid_country_code_percent*](../checks/column/accepted_values/text-valid-country-code-percent.md)|[accepted_values](../categories-of-data-quality-checks/how-to-validate-accepted-values-in-columns.md)|This check measures the percentage of text values that are valid two-letter country codes. It raises a data quality issue when the percentage of valid country codes (excluding null values) falls below a minimum accepted rate.| |
|[*text_valid_currency_code_percent*](../checks/column/accepted_values/text-valid-currency-code-percent.md)|[accepted_values](../categories-of-data-quality-checks/how-to-validate-accepted-values-in-columns.md)|This check measures the percentage of text values that are valid currency names. It raises a data quality issue when the percentage of valid currency names (excluding null values) falls below a minimum accepted rate.| |
|[*text_parsable_to_boolean_percent*](../checks/column/conversions/text-parsable-to-boolean-percent.md)|[conversions](../categories-of-data-quality-checks/how-to-verify-text-values-are-parsable.md)|Verifies that values in a text column are convertible to a boolean value. Texts are convertible to a boolean value when they are one of the well-known boolean placeholders: &#x27;0&#x27;, &#x27;1&#x27;, &#x27;true&#x27;, &#x27;false&#x27;, &#x27;yes&#x27;, &#x27;no&#x27;, &#x27;y&#x27;, &#x27;n&#x27;. This check measures the percentage of valid values and raises a data quality issue when the percentage of valid values is below an accepted rate.|:material-check-bold:|
|[*text_parsable_to_integer_percent*](../checks/column/conversions/text-parsable-to-integer-percent.md)|[conversions](../categories-of-data-quality-checks/how-to-verify-text-values-are-parsable.md)|Verifies that values in a text column can be parsed and converted to an integer type. This check measures the percentage of valid values and raises a data quality issue when the percentage of valid values is below an accepted rate.|:material-check-bold:|
|[*text_parsable_to_float_percent*](../checks/column/conversions/text-parsable-to-float-percent.md)|[conversions](../categories-of-data-quality-checks/how-to-verify-text-values-are-parsable.md)|Verifies that values in a text column can be parsed and converted to a float (or numeric) type. This check measures the percentage of valid values and raises a data quality issue when the percentage of valid values is below an accepted rate.|:material-check-bold:|
|[*text_parsable_to_date_percent*](../checks/column/conversions/text-parsable-to-date-percent.md)|[conversions](../categories-of-data-quality-checks/how-to-verify-text-values-are-parsable.md)|Verifies that values in a text column can be parsed and converted to a date type. This check measures the percentage of valid values and raises a data quality issue when the percentage of valid values is below an accepted rate.|:material-check-bold:|
|[*sql_condition_failed_on_column*](../checks/column/custom_sql/sql-condition-failed-on-column.md)|[custom_sql](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-with-custom-sql.md)|A column-level check that uses a custom SQL expression on each column to verify (assert) that all rows pass a custom condition defined as an SQL expression. Use the {alias} token to reference the tested table, and the {column} to reference the column that is tested. This data quality check can be used to compare columns on the same table. For example, when this check is applied on a *col_price* column, the condition can verify that the *col_price* is higher than the *col_tax* using an SQL expression: &#x60;{alias}.{column} &gt; {alias}.col_tax&#x60; Use an SQL expression that returns a *true* value for valid values and *false* for invalid values, because it is an assertion.|:material-check-bold:|
|[*sql_condition_passed_percent_on_column*](../checks/column/custom_sql/sql-condition-passed-percent-on-column.md)|[custom_sql](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-with-custom-sql.md)|A table-level check that ensures that a minimum percentage of rows passed a custom SQL condition (expression). Measures the percentage of rows passing the condition. Raises a data quality issue when the percent of valid rows is below the *min_percent* parameter.| |
|[*import_custom_result_on_column*](../checks/column/custom_sql/import-custom-result-on-column.md)|[custom_sql](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-with-custom-sql.md)|Column level check that uses a custom SQL SELECT statement to retrieve a result of running a custom data quality check on a column by a custom data quality check, hardcoded in the data pipeline. The result is retrieved by querying a separate **logging table**, whose schema is not fixed. The logging table should have columns that identify a table and a column for which they store custom data quality check results, and a *severity* column of the data quality issue. The SQL query that is configured in this external data quality results importer must be a complete SELECT statement that queries a dedicated logging table, created by the data engineering team.| |
|[*date_values_in_future_percent*](../checks/column/datetime/date-values-in-future-percent.md)|[datetime](../categories-of-data-quality-checks/how-to-detect-invalid-dates.md)|Detects dates in the future in date, datetime and timestamp columns. Measures a percentage of dates in the future. Raises a data quality issue when too many future dates are found.|:material-check-bold:|
|[*date_in_range_percent*](../checks/column/datetime/date-in-range-percent.md)|[datetime](../categories-of-data-quality-checks/how-to-detect-invalid-dates.md)|Verifies that the dates in date, datetime, or timestamp columns are within a reasonable range of dates. The default configuration detects fake dates such as 1900-01-01 and 2099-12-31. Measures the percentage of valid dates and raises a data quality issue when too many dates are found.|:material-check-bold:|
|[*text_match_date_format_percent*](../checks/column/datetime/text-match-date-format-percent.md)|[datetime](../categories-of-data-quality-checks/how-to-detect-invalid-dates.md)|Verifies that the values in text columns match one of the predefined date formats, such as an ISO 8601 date. Measures the percentage of valid date strings and raises a data quality issue when too many invalid date strings are found.|:material-check-bold:|
|[*number_below_min_value*](../checks/column/numeric/number-below-min-value.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds numeric values smaller than the minimum accepted value. It counts the values that are too small. This check raises a data quality issue when the count of too small values exceeds the maximum accepted count.|:material-check-bold:|
|[*number_above_max_value*](../checks/column/numeric/number-above-max-value.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds numeric values bigger than the maximum accepted value. It counts the values that are too big. This check raises a data quality issue when the count of too big values exceeds the maximum accepted count.|:material-check-bold:|
|[*negative_values*](../checks/column/numeric/negative-values.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds and counts negative values in a numeric column. It raises a data quality issue when the count of negative values is above the maximum accepted count.|:material-check-bold:|
|[*negative_values_percent*](../checks/column/numeric/negative-values-percent.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds negative values in a numeric column. It measures the percentage of negative values and raises a data quality issue when the rate of negative values exceeds the maximum accepted percentage.| |
|[*number_below_min_value_percent*](../checks/column/numeric/number-below-min-value-percent.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds numeric values smaller than the minimum accepted value. It measures the percentage of values that are too small. This check raises a data quality issue when the percentage of values that are too small exceeds the maximum accepted percentage.| |
|[*number_above_max_value_percent*](../checks/column/numeric/number-above-max-value-percent.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds numeric values bigger than the maximum accepted value. It measures the percentage of values that are too big. This check raises a data quality issue when the percentage of values that are too big exceeds the maximum accepted percentage.| |
|[*invalid_latitude*](../checks/column/numeric/invalid-latitude.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds numeric values that are not valid latitude coordinates. A valid latitude coordinate is in the range -90...90. It counts the values outside a valid range for a latitude. This check raises a data quality issue when the count of invalid values exceeds the maximum accepted count.| |
|[*valid_latitude_percent*](../checks/column/numeric/valid-latitude-percent.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check verifies that numeric values are valid latitude coordinates. A valid latitude coordinate is in the range -90...90. It measures the percentage of values within a valid range for a latitude. This check raises a data quality issue when the rate of valid values is below the minimum accepted percentage.| |
|[*invalid_longitude*](../checks/column/numeric/invalid-longitude.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds numeric values that are not valid longitude coordinates. A valid longitude coordinate is in the range -180...180. It counts the values outside a valid range for a longitude. This check raises a data quality issue when the count of invalid values exceeds the maximum accepted count.| |
|[*valid_longitude_percent*](../checks/column/numeric/valid-longitude-percent.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check verifies that numeric values are valid longitude coordinates. A valid longitude coordinate is in the range --180...180. It measures the percentage of values within a valid range for a longitude. This check raises a data quality issue when the rate of valid values is below the minimum accepted percentage.| |
|[*non_negative_values*](../checks/column/numeric/non-negative-values.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds and counts non0negative values in a numeric column. It raises a data quality issue when the count of non-negative values is above the maximum accepted count.| |
|[*non_negative_values_percent*](../checks/column/numeric/non-negative-values-percent.md)|[numeric](../categories-of-data-quality-checks/how-to-detect-data-quality-issues-in-numeric-fields.md)|This check finds non-negative values in a numeric column. It measures the percentage of non-negative values and raises a data quality issue when the rate of non-negative values exceeds the maximum accepted percentage.| |
|[*text_not_matching_regex_found*](../checks/column/patterns/text-not-matching-regex-found.md)|[patterns](../categories-of-data-quality-checks/how-to-detect-bad-values-not-matching-patterns.md)|This check validates text values using a pattern defined as a regular expression. It counts the number of invalid values and raises a data quality issue when the number exceeds a threshold.|:material-check-bold:|
|[*texts_matching_regex_percent*](../checks/column/patterns/texts-matching-regex-percent.md)|[patterns](../categories-of-data-quality-checks/how-to-detect-bad-values-not-matching-patterns.md)|This check validates text values using a pattern defined as a regular expression. It measures the percentage of valid values and raises a data quality issue when the rate is below a threshold.|:material-check-bold:|
|[*invalid_email_format_found*](../checks/column/patterns/invalid-email-format-found.md)|[patterns](../categories-of-data-quality-checks/how-to-detect-bad-values-not-matching-patterns.md)|This check detects invalid email addresses in text columns using a regular expression. It counts the number of invalid emails and raises a data quality issue when the number is above a threshold.|:material-check-bold:|
|[*invalid_email_format_percent*](../checks/column/patterns/invalid-email-format-percent.md)|[patterns](../categories-of-data-quality-checks/how-to-detect-bad-values-not-matching-patterns.md)|This check detects invalid email addresses in text columns using a regular expression. It calculated the percentage of invalid emails and raises a data quality issue when the percentage is above a threshold.| |
|[*text_not_matching_date_pattern_found*](../checks/column/patterns/text-not-matching-date-pattern-found.md)|[patterns](../categories-of-data-quality-checks/how-to-detect-bad-values-not-matching-patterns.md)|This check detects dates in the wrong format inside text columns using a regular expression. It counts the number of incorrectly formatted dates and raises a data quality issue when the number exceeds a threshold.| |
|[*text_matching_date_pattern_percent*](../checks/column/patterns/text-matching-date-pattern-percent.md)|[patterns](../categories-of-data-quality-checks/how-to-detect-bad-values-not-matching-patterns.md)|This check validates the date format of dates stored in text columns. It measures the percentage of correctly formatted dates and raises a data quality issue when the rate is below a threshold.| |
|[*text_matching_name_pattern_percent*](../checks/column/patterns/text-matching-name-pattern-percent.md)|[patterns](../categories-of-data-quality-checks/how-to-detect-bad-values-not-matching-patterns.md)|This check verifies if values stored in a text column contain only letters and are usable as literal identifiers. It measures the percentage of valid literal identifiers and raises a data quality issue when the rate is below a threshold.| |
|[*invalid_uuid_format_found*](../checks/column/patterns/invalid-uuid-format-found.md)|[patterns](../categories-of-data-quality-checks/how-to-detect-bad-values-not-matching-patterns.md)|This check detects invalid UUID identifiers in text columns using a regular expression. It counts the number of invalid UUIDs and raises a data quality issue when the number is above a threshold.| |
|[*valid_uuid_format_percent*](../checks/column/patterns/valid-uuid-format-percent.md)|[patterns](../categories-of-data-quality-checks/how-to-detect-bad-values-not-matching-patterns.md)|This check validates the format of UUID values in text columns. It measures the percentage of valid UUIDs and raises a data quality issue when the rate is below a threshold.| |
|[*invalid_ip4_address_format_found*](../checks/column/patterns/invalid-ip4-address-format-found.md)|[patterns](../categories-of-data-quality-checks/how-to-detect-bad-values-not-matching-patterns.md)|This check detects invalid IP4 internet addresses in text columns using a regular expression. It counts the number of invalid addresses and raises a data quality issue when the number is above a threshold.| |
|[*invalid_ip6_address_format_found*](../checks/column/patterns/invalid-ip6-address-format-found.md)|[patterns](../categories-of-data-quality-checks/how-to-detect-bad-values-not-matching-patterns.md)|This check detects invalid IP6 internet addresses in text columns using a regular expression. It counts the number of invalid addresses and raises a data quality issue when the number is above a threshold.| |
|[*contains_usa_phone_percent*](../checks/column/pii/contains-usa-phone-percent.md)|[pii](../categories-of-data-quality-checks/how-to-detect-pii-values-and-sensitive-data.md)|This check detects USA phone numbers inside text columns. It measures the percentage of columns containing a phone number and raises a data quality issue when too many rows contain phone numbers.|:material-check-bold:|
|[*contains_email_percent*](../checks/column/pii/contains-email-percent.md)|[pii](../categories-of-data-quality-checks/how-to-detect-pii-values-and-sensitive-data.md)|This check detects emails inside text columns. It measures the percentage of columns containing an email and raises a data quality issue when too many rows contain emails.|:material-check-bold:|
|[*contains_usa_zipcode_percent*](../checks/column/pii/contains-usa-zipcode-percent.md)|[pii](../categories-of-data-quality-checks/how-to-detect-pii-values-and-sensitive-data.md)|This check detects USA zip code inside text columns. It measures the percentage of columns containing a zip code and raises a data quality issue when too many rows contain zip codes.| |
|[*contains_ip4_percent*](../checks/column/pii/contains-ip4-percent.md)|[pii](../categories-of-data-quality-checks/how-to-detect-pii-values-and-sensitive-data.md)|This check detects IP4 addresses inside text columns. It measures the percentage of columns containing an IP4 address and raises a data quality issue when too many rows contain IP4 addresses.| |
|[*contains_ip6_percent*](../checks/column/pii/contains-ip6-percent.md)|[pii](../categories-of-data-quality-checks/how-to-detect-pii-values-and-sensitive-data.md)|This check detects IP6 addresses inside text columns. It measures the percentage of columns containing an IP6 address and raises a data quality issue when too many rows contain IP6 addresses.| |

## What's more
- Review the [types of data quality dashboards](types-of-data-quality-dashboards.md) that are provided with DQOps.
- Learn how DQOps calculates [data quality KPIs per data quality dimension](definition-of-data-quality-kpis.md#monthly-with-data-quality-dimensions).
