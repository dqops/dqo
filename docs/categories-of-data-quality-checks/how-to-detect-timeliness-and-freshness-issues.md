# Detecting data quality issues with timeliness
Read this guide to learn what types of data quality checks are supported in DQOps to detect issues related to timeliness.
The data quality checks are configured in the `timeliness` category in DQOps.

## Timeliness category
Data quality checks that are detecting issues related to timeliness are listed below.

## Detecting timeliness issues
How to detect timeliness data quality issues.

## List of timeliness checks at a table level
| Data quality check name | Data quality dimension | Description | Standard check |
|-------------------------|------------------------|-------------|-------|
|[*data_freshness*](../checks/table/timeliness/data-freshness.md)|Timeliness|A table-level check that calculates the time difference between the most recent row in the table and the current time. The timestamp column that is used for comparison is defined as the timestamp_columns.event_timestamp_column on the table configuration. This check is also known as &quot;Data Freshness&quot;.|:material-check-bold:|
|[*data_staleness*](../checks/table/timeliness/data-staleness.md)|Timeliness|A table-level check that calculates the time difference between the last timestamp when any data was loaded into a table and the current time. This check can only be use when a data pipeline, ETL process, or trigger in the data warehouse is filling an extra column with the timestamp when the data loading job was loaded. The ingestion column used for comparison is defined as the timestamp_columns.ingestion_timestamp_column on the table configuration. This check is also known as &quot;Data Staleness&quot;.| |
|[*data_ingestion_delay*](../checks/table/timeliness/data-ingestion-delay.md)|Timeliness|A table-level check that calculates the time difference between the most recent row in the table and the most recent timestamp when the last row was loaded into the data warehouse or data lake. To identify the most recent row, the check finds the maximum value of the timestamp column that should contain the last modification timestamp from the source. The timestamp when the row was loaded is identified by the most recent (maximum) value a timestamp column that was filled by the data pipeline, for example: &quot;loaded_at&quot;, &quot;updated_at&quot;, etc. This check requires that the data pipeline is filling an extra column with the timestamp when the data loading job has been executed. The names of both columns used for comparison should be specified in the &quot;timestamp_columns&quot; configuration entry on the table.| |
|[*reload_lag*](../checks/table/timeliness/reload-lag.md)|Timeliness|A table-level check that calculates the maximum difference in days between ingestion timestamp and event timestamp values on any row. This check should be executed only as a partitioned check because this check finds the longest delay between the time that the row was created in the data source and the timestamp when the row was loaded into its daily or monthly partition. This check detects that a daily or monthly partition was reloaded, setting also the most recent timestamps in the created_at, loaded_at, inserted_at or other similar columns filled by the data pipeline or an ETL process during data loading.|:material-check-bold:|


**Reference and samples**

The full list of all data quality checks in this category is located in the [table/timeliness](../checks/table/timeliness/index.md) reference.
The reference section provides YAML code samples that are ready to copy-paste to the [*.dqotable.yaml*](../reference/yaml/TableYaml.md) files,
the parameters reference, and samples of data source specific SQL queries generated by [data quality sensors](../dqo-concepts/definition-of-data-quality-sensors.md)
that are used by those checks.

## Configure event and ingestion timestamp columns for timeliness checks

To run timeliness checks you need to configure event and/or ingestion timestamp columns.

To configure the event and/or ingestion timestamp columns:

1. Go to the **Data Sources** section.

2. Select the table of interest from the tree view.

3. Select the **Data and Time Columns** tab and select a column from the drop-down list in the "Event timestamp column name
   for timeliness checks" and/or "Ingestion timestamp column name for timeliness checks" input fields.

    ![Configure event and ingestion timestamp columns](https://dqops.com/docs/images/working-with-dqo/run-data-quality-checks/event-and-ingestion-columns-configuration-for-timeliness-checks.png)

4. Click the Save button in the upper right corner.

The event and ingestion timestamps for timeliness checks can be also configured by adding
the appropriate parameters to the YAML configuration file.

Below is an example of the YAML file showing a sample configuration with set event timestamps column `event_timestamp_column`,
ingestion timestamps column `ingestion_timestamp_column`.

``` yaml hl_lines="7-9"
apiVersion: dqo/v1
kind: table
spec:
  target:
    schema_name: target_schema
    table_name: target_table
  timestamp_columns:
    event_timestamp_column: col_event_timestamp
    ingestion_timestamp_column: col_inserted_at
    partition_by_column: 
```

## What's next
- Learn how to [run data quality checks](../dqo-concepts/running-data-quality-checks.md#targeting-a-category-of-checks) filtering by a check category name
- Learn how to [configure data quality checks](../dqo-concepts/configuring-data-quality-checks-and-rules.md) and apply alerting rules
- Read the definition of [data quality dimensions](../dqo-concepts/data-quality-dimensions.md) used by DQOps
