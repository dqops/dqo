---
swagger: "2.0"
info:
  description: "DQOps REST API"
  version: "v1"
  title: "DQOps"
  termsOfService: "https://dqops.com/terms-of-service"
  contact:
    name: "DQOps Support"
    url: "https://dqops.com/"
    email: "support@dqops.com"
  license:
    name: "Apache 2.0"
    url: "https://www.apache.org/licenses/LICENSE-2.0.html"
basePath: "/"
tags:
- name: "CheckResults"
  description: "Returns all the data quality check results of executed checks on tables\
    \ and columns."
- name: "CheckResultsOverview"
  description: "Returns the overview of the recently executed checks on tables and\
    \ columns, returning a summary of the last 5 runs."
- name: "Checks"
  description: "Data quality check definition management operations for adding/removing/changing\
    \ custom data quality checks."
- name: "Columns"
  description: "Operations related to manage the metadata of columns, and managing\
    \ the configuration of column-level data quality checks."
- name: "Connections"
  description: "Operations for adding/updating/deleting the configuration of data\
    \ sources managed by DQOps."
- name: "Dashboards"
  description: "Operations for retrieving the list of data quality dashboards supported\
    \ by DQOps and issuing short-term access keys to open a dashboard."
- name: "DataGroupingConfigurations"
  description: "Operations for managing the configuration of data groupings on a table\
    \ level in DQOps."
- name: "DataSources"
  description: "Rest API controller that operates on data sources that are not yet\
    \ imported, testing connections or retrieving the metadata (schemas and tables)."
- name: "DefaultColumnCheckPatterns"
  description: "Operations for managing the configuration of the default column-level\
    \ checks for columns matching a pattern."
- name: "Defaults"
  description: "Default settings management for configuring the default data quality\
    \ checks that are configured for all imported tables and columns."
- name: "DefaultTableCheckPatterns"
  description: "Operations for managing the configuration of the default table-level\
    \ checks for tables matching a pattern."
- name: "Dictionaries"
  description: "Operations for managing data dictionary CSV files in DQOps. Data dictionaries\
    \ can be used in *accepted_values* data quality checks."
- name: "Environment"
  description: "DQOps environment and configuration controller, provides access to\
    \ the DQOps configuration, current user's information and issue local API Keys\
    \ for the calling user."
- name: "Errors"
  description: "Operations that return the execution errors captured when data quality\
    \ checks were executed on data sources, and sensors or rules failed with an error."
- name: "Healthcheck"
  description: "Health check operations for checking if the DQOps service is up and\
    \ operational. Used for monitoring by load balancers."
- name: "Incidents"
  description: "Data quality incidents controller that supports reading and updating\
    \ data quality incidents, such as changing the incident status or assigning an\
    \ external ticket number."
- name: "Jobs"
  description: "Jobs management controller that supports starting new jobs, such as\
    \ running selected data quality checks. Provides access to the job queue for incremental\
    \ monitoring."
- name: "Labels"
  description: "Operations that returns all labels that are assigned to data assets.\
    \ Labels serve the purpose of a lazy business glossary."
- name: "LogShipping"
  description: "Log shipping controller that accepts logs sent from a web application\
    \ or external tools and aggregates them in the local DQOps instance logs."
- name: "Rules"
  description: "Operations for managing custom data quality rule definitions in DQOps.\
    \ The custom rules are stored in the DQOps user home folder."
- name: "Schemas"
  description: "Operations for listing imported schemas from monitored data sources.\
    \ Also provides operations for activating and deactivating multiple checks at\
    \ once."
- name: "Search"
  description: "Search operations for finding data assets, such as tables."
- name: "SensorReadouts"
  description: "Operations that are retrieving the data quality sensor readouts of\
    \ executed checks on tables and columns."
- name: "Sensors"
  description: "Operations for managing custom data quality sensor definitions in\
    \ DQOps. The custom sensors are stored in the DQOps user home folder."
- name: "SharedCredentials"
  description: "Operations for managing shared credentials in DQOps. Credentials that\
    \ are stored in the shared .credentials folder in the DQOps user's home folder."
- name: "TableComparisonResults"
  description: "Operations that returns the results of the most recent table comparison\
    \ that was performed between the compared table and the reference table (the source\
    \ of truth)."
- name: "TableComparisons"
  description: "Operations for managing the configurations of table comparisons between\
    \ tables on the same or different data sources"
- name: "Tables"
  description: "Operations related to manage the metadata of imported tables, and\
    \ managing the configuration of table-level data quality checks."
- name: "Timezones"
  description: "Operations for returning time zone names and codes supported by DQOps."
- name: "Users"
  description: "Operations for managing access for DQOps users in a multi-user installations.\
    \ User management is supported in the TEAM and ENTERPRISE licences."
paths:
  /api/checks:
    get:
      tags:
      - "Checks"
      summary: "getAllChecks"
      description: "Returns a flat list of all checks available in DQOps, both built-in\
        \ checks and user defined or customized checks."
      operationId: "getAllChecks"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckDefinitionListModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/checks/{fullCheckName}:
    get:
      tags:
      - "Checks"
      summary: "getCheck"
      description: "Returns a check definition"
      operationId: "getCheck"
      produces:
      - "application/json"
      parameters:
      - name: "fullCheckName"
        in: "path"
        description: "Full check name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckDefinitionModel"
        404:
          description: "Check name not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "Checks"
      summary: "createCheck"
      description: "Creates (adds) a new custom check that is a pair of a sensor name\
        \ and a rule name."
      operationId: "createCheck"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "fullCheckName"
        in: "path"
        description: "Full check name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Check model"
        required: false
        schema:
          $ref: "#/definitions/CheckDefinitionModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New custom check successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Custom check with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Checks"
      summary: "updateCheck"
      description: "Updates an existing check, making a custom check definition if\
        \ it is not present"
      operationId: "updateCheck"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "List of check definitions"
        required: false
        schema:
          $ref: "#/definitions/CheckDefinitionModel"
      - name: "fullCheckName"
        in: "path"
        description: "Full check name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Custom check successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Check not found"
        409:
          description: "Cannot change a check definition of a built-in check"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "Checks"
      summary: "deleteCheck"
      description: "Deletes a custom check definition"
      operationId: "deleteCheck"
      produces:
      - "application/json"
      parameters:
      - name: "fullCheckName"
        in: "path"
        description: "Full check name"
        required: true
        type: "string"
      responses:
        200:
          description: "Custom check definition successfully deleted"
          schema:
            $ref: "#/definitions/MonoVoid"
        404:
          description: "Custom check not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections:
    get:
      tags:
      - "Connections"
      summary: "getAllConnections"
      description: "Returns a list of connections (data sources)"
      operationId: "getAllConnections"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/ConnectionModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}:
    get:
      tags:
      - "Connections"
      summary: "getConnection"
      description: "Return the full details of a connection given the connection name"
      operationId: "getConnection"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      responses:
        200:
          description: "Connection returned"
          schema:
            $ref: "#/definitions/ConnectionSpecificationModel"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "Connections"
      summary: "createConnection"
      description: "Creates a new connection"
      operationId: "createConnection"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Connection specification"
        required: false
        schema:
          $ref: "#/definitions/ConnectionSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New connection successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Connection with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Connections"
      summary: "updateConnection"
      description: "Updates an existing connection"
      operationId: "updateConnection"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Connection specification"
        required: false
        schema:
          $ref: "#/definitions/ConnectionSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Connection successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "Connections"
      summary: "deleteConnection"
      description: "Deletes a connection"
      operationId: "deleteConnection"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      responses:
        200:
          description: "Connection successfully deleted"
          schema:
            $ref: "#/definitions/DqoQueueJobId"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/basic:
    get:
      tags:
      - "Connections"
      summary: "getConnectionBasic"
      description: "Return the basic details of a connection given the connection\
        \ name"
      operationId: "getConnectionBasic"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      responses:
        200:
          description: "Connection basic information returned"
          schema:
            $ref: "#/definitions/ConnectionModel"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "Connections"
      summary: "createConnectionBasic"
      description: "Creates a new connection given the basic information."
      operationId: "createConnectionBasic"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Basic connection model"
        required: false
        schema:
          $ref: "#/definitions/ConnectionModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New connection successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Connection with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Connections"
      summary: "updateConnectionBasic"
      description: "Updates the basic information of a connection"
      operationId: "updateConnectionBasic"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Connection basic details"
        required: false
        schema:
          $ref: "#/definitions/ConnectionModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Connection's basic parameters successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/checks/{checkName}/bulkactivate:
    put:
      tags:
      - "Connections"
      summary: "bulkActivateConnectionChecks"
      description: "Activates all named check on this connection in the locations\
        \ specified by filter"
      operationId: "bulkActivateConnectionChecks"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "checkName"
        in: "path"
        description: "Check name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Check search filters and rules configuration"
        required: false
        schema:
          $ref: "#/definitions/AllChecksPatchParameters"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Checks enabled in bulk"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/checks/{checkName}/bulkdeactivate:
    put:
      tags:
      - "Connections"
      summary: "bulkDeactivateConnectionChecks"
      description: "Deactivates (deletes) all named check on this connection in the\
        \ locations specified by filter"
      operationId: "bulkDeactivateConnectionChecks"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "checkName"
        in: "path"
        description: "Check name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Check search filters and table/column selectors."
        required: false
        schema:
          $ref: "#/definitions/BulkCheckDeactivateParameters"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Checks disabled"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/comments:
    get:
      tags:
      - "Connections"
      summary: "getConnectionComments"
      description: "Return the comments for a connection"
      operationId: "getConnectionComments"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      responses:
        200:
          description: "Connection's comments returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CommentSpec"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Connections"
      summary: "updateConnectionComments"
      description: "Updates (replaces) the list of comments of a connection"
      operationId: "updateConnectionComments"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "List of comments"
        required: false
        schema:
          type: "array"
          items:
            $ref: "#/definitions/CommentSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Connection's comments successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/commoncolumns:
    get:
      tags:
      - "Connections"
      summary: "getConnectionCommonColumns"
      description: "Finds common column names that are used on one or more tables.\
        \ The list of columns is sorted in descending order by column name."
      operationId: "getConnectionCommonColumns"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      responses:
        200:
          description: "List of common columns within a connection returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CommonColumnModel"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/defaultgroupingconfiguration:
    get:
      tags:
      - "Connections"
      summary: "getConnectionDefaultGroupingConfiguration"
      description: "Return the default data grouping configuration for a connection"
      operationId: "getConnectionDefaultGroupingConfiguration"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      responses:
        200:
          description: "Connection's default data grouping configuration returned"
          schema:
            $ref: "#/definitions/DataGroupingConfigurationSpec"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Connections"
      summary: "updateConnectionDefaultGroupingConfiguration"
      description: "Updates the default data grouping connection of a connection"
      operationId: "updateConnectionDefaultGroupingConfiguration"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Default data grouping configuration to be assigned to a connection"
        required: false
        schema:
          $ref: "#/definitions/DataGroupingConfigurationSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Connection's default data grouping configuration successfully\
            \ updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/incidentgrouping:
    get:
      tags:
      - "Connections"
      summary: "getConnectionIncidentGrouping"
      description: "Retrieves the configuration of data quality incident grouping\
        \ and incident notifications"
      operationId: "getConnectionIncidentGrouping"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      responses:
        200:
          description: "Connection's incident grouping configuration returned"
          schema:
            $ref: "#/definitions/ConnectionIncidentGroupingSpec"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Connections"
      summary: "updateConnectionIncidentGrouping"
      description: "Updates (replaces) configuration of incident grouping and notifications\
        \ on a connection (data source) level."
      operationId: "updateConnectionIncidentGrouping"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Incident grouping and notification configuration"
        required: false
        schema:
          $ref: "#/definitions/ConnectionIncidentGroupingSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Connection's incident configuration successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/labels:
    get:
      tags:
      - "Connections"
      summary: "getConnectionLabels"
      description: "Return the labels for a connection"
      operationId: "getConnectionLabels"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      responses:
        200:
          description: "Connection's labels returned"
          schema:
            type: "array"
            items:
              type: "string"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Connections"
      summary: "updateConnectionLabels"
      description: "Updates the list of labels of a connection"
      operationId: "updateConnectionLabels"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "List of labels"
        required: false
        schema:
          type: "array"
          items:
            type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Connection's labels successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schedules/{schedulingGroup}:
    get:
      tags:
      - "Connections"
      summary: "getConnectionSchedulingGroup"
      description: "Return the schedule for a connection for a scheduling group"
      operationId: "getConnectionSchedulingGroup"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schedulingGroup"
        in: "path"
        description: "Check scheduling group (named schedule)"
        required: true
        type: "string"
        enum:
        - "profiling"
        - "monitoring_daily"
        - "monitoring_monthly"
        - "partitioned_daily"
        - "partitioned_monthly"
      responses:
        200:
          description: "Connection's schedule returned"
          schema:
            $ref: "#/definitions/MonitoringScheduleSpec"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Connections"
      summary: "updateConnectionSchedulingGroup"
      description: "Updates the schedule of a connection for a scheduling group (named\
        \ schedule for checks with a similar time series configuration)"
      operationId: "updateConnectionSchedulingGroup"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schedulingGroup"
        in: "path"
        description: "Check scheduling group (named schedule)"
        required: true
        type: "string"
        enum:
        - "profiling"
        - "monitoring_daily"
        - "monitoring_monthly"
        - "partitioned_daily"
        - "partitioned_monthly"
      - in: "body"
        name: "body"
        description: "Monitoring schedule definition to store"
        required: false
        schema:
          $ref: "#/definitions/MonitoringScheduleSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Connection's schedule successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas:
    get:
      tags:
      - "Schemas"
      summary: "getSchemas"
      description: "Returns a list of schemas inside a connection"
      operationId: "getSchemas"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/SchemaModel"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/bulkenable/monitoring/{timeScale}:
    get:
      tags:
      - "Schemas"
      summary: "getSchemaMonitoringChecksTemplates"
      description: "Return available data quality checks on a requested schema."
      operationId: "getSchemaMonitoringChecksTemplates"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "checkTarget"
        in: "query"
        description: "Check target"
        required: false
        type: "string"
        enum:
        - "table"
        - "column"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      responses:
        200:
          description: "Potential data quality checks on a schema returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckTemplate"
        404:
          description: "Connection or schema not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/bulkenable/partitioned/{timeScale}:
    get:
      tags:
      - "Schemas"
      summary: "getSchemaPartitionedChecksTemplates"
      description: "Return available data quality checks on a requested schema."
      operationId: "getSchemaPartitionedChecksTemplates"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "checkTarget"
        in: "query"
        description: "Check target"
        required: false
        type: "string"
        enum:
        - "table"
        - "column"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      responses:
        200:
          description: "Potential data quality checks on a schema returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckTemplate"
        404:
          description: "Connection or schema not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/bulkenable/profiling:
    get:
      tags:
      - "Schemas"
      summary: "getSchemaProfilingChecksTemplates"
      description: "Return available data quality checks on a requested schema."
      operationId: "getSchemaProfilingChecksTemplates"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "checkTarget"
        in: "query"
        description: "Check target"
        required: false
        type: "string"
        enum:
        - "table"
        - "column"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      responses:
        200:
          description: "Potential data quality checks on a schema returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckTemplate"
        404:
          description: "Connection or schema not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/monitoring/{timeScale}/model:
    get:
      tags:
      - "Schemas"
      summary: "getSchemaMonitoringChecksModel"
      description: "Return a UI friendly model of configurations for data quality\
        \ monitoring checks on a schema"
      operationId: "getSchemaMonitoringChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Check time-scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "tableNamePattern"
        in: "query"
        description: "Table name pattern"
        required: false
        type: "string"
      - name: "columnNamePattern"
        in: "query"
        description: "Column name pattern"
        required: false
        type: "string"
      - name: "columnDataType"
        in: "query"
        description: "Column data-type"
        required: false
        type: "string"
      - name: "checkTarget"
        in: "query"
        description: "Check target"
        required: false
        type: "string"
        enum:
        - "table"
        - "column"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "checkEnabled"
        in: "query"
        description: "Check enabled"
        required: false
        type: "boolean"
      - name: "checkConfigured"
        in: "query"
        description: "Check configured"
        required: false
        type: "boolean"
      - name: "limit"
        in: "query"
        description: "Limit of results, the default value is 1000"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Configuration of data quality monitoring checks on a schema\
            \ returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckConfigurationModel"
        404:
          description: "Connection or schema not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/partitioned/{timeScale}/model:
    get:
      tags:
      - "Schemas"
      summary: "getSchemaPartitionedChecksModel"
      description: "Return a UI friendly model of configurations for data quality\
        \ partitioned checks on a schema"
      operationId: "getSchemaPartitionedChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Check time-scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "tableNamePattern"
        in: "query"
        description: "Table name pattern"
        required: false
        type: "string"
      - name: "columnNamePattern"
        in: "query"
        description: "Column name pattern"
        required: false
        type: "string"
      - name: "columnDataType"
        in: "query"
        description: "Column data-type"
        required: false
        type: "string"
      - name: "checkTarget"
        in: "query"
        description: "Check target"
        required: false
        type: "string"
        enum:
        - "table"
        - "column"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "checkEnabled"
        in: "query"
        description: "Check enabled"
        required: false
        type: "boolean"
      - name: "checkConfigured"
        in: "query"
        description: "Check configured"
        required: false
        type: "boolean"
      - name: "limit"
        in: "query"
        description: "Limit of results, the default value is 1000"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Configuration of data quality partitioned checks on a schema\
            \ returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckConfigurationModel"
        404:
          description: "Connection or schema not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/profiling/model:
    get:
      tags:
      - "Schemas"
      summary: "getSchemaProfilingChecksModel"
      description: "Return a flat list of configurations for profiling checks on a\
        \ schema"
      operationId: "getSchemaProfilingChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableNamePattern"
        in: "query"
        description: "Table name pattern"
        required: false
        type: "string"
      - name: "columnNamePattern"
        in: "query"
        description: "Column name pattern"
        required: false
        type: "string"
      - name: "columnDataType"
        in: "query"
        description: "Column data-type"
        required: false
        type: "string"
      - name: "checkTarget"
        in: "query"
        description: "Check target"
        required: false
        type: "string"
        enum:
        - "table"
        - "column"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "checkEnabled"
        in: "query"
        description: "Check enabled"
        required: false
        type: "boolean"
      - name: "checkConfigured"
        in: "query"
        description: "Check configured"
        required: false
        type: "boolean"
      - name: "limit"
        in: "query"
        description: "Limit of results, the default value is 1000"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "List of profiling checks configurations on a schema returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckConfigurationModel"
        404:
          description: "Connection or schema not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables:
    get:
      tags:
      - "Tables"
      summary: "getTables"
      description: "Returns a list of tables inside a connection/schema"
      operationId: "getTables"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "label"
        in: "query"
        description: "Optional labels to filter the tables"
        required: false
        type: "array"
        items:
          type: "string"
        collectionFormat: "multi"
      - name: "page"
        in: "query"
        description: "Page number, the first page is 1"
        required: false
        type: "integer"
        format: "int32"
      - name: "limit"
        in: "query"
        description: "Page size, the default is 100 rows, but paging is disabled is\
          \ neither page and limit parameters are provided"
        required: false
        type: "integer"
        format: "int32"
      - name: "filter"
        in: "query"
        description: "Optional table name filter"
        required: false
        type: "string"
      - name: "checkType"
        in: "query"
        description: "Optional parameter for the check type, when provided, returns\
          \ the results for data quality dimensions for the data quality checks of\
          \ that type"
        required: false
        type: "string"
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/TableListModel"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}:
    get:
      tags:
      - "Tables"
      summary: "getTable"
      description: "Return the table specification"
      operationId: "getTable"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Table full specification returned"
          schema:
            $ref: "#/definitions/TableModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "Tables"
      summary: "createTable"
      description: "Creates a new table (adds a table metadata)"
      operationId: "createTable"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table specification"
        required: false
        schema:
          $ref: "#/definitions/TableSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New table successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Table with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTable"
      description: "Updates an existing table specification, changing all the fields"
      operationId: "updateTable"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Full table specification"
        required: false
        schema:
          $ref: "#/definitions/TableSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "Tables"
      summary: "deleteTable"
      description: "Deletes a table"
      operationId: "deleteTable"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Table successfully deleted"
          schema:
            $ref: "#/definitions/DqoQueueJobId"
        404:
          description: "Table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/basic:
    get:
      tags:
      - "Tables"
      summary: "getTableBasic"
      description: "Return the basic table information"
      operationId: "getTableBasic"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Table basic information returned"
          schema:
            $ref: "#/definitions/TableListModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTableBasic"
      description: "Updates the basic field of an existing table, changing only the\
        \ most important fields."
      operationId: "updateTableBasic"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table basic model with the updated settings"
        required: false
        schema:
          $ref: "#/definitions/TableListModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/bulkenable/monitoring/{timeScale}:
    get:
      tags:
      - "Tables"
      summary: "getTableMonitoringChecksTemplates"
      description: "Return available data quality checks on a requested table."
      operationId: "getTableMonitoringChecksTemplates"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      responses:
        200:
          description: "Potential data quality checks on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckTemplate"
        404:
          description: "Connection, schema or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/bulkenable/partitioned/{timeScale}:
    get:
      tags:
      - "Tables"
      summary: "getTablePartitionedChecksTemplates"
      description: "Return available data quality checks on a requested table."
      operationId: "getTablePartitionedChecksTemplates"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      responses:
        200:
          description: "Potential data quality checks on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckTemplate"
        404:
          description: "Connection, schema or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/bulkenable/profiling:
    get:
      tags:
      - "Tables"
      summary: "getTableProfilingChecksTemplates"
      description: "Return available data quality checks on a requested table."
      operationId: "getTableProfilingChecksTemplates"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      responses:
        200:
          description: "Potential data quality checks on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckTemplate"
        404:
          description: "Connection, schema or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columnchecks/monitoring/{timeScale}/model:
    get:
      tags:
      - "Tables"
      summary: "getTableColumnsMonitoringChecksModel"
      description: "Return a UI friendly model of configurations for column-level\
        \ data quality monitoring checks on a table"
      operationId: "getTableColumnsMonitoringChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Check time-scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "columnNamePattern"
        in: "query"
        description: "Column name pattern"
        required: false
        type: "string"
      - name: "columnDataType"
        in: "query"
        description: "Column data-type"
        required: false
        type: "string"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "checkEnabled"
        in: "query"
        description: "Check enabled"
        required: false
        type: "boolean"
      - name: "checkConfigured"
        in: "query"
        description: "Check configured"
        required: false
        type: "boolean"
      - name: "limit"
        in: "query"
        description: "Limit of results, the default value is 1000"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Configuration of data quality monitoring checks on a schema\
            \ returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckConfigurationModel"
        404:
          description: "Connection, schema or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columnchecks/partitioned/{timeScale}/model:
    get:
      tags:
      - "Tables"
      summary: "getTableColumnsPartitionedChecksModel"
      description: "Return a UI friendly model of configurations for column-level\
        \ data quality partitioned checks on a table"
      operationId: "getTableColumnsPartitionedChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Check time-scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "columnNamePattern"
        in: "query"
        description: "Column name pattern"
        required: false
        type: "string"
      - name: "columnDataType"
        in: "query"
        description: "Column data-type"
        required: false
        type: "string"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "checkEnabled"
        in: "query"
        description: "Check enabled"
        required: false
        type: "boolean"
      - name: "checkConfigured"
        in: "query"
        description: "Check configured"
        required: false
        type: "boolean"
      - name: "limit"
        in: "query"
        description: "Limit of results, the default value is 1000"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Configuration of data quality partitioned checks on a schema\
            \ returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckConfigurationModel"
        404:
          description: "Connection, schema or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columnchecks/profiling/model:
    get:
      tags:
      - "Tables"
      summary: "getTableColumnsProfilingChecksModel"
      description: "Return a UI friendly model of configurations for column-level\
        \ data quality profiling checks on a table"
      operationId: "getTableColumnsProfilingChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnNamePattern"
        in: "query"
        description: "Column name pattern"
        required: false
        type: "string"
      - name: "columnDataType"
        in: "query"
        description: "Column data-type"
        required: false
        type: "string"
      - name: "checkCategory"
        in: "query"
        description: "Check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "checkEnabled"
        in: "query"
        description: "Check enabled"
        required: false
        type: "boolean"
      - name: "checkConfigured"
        in: "query"
        description: "Check configured"
        required: false
        type: "boolean"
      - name: "limit"
        in: "query"
        description: "Limit of results, the default value is 1000"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Configuration of data quality profiling checks on a schema\
            \ returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckConfigurationModel"
        404:
          description: "Connection, schema or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns:
    get:
      tags:
      - "Columns"
      summary: "getColumns"
      description: "Returns a list of columns inside a table"
      operationId: "getColumns"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "dataQualityStatus"
        in: "query"
        description: "Optional parameter to opt out from retrieving the most recent\
          \ data quality status for the column. By default, DQOps calculates the data\
          \ quality status from the data quality results."
        required: false
        type: "boolean"
      - name: "checkType"
        in: "query"
        description: "Optional parameter for the check type, when provided, returns\
          \ the results for data quality dimensions for the data quality checks of\
          \ that type"
        required: false
        type: "string"
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/ColumnListModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/statistics:
    get:
      tags:
      - "Columns"
      summary: "getColumnsStatistics"
      description: "Returns a list of columns inside a table with the metrics captured\
        \ by the most recent statistics collection."
      operationId: "getColumnsStatistics"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/TableColumnsStatisticsModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}:
    get:
      tags:
      - "Columns"
      summary: "getColumn"
      description: "Returns the full column specification"
      operationId: "getColumn"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "Column returned"
          schema:
            $ref: "#/definitions/ColumnModel"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "Columns"
      summary: "createColumn"
      description: "Creates a new column (adds a column metadata to the table)"
      operationId: "createColumn"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Column specification"
        required: false
        schema:
          $ref: "#/definitions/ColumnSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New column successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Column with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumn"
      description: "Updates an existing column specification, changing all the fields\
        \ (even the column level data quality checks)."
      operationId: "updateColumn"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Column specification"
        required: false
        schema:
          $ref: "#/definitions/ColumnSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Column successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "Columns"
      summary: "deleteColumn"
      description: "Deletes a column from the table"
      operationId: "deleteColumn"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "Column successfully deleted"
          schema:
            $ref: "#/definitions/DqoQueueJobId"
        404:
          description: "Column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/basic:
    get:
      tags:
      - "Columns"
      summary: "getColumnBasic"
      description: "Returns the column specification"
      operationId: "getColumnBasic"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "Column basic details returned"
          schema:
            $ref: "#/definitions/ColumnListModel"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumnBasic"
      description: "Updates an existing column, changing only the basic information\
        \ like the expected data type (the data type snapshot)."
      operationId: "updateColumnBasic"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Basic column information to store"
        required: false
        schema:
          $ref: "#/definitions/ColumnListModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Column basic information successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/comments:
    get:
      tags:
      - "Columns"
      summary: "getColumnComments"
      description: "Return the list of comments assigned to a column"
      operationId: "getColumnComments"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "List of comments assigned to a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CommentSpec"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumnComments"
      description: "Updates the list of comments assigned to a column."
      operationId: "updateColumnComments"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "List of comments to stored (replaced) on the column or an empty\
          \ object to clear the list of assigned comments on the column"
        required: false
        schema:
          type: "array"
          items:
            $ref: "#/definitions/CommentSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Column's list of comments successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/labels:
    get:
      tags:
      - "Columns"
      summary: "getColumnLabels"
      description: "Return the list of labels assigned to a column"
      operationId: "getColumnLabels"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "List of labels assigned to a column returned"
          schema:
            type: "array"
            items:
              type: "string"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumnLabels"
      description: "Updates the list of labels assigned to a column."
      operationId: "updateColumnLabels"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "List of labels to stored (replaced) on the column or an empty\
          \ object to clear the list of assigned labels on the column"
        required: false
        schema:
          type: "array"
          items:
            type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Column's list of labels successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/monitoring/daily:
    get:
      tags:
      - "Columns"
      summary: "getColumnMonitoringChecksDaily"
      description: "Return the configuration of daily column level data quality monitoring\
        \ on a column"
      operationId: "getColumnMonitoringChecksDaily"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of daily column level data quality monitoring\
            \ on a column returned"
          schema:
            $ref: "#/definitions/ColumnDailyMonitoringCheckCategoriesSpec"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumnMonitoringChecksDaily"
      description: "Updates configuration of daily column level data quality monitoring\
        \ on a column."
      operationId: "updateColumnMonitoringChecksDaily"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Configuration of daily column level data quality monitoring\
          \ to configure on a column or an empty object to clear the list of assigned\
          \ daily data quality monitoring on the column"
        required: false
        schema:
          $ref: "#/definitions/ColumnDailyMonitoringCheckCategoriesSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Daily column level data quality monitoring successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/monitoring/monthly:
    get:
      tags:
      - "Columns"
      summary: "getColumnMonitoringChecksMonthly"
      description: "Return the configuration of monthly column level data quality\
        \ monitoring on a column"
      operationId: "getColumnMonitoringChecksMonthly"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of monthly column level data quality monitoring\
            \ on a column returned"
          schema:
            $ref: "#/definitions/ColumnMonthlyMonitoringCheckCategoriesSpec"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumnMonitoringChecksMonthly"
      description: "Updates configuration of monthly column level data quality monitoring\
        \ checks on a column."
      operationId: "updateColumnMonitoringChecksMonthly"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Configuration of monthly column level data quality monitoring\
          \ to configure on a column or an empty object to clear the list of assigned\
          \ monthly data quality monitoring on the column"
        required: false
        schema:
          $ref: "#/definitions/ColumnMonthlyMonitoringCheckCategoriesSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Monthly column level data quality monitoring checks successfully\
            \ updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/monitoring/{timeScale}/errors:
    get:
      tags:
      - "Errors"
      summary: "getColumnMonitoringErrors"
      description: "Returns errors related to the recent column level monitoring executions\
        \ for the monitoring at a requested time scale"
      operationId: "getColumnMonitoringErrors"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "View of errors for the monitoring at a requested time scale\
            \ on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/ErrorsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/monitoring/{timeScale}/model:
    get:
      tags:
      - "Columns"
      summary: "getColumnMonitoringChecksModel"
      description: "Return a UI friendly model of column level data quality monitoring\
        \ on a column"
      operationId: "getColumnMonitoringChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      responses:
        200:
          description: "Model of column level data quality monitoring on a column\
            \ returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection, table or column not found, or invalid time scale"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumnMonitoringChecksModel"
      description: "Updates configuration of column level data quality monitoring\
        \ on a column, for a given time scale, from a UI friendly model."
      operationId: "updateColumnMonitoringChecksModel"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality monitoring\
          \ configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Column level data quality monitoring successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table or column not found, or invalid time scale"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/monitoring/{timeScale}/model/basic
  : get:
      tags:
      - "Columns"
      summary: "getColumnMonitoringChecksBasicModel"
      description: "Return a simplistic UI friendly model of column level data quality\
        \ monitoring on a column"
      operationId: "getColumnMonitoringChecksBasicModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      responses:
        200:
          description: "Simplistic model of column level data quality monitoring on\
            \ a column returned"
          schema:
            $ref: "#/definitions/CheckContainerListModel"
        404:
          description: "Connection, table or column not found, or invalid time scale"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/monitoring/{timeScale}/model/filter/{checkCategory}/{checkName}
  : get:
      tags:
      - "Columns"
      summary: "getColumnMonitoringChecksModelFilter"
      description: "Return a UI friendly model of column level data quality monitoring\
        \ on a column filtered by category and check name"
      operationId: "getColumnMonitoringChecksModelFilter"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "checkCategory"
        in: "path"
        description: "Check category"
        required: true
        type: "string"
      - name: "checkName"
        in: "path"
        description: "Check name"
        required: true
        type: "string"
      responses:
        200:
          description: "Model of column level data quality monitoring on a column\
            \ returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection, table or column not found, or invalid time scale"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/monitoring/{timeScale}/overview:
    get:
      tags:
      - "CheckResultsOverview"
      summary: "getColumnMonitoringChecksOverview"
      description: "Returns an overview of the most recent column level monitoring\
        \ executions for the monitoring at a requested time scale"
      operationId: "getColumnMonitoringChecksOverview"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "category"
        in: "query"
        description: "Optional check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Optional check name"
        required: false
        type: "string"
      responses:
        200:
          description: "An overview of the most recent monitoring executions for the\
            \ monitoring at a requested time scale on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsOverviewDataModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/monitoring/{timeScale}/readouts:
    get:
      tags:
      - "SensorReadouts"
      summary: "getColumnMonitoringSensorReadouts"
      description: "Returns a complete view of the sensor readouts for recent column\
        \ level monitoring executions for the monitoring at a requested time scale"
      operationId: "getColumnMonitoringSensorReadouts"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "View of the sensor readouts of recent monitoring executions\
            \ for the monitoring at a requested time scale on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/SensorReadoutsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/monitoring/{timeScale}/results:
    get:
      tags:
      - "CheckResults"
      summary: "getColumnMonitoringChecksResults"
      description: "Returns a complete view of the recent column level monitoring\
        \ executions for the monitoring at a requested time scale"
      operationId: "getColumnMonitoringChecksResults"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "View of the recent monitoring executions for the monitoring\
            \ at a requested time scale on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/partitioned/daily:
    get:
      tags:
      - "Columns"
      summary: "getColumnPartitionedChecksDaily"
      description: "Return the configuration of daily column level data quality partitioned\
        \ checks on a column"
      operationId: "getColumnPartitionedChecksDaily"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of daily column level data quality partitioned\
            \ checks on a column returned"
          schema:
            $ref: "#/definitions/ColumnDailyPartitionedCheckCategoriesSpec"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumnPartitionedChecksDaily"
      description: "Updates configuration of daily column level data quality partitioned\
        \ checks on a column."
      operationId: "updateColumnPartitionedChecksDaily"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Configuration of daily column level data quality partitioned\
          \ checks to configure on a column or an empty object to clear the list of\
          \ assigned data quality partitioned checks on the column"
        required: false
        schema:
          $ref: "#/definitions/ColumnDailyPartitionedCheckCategoriesSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Daily column level data quality partitioned checks successfully\
            \ updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/partitioned/monthly:
    get:
      tags:
      - "Columns"
      summary: "getColumnPartitionedChecksMonthly"
      description: "Return the configuration of monthly column level data quality\
        \ partitioned checks on a column"
      operationId: "getColumnPartitionedChecksMonthly"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of monthly column level data quality partitioned\
            \ checks on a column returned"
          schema:
            $ref: "#/definitions/ColumnMonthlyPartitionedCheckCategoriesSpec"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumnPartitionedChecksMonthly"
      description: "Updates configuration of monthly column level data quality partitioned\
        \ checks on a column."
      operationId: "updateColumnPartitionedChecksMonthly"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Configuration of monthly column level data quality partitioned\
          \ checks to configure on a column or an empty object to clear the list of\
          \ assigned data quality partitioned checks on the column"
        required: false
        schema:
          $ref: "#/definitions/ColumnMonthlyPartitionedCheckCategoriesSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Monthly column level data quality partitioned checks successfully\
            \ updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/partitioned/{timeScale}/errors:
    get:
      tags:
      - "Errors"
      summary: "getColumnPartitionedErrors"
      description: "Returns the errors related to the recent column level partitioned\
        \ checks executions for a requested time scale"
      operationId: "getColumnPartitionedErrors"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "View of errors related to the recent partitioned check executions\
            \ for a requested time scale on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/ErrorsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/partitioned/{timeScale}/model:
    get:
      tags:
      - "Columns"
      summary: "getColumnPartitionedChecksModel"
      description: "Return a UI friendly model of column level data quality partitioned\
        \ checks on a column"
      operationId: "getColumnPartitionedChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      responses:
        200:
          description: "Model of column level data quality partitioned checks on a\
            \ column returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection, table or column not found, or invalid time scale"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumnPartitionedChecksModel"
      description: "Updates configuration of column level data quality partitioned\
        \ checks on a column, for a given time scale, from a UI friendly model."
      operationId: "updateColumnPartitionedChecksModel"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality partitioned\
          \ checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Column level data quality partitioned checks successfully\
            \ updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table or column not found, or invalid time scale"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/partitioned/{timeScale}/model/basic
  : get:
      tags:
      - "Columns"
      summary: "getColumnPartitionedChecksBasicModel"
      description: "Return a simplistic UI friendly model of column level data quality\
        \ partitioned checks on a column"
      operationId: "getColumnPartitionedChecksBasicModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      responses:
        200:
          description: "Simplistic model of column level data quality partitioned\
            \ checks on a column returned"
          schema:
            $ref: "#/definitions/CheckContainerListModel"
        404:
          description: "Connection, table or column not found, or invalid time scale"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/partitioned/{timeScale}/model/filter/{checkCategory}/{checkName}
  : get:
      tags:
      - "Columns"
      summary: "getColumnPartitionedChecksModelFilter"
      description: "Return a UI friendly model of column level data quality partitioned\
        \ checks on a column, filtered by category and check name"
      operationId: "getColumnPartitionedChecksModelFilter"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "checkCategory"
        in: "path"
        description: "Check category"
        required: true
        type: "string"
      - name: "checkName"
        in: "path"
        description: "Check name"
        required: true
        type: "string"
      responses:
        200:
          description: "Model of column level data quality partitioned checks on a\
            \ column returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection, table or column not found, or invalid time scale"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/partitioned/{timeScale}/overview:
    get:
      tags:
      - "CheckResultsOverview"
      summary: "getColumnPartitionedChecksOverview"
      description: "Returns an overview of the most recent column level partitioned\
        \ checks executions for a requested time scale"
      operationId: "getColumnPartitionedChecksOverview"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "category"
        in: "query"
        description: "Optional check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Optional check name"
        required: false
        type: "string"
      responses:
        200:
          description: "An overview of the most recent partitioned check executions\
            \ for a requested time scale on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsOverviewDataModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/partitioned/{timeScale}/readouts:
    get:
      tags:
      - "SensorReadouts"
      summary: "getColumnPartitionedSensorReadouts"
      description: "Returns a view of the sensor readouts for recent column level\
        \ partitioned checks executions for a requested time scale"
      operationId: "getColumnPartitionedSensorReadouts"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "View of the sensor readouts for recent partitioned check executions\
            \ for a requested time scale on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/SensorReadoutsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/partitioned/{timeScale}/results:
    get:
      tags:
      - "CheckResults"
      summary: "getColumnPartitionedChecksResults"
      description: "Returns an overview of the most recent column level partitioned\
        \ checks executions for a requested time scale"
      operationId: "getColumnPartitionedChecksResults"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "View of the recent partitioned check executions for a requested\
            \ time scale on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/profiling:
    get:
      tags:
      - "Columns"
      summary: "getColumnProfilingChecks"
      description: "Return the configuration of column level data quality profiling\
        \ checks on a column"
      operationId: "getColumnProfilingChecks"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of column level data quality profiling checks\
            \ on a column returned"
          schema:
            $ref: "#/definitions/ColumnProfilingCheckCategoriesSpec"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumnProfilingChecks"
      description: "Updates configuration of column level data quality profiling checks\
        \ on a column."
      operationId: "updateColumnProfilingChecks"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Configuration of column level data quality profiling checks\
          \ to configure on a column or an empty object to clear the list of assigned\
          \ data quality profiling checks on the column"
        required: false
        schema:
          $ref: "#/definitions/ColumnProfilingCheckCategoriesSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Column level data quality profiling checks successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/profiling/errors:
    get:
      tags:
      - "Errors"
      summary: "getColumnProfilingErrors"
      description: "Returns the errors related to the recent check executions for\
        \ all column level data quality profiling checks on a column"
      operationId: "getColumnProfilingErrors"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Errors related to the most recent check runs for column level\
            \ data quality profiling checks on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/ErrorsListModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/profiling/model:
    get:
      tags:
      - "Columns"
      summary: "getColumnProfilingChecksModel"
      description: "Return a UI friendly model of data quality profiling checks on\
        \ a column"
      operationId: "getColumnProfilingChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "Model of column level data quality profiling checks on a column\
            \ returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Columns"
      summary: "updateColumnProfilingChecksModel"
      description: "Updates configuration of column level data quality profiling checks\
        \ on a column from a UI friendly model."
      operationId: "updateColumnProfilingChecksModel"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality profiling\
          \ checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Column level data quality profiling checks successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table or column not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/profiling/model/basic:
    get:
      tags:
      - "Columns"
      summary: "getColumnProfilingChecksBasicModel"
      description: "Return a simplistic UI friendly model of column level data quality\
        \ profiling checks on a column"
      operationId: "getColumnProfilingChecksBasicModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "Simplistic model of column level data quality profiling checks\
            \ on a column returned"
          schema:
            $ref: "#/definitions/CheckContainerListModel"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/profiling/model/filter/{checkCategory}/{checkName}
  : get:
      tags:
      - "Columns"
      summary: "getColumnProfilingChecksModelFilter"
      description: "Return a UI friendly model of data quality profiling checks on\
        \ a column filtered by category and check name"
      operationId: "getColumnProfilingChecksModelFilter"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "checkCategory"
        in: "path"
        description: "Check category"
        required: true
        type: "string"
      - name: "checkName"
        in: "path"
        description: "Check name"
        required: true
        type: "string"
      responses:
        200:
          description: "Model of column level data quality profiling checks on a column\
            \ returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/profiling/overview:
    get:
      tags:
      - "CheckResultsOverview"
      summary: "getColumnProfilingChecksOverview"
      description: "Returns an overview of the most recent check executions for all\
        \ column level data quality profiling checks on a column"
      operationId: "getColumnProfilingChecksOverview"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "category"
        in: "query"
        description: "Optional check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Optional check name"
        required: false
        type: "string"
      responses:
        200:
          description: "Overview of the most recent check runs for column level data\
            \ quality profiling checks on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsOverviewDataModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/profiling/readouts:
    get:
      tags:
      - "SensorReadouts"
      summary: "getColumnProfilingSensorReadouts"
      description: "Returns sensor results of the recent check executions for all\
        \ column level data quality profiling checks on a column"
      operationId: "getColumnProfilingSensorReadouts"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Complete view sensor readouts of recent check runs for column\
            \ level data quality profiling checks on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/SensorReadoutsListModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/profiling/results:
    get:
      tags:
      - "CheckResults"
      summary: "getColumnProfilingChecksResults"
      description: "Returns an overview of the most recent check executions for all\
        \ column level data quality profiling checks on a column"
      operationId: "getColumnProfilingChecksResults"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Complete view of the most recent check runs for column level\
            \ data quality profiling checks on a column returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsListModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/columns/{columnName}/statistics:
    get:
      tags:
      - "Columns"
      summary: "getColumnStatistics"
      description: "Returns the column specification with the metrics captured by\
        \ the most recent statistics collection."
      operationId: "getColumnStatistics"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "columnName"
        in: "path"
        description: "Column name"
        required: true
        type: "string"
      responses:
        200:
          description: "Column statistics returned"
          schema:
            $ref: "#/definitions/ColumnStatisticsModel"
        404:
          description: "Connection, table or column not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/comments:
    get:
      tags:
      - "Tables"
      summary: "getTableComments"
      description: "Return the list of comments added to a table"
      operationId: "getTableComments"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "List of comments on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CommentSpec"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTableComments"
      description: "Updates the list of comments on an existing table."
      operationId: "updateTableComments"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "List of comments to attach (replace) on a table or an empty\
          \ object to clear the list of comments on a table"
        required: false
        schema:
          type: "array"
          items:
            $ref: "#/definitions/CommentSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table's comments successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/defaultgroupingconfiguration:
    get:
      tags:
      - "Tables"
      summary: "getTableDefaultGroupingConfiguration"
      description: "Return the default data grouping configuration for a table."
      operationId: "getTableDefaultGroupingConfiguration"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Default data grouping configuration for a table returned"
          schema:
            $ref: "#/definitions/DataGroupingConfigurationSpec"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTableDefaultGroupingConfiguration"
      description: "Updates the default data grouping configuration at a table level."
      operationId: "updateTableDefaultGroupingConfiguration"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Default data grouping configuration to store or an empty object\
          \ to clear the data grouping configuration on a table level"
        required: false
        schema:
          $ref: "#/definitions/DataGroupingConfigurationSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table's default data grouping configuration successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/groupings:
    get:
      tags:
      - "DataGroupingConfigurations"
      summary: "getTableGroupingConfigurations"
      description: "Returns the list of data grouping configurations on a table"
      operationId: "getTableGroupingConfigurations"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/DataGroupingConfigurationListModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "DataGroupingConfigurations"
      summary: "createTableGroupingConfiguration"
      description: "Creates a new data grouping configuration on a table level"
      operationId: "createTableGroupingConfiguration"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Data grouping configuration simplified model"
        required: false
        schema:
          $ref: "#/definitions/DataGroupingConfigurationTrimmedModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New data grouping configuration successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Data grouping configuration with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/groupings/setdefault:
    patch:
      tags:
      - "DataGroupingConfigurations"
      summary: "setTableDefaultGroupingConfiguration"
      description: "Sets a table's grouping configuration as the default or disables\
        \ data grouping"
      operationId: "setTableDefaultGroupingConfiguration"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "dataGroupingConfigurationName"
        in: "query"
        description: "Data grouping configuration name or empty to disable data grouping"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Data grouping configuration successfully set as the default\
            \ for the table"
        404:
          description: "Connection, table or data grouping configuration not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/groupings/{dataGroupingConfigurationName}:
    put:
      tags:
      - "DataGroupingConfigurations"
      summary: "updateTableGroupingConfiguration"
      description: "Updates a data grouping configuration according to the provided\
        \ model"
      operationId: "updateTableGroupingConfiguration"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "dataGroupingConfigurationName"
        in: "path"
        description: "Data grouping configuration name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Data grouping configuration simplified model"
        required: false
        schema:
          $ref: "#/definitions/DataGroupingConfigurationTrimmedModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Data grouping configuration successfully updated"
        404:
          description: "Connection, table or data grouping not found"
        406:
          description: "Incorrect request"
        409:
          description: "Data grouping configuration with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "DataGroupingConfigurations"
      summary: "deleteTableGroupingConfiguration"
      description: "Deletes a data grouping configuration from a table"
      operationId: "deleteTableGroupingConfiguration"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "dataGroupingConfigurationName"
        in: "path"
        description: "Data grouping configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Data grouping configuration removed"
        404:
          description: "Connection or table not found"
        406:
          description: "Invalid request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/groupings/{groupingConfigurationName}:
    get:
      tags:
      - "DataGroupingConfigurations"
      summary: "getTableGroupingConfiguration"
      description: "Returns a model of the data grouping configuration"
      operationId: "getTableGroupingConfiguration"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "groupingConfigurationName"
        in: "path"
        description: "Data grouping configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/DataGroupingConfigurationModel"
        404:
          description: "Connection, table or data grouping not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/incidentgrouping:
    get:
      tags:
      - "Tables"
      summary: "getTableIncidentGrouping"
      description: "Return the configuration of incident grouping on a table"
      operationId: "getTableIncidentGrouping"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Table's incident grouping configuration returned"
          schema:
            $ref: "#/definitions/TableIncidentGroupingSpec"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTableIncidentGrouping"
      description: "Updates the configuration of incident grouping on a table."
      operationId: "updateTableIncidentGrouping"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "New configuration of the table's incident grouping"
        required: false
        schema:
          $ref: "#/definitions/TableIncidentGroupingSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table's incident grouping configuration successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/labels:
    get:
      tags:
      - "Tables"
      summary: "getTableLabels"
      description: "Return the list of labels assigned to a table"
      operationId: "getTableLabels"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "List of labels on a table returned"
          schema:
            type: "array"
            items:
              type: "string"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTableLabels"
      description: "Updates the list of assigned labels of an existing table."
      operationId: "updateTableLabels"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "List of labels to attach (replace) on a table or an empty object\
          \ to clear the list of labels on a table"
        required: false
        schema:
          type: "array"
          items:
            type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table's labels successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/monitoring/daily:
    get:
      tags:
      - "Tables"
      summary: "getTableMonitoringChecksDaily"
      description: "Return the configuration of daily table level data quality monitoring\
        \ on a table"
      operationId: "getTableDailyMonitoringChecks"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of daily table level data quality monitoring\
            \ on a table returned"
          schema:
            $ref: "#/definitions/TableDailyMonitoringCheckCategoriesSpec"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTableMonitoringChecksDaily"
      description: "Updates the list of daily table level data quality monitoring\
        \ on an existing table."
      operationId: "updateTableDailyMonitoringChecks"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Configuration of daily table level data quality monitoring to\
          \ store or an empty object to remove all data quality monitoring on the\
          \ table level (column level monitoring are preserved)."
        required: false
        schema:
          $ref: "#/definitions/TableDailyMonitoringCheckCategoriesSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Daily table level data quality monitoring successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/monitoring/monthly:
    get:
      tags:
      - "Tables"
      summary: "getTableMonitoringChecksMonthly"
      description: "Return the configuration of monthly table level data quality monitoring\
        \ on a table"
      operationId: "getTableMonitoringChecksMonthly"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of monthly table level data quality monitoring\
            \ on a table returned"
          schema:
            $ref: "#/definitions/TableMonthlyMonitoringCheckCategoriesSpec"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTableMonitoringChecksMonthly"
      description: "Updates the list of monthly table level data quality monitoring\
        \ on an existing table."
      operationId: "updateTableMonitoringChecksMonthly"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Configuration of monthly table level data quality monitoring\
          \ to store or an empty object to remove all data quality monitoring on the\
          \ table level (column level monitoring are preserved)."
        required: false
        schema:
          $ref: "#/definitions/TableMonthlyMonitoringCheckCategoriesSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Monthly table level data quality monitoring successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/monitoring/{timeScale}/comparisons/{tableComparisonConfigurationName}/results
  : get:
      tags:
      - "TableComparisonResults"
      summary: "getTableComparisonMonitoringResults"
      description: "Retrieves the results of the most table comparison performed using\
        \ the monitoring comparison checks."
      operationId: "getTableComparisonMonitoringResults"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "The results of the most recent table comparison using the\
            \ monitoring checks on a table returned"
          schema:
            $ref: "#/definitions/TableComparisonResultsModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/monitoring/{timeScale}/errors:
    get:
      tags:
      - "Errors"
      summary: "getTableMonitoringErrors"
      description: "Returns the errors related to the most recent table level monitoring\
        \ executions for the monitoring at a requested time scale"
      operationId: "getTableMonitoringErrors"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Errors related to the most recent monitoring executions for\
            \ the monitoring at a requested time scale on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/ErrorsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/monitoring/{timeScale}/model:
    get:
      tags:
      - "Tables"
      summary: "getTableMonitoringChecksModel"
      description: "Return a UI friendly model of configurations for table level data\
        \ quality monitoring on a table for a given time scale"
      operationId: "getTableMonitoringChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      responses:
        200:
          description: "Configuration of table level {timeScale} data quality monitoring\
            \ on a table returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTableMonitoringChecksModel"
      description: "Updates the data quality monitoring from a model that contains\
        \ a patch with changes."
      operationId: "updateTableMonitoringChecksModel"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality monitoring\
          \ configuration."
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table level data quality monitoring successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found or invalid time scale"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/monitoring/{timeScale}/model/basic:
    get:
      tags:
      - "Tables"
      summary: "getTableMonitoringChecksBasicModel"
      description: "Return a simplistic UI friendly model of table level data quality\
        \ monitoring on a table for a given time scale"
      operationId: "getTableMonitoringChecksBasicModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      responses:
        200:
          description: "List of table level {timeScale} data quality monitoring on\
            \ a table returned"
          schema:
            $ref: "#/definitions/CheckContainerListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/monitoring/{timeScale}/model/filter/{checkCategory}/{checkName}
  : get:
      tags:
      - "Tables"
      summary: "getTableMonitoringChecksModelFilter"
      description: "Return a UI friendly model of configurations for table level data\
        \ quality monitoring on a table for a given time scale, filtered by category\
        \ and check name."
      operationId: "getTableMonitoringChecksModelFilter"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "checkCategory"
        in: "path"
        description: "Check category"
        required: true
        type: "string"
      - name: "checkName"
        in: "path"
        description: "Check name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of table level {timeScale} data quality monitoring\
            \ on a table returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/monitoring/{timeScale}/overview:
    get:
      tags:
      - "CheckResultsOverview"
      summary: "getTableMonitoringChecksOverview"
      description: "Returns an overview of the most recent table level monitoring\
        \ executions for the monitoring at a requested time scale"
      operationId: "getTableMonitoringChecksOverview"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "category"
        in: "query"
        description: "Optional check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Optional check name"
        required: false
        type: "string"
      responses:
        200:
          description: "An overview of the most recent monitoring executions for the\
            \ monitoring at a requested time scale on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsOverviewDataModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/monitoring/{timeScale}/readouts:
    get:
      tags:
      - "SensorReadouts"
      summary: "getTableMonitoringSensorReadouts"
      description: "Returns the complete results of the most recent table level monitoring\
        \ executions for the monitoring at a requested time scale"
      operationId: "getTableMonitoringSensorReadouts"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Complete view of the most recent monitoring executions for\
            \ the monitoring at a requested time scale on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/SensorReadoutsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/monitoring/{timeScale}/results:
    get:
      tags:
      - "CheckResults"
      summary: "getTableMonitoringChecksResults"
      description: "Returns the complete results of the most recent table level monitoring\
        \ executions for the monitoring at a requested time scale"
      operationId: "getTableMonitoringChecksResults"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Complete view of the most recent monitoring executions for\
            \ the monitoring at a requested time scale on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/partitioned/daily:
    get:
      tags:
      - "Tables"
      summary: "getTablePartitionedChecksDaily"
      description: "Return the configuration of daily table level data quality partitioned\
        \ checks on a table"
      operationId: "getTableDailyPartitionedChecks"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of table level data quality partitioned checks\
            \ on a table returned"
          schema:
            $ref: "#/definitions/TableDailyPartitionedCheckCategoriesSpec"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTablePartitionedChecksDaily"
      description: "Updates the list of daily table level data quality partitioned\
        \ checks on an existing table."
      operationId: "updateTablePartitionedChecksDaily"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Configuration of daily table level data quality partitioned\
          \ checks to store or an empty object to remove all data quality partitioned\
          \ checks on the table level (column level partitioned checks are preserved)."
        required: false
        schema:
          $ref: "#/definitions/TableDailyPartitionedCheckCategoriesSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Daily table level data quality monitoring successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/partitioned/monthly:
    get:
      tags:
      - "Tables"
      summary: "getTablePartitionedChecksMonthly"
      description: "Return the configuration of monthly table level data quality partitioned\
        \ checks on a table"
      operationId: "getTablePartitionedChecksMonthly"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of table level data quality partitioned checks\
            \ on a table returned"
          schema:
            $ref: "#/definitions/TableMonthlyPartitionedCheckCategoriesSpec"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTablePartitionedChecksMonthly"
      description: "Updates the list of monthly table level data quality partitioned\
        \ checks on an existing table."
      operationId: "updateTablePartitionedChecksMonthly"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Configuration of monthly table level data quality partitioned\
          \ checks to store or an empty object to remove all data quality partitioned\
          \ checks on the table level (column level partitioned checks are preserved)."
        required: false
        schema:
          $ref: "#/definitions/TableMonthlyPartitionedCheckCategoriesSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Monthly table level data quality partitioned checks successfully\
            \ updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/partitioned/{timeScale}/comparisons/{tableComparisonConfigurationName}/results
  : get:
      tags:
      - "TableComparisonResults"
      summary: "getTableComparisonPartitionedResults"
      description: "Retrieves the results of the most table comparison performed using\
        \ the partitioned comparison checks, comparing days or months of data."
      operationId: "getTableComparisonPartitionedResults"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "The results of the most recent table comparison using the\
            \ partitioned checks on a table returned"
          schema:
            $ref: "#/definitions/TableComparisonResultsModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/partitioned/{timeScale}/errors:
    get:
      tags:
      - "Errors"
      summary: "getTablePartitionedErrors"
      description: "Returns errors related to the recent table level partitioned checks\
        \ executions for a requested time scale"
      operationId: "getTablePartitionedErrors"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "The errors related to partitioned check executions for a requested\
            \ time scale on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/ErrorsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/partitioned/{timeScale}/model:
    get:
      tags:
      - "Tables"
      summary: "getTablePartitionedChecksModel"
      description: "Return a UI friendly model of configurations for table level data\
        \ quality partitioned checks on a table for a given time scale"
      operationId: "getTablePartitionedChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      responses:
        200:
          description: "Configuration of table level {timeScale} data quality partitioned\
            \ checks on a table returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTablePartitionedChecksModel"
      description: "Updates the data quality partitioned checks from a model that\
        \ contains a patch with changes."
      operationId: "updateTablePartitionedChecksModel"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality partitioned\
          \ checks configuration."
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoObject"
        204:
          description: "Table level data quality partitioned checks successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found or invalid time scale"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/partitioned/{timeScale}/model/basic:
    get:
      tags:
      - "Tables"
      summary: "getTablePartitionedChecksBasicModel"
      description: "Return a simplistic UI friendly model of table level data quality\
        \ partitioned checks on a table for a given time scale"
      operationId: "getTablePartitionedChecksBasicModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      responses:
        200:
          description: "List of table level {timeScale} data quality partitioned checks\
            \ on a table returned"
          schema:
            $ref: "#/definitions/CheckContainerListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/partitioned/{timeScale}/model/filter/{checkCategory}/{checkName}
  : get:
      tags:
      - "Tables"
      summary: "getTablePartitionedChecksModelFilter"
      description: "Return a UI friendly model of configurations for table level data\
        \ quality partitioned checks on a table for a given time scale, filtered by\
        \ category and check name."
      operationId: "getTablePartitionedChecksModelFilter"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "checkCategory"
        in: "path"
        description: "Check category"
        required: true
        type: "string"
      - name: "checkName"
        in: "path"
        description: "Check name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of table level {timeScale} data quality partitioned\
            \ checks on a table returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/partitioned/{timeScale}/overview:
    get:
      tags:
      - "CheckResultsOverview"
      summary: "getTablePartitionedChecksOverview"
      description: "Returns an overview of the most recent table level partitioned\
        \ checks executions for a requested time scale"
      operationId: "getTablePartitionedChecksOverview"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "category"
        in: "query"
        description: "Optional check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Optional check name"
        required: false
        type: "string"
      responses:
        200:
          description: "An overview of the most recent partitioned check executions\
            \ for a requested time scale on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsOverviewDataModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/partitioned/{timeScale}/readouts:
    get:
      tags:
      - "SensorReadouts"
      summary: "getTablePartitionedSensorReadouts"
      description: "Returns a complete view of sensor readouts for recent table level\
        \ partitioned checks executions for a requested time scale"
      operationId: "getTablePartitionedSensorReadouts"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "The complete view of the sensor readouts for recent partitioned\
            \ check executions for a requested time scale on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/SensorReadoutsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/partitioned/{timeScale}/results:
    get:
      tags:
      - "CheckResults"
      summary: "getTablePartitionedChecksResults"
      description: "Returns a complete view of the recent table level partitioned\
        \ checks executions for a requested time scale"
      operationId: "getTablePartitionedChecksResults"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "timeScale"
        in: "path"
        description: "Time scale"
        required: true
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "The complete view of the most recent partitioned check executions\
            \ for a requested time scale on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsListModel"
        404:
          description: "Connection or table not found or time scale invalid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/partitioning:
    get:
      tags:
      - "Tables"
      summary: "getTablePartitioning"
      description: "Return the table partitioning information"
      operationId: "getTablePartitioning"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Table partitioning information returned"
          schema:
            $ref: "#/definitions/TablePartitioningModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTablePartitioning"
      description: "Updates the table partitioning configuration of an existing table."
      operationId: "updateTablePartitioning"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table partitioning model with the updated settings"
        required: false
        schema:
          $ref: "#/definitions/TablePartitioningModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table partitioning successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/profiling:
    get:
      tags:
      - "Tables"
      summary: "getTableProfilingChecks"
      description: "Return the configuration of table level data quality checks on\
        \ a table"
      operationId: "getTableProfilingChecks"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of table level data quality checks on a table\
            \ returned"
          schema:
            $ref: "#/definitions/TableProfilingCheckCategoriesSpec"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTableProfilingChecks"
      description: "Updates the list of table level data quality profiling checks\
        \ on an existing table."
      operationId: "updateTableProfilingChecks"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Configuration of table level data quality profiling checks to\
          \ store or an empty object to remove all data quality profiling checks on\
          \ the table level (column level profiling checks are preserved)."
        required: false
        schema:
          $ref: "#/definitions/TableProfilingCheckCategoriesSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table level data quality profiling checks successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/profiling/comparisons/{tableComparisonConfigurationName}/results
  : get:
      tags:
      - "TableComparisonResults"
      summary: "getTableComparisonProfilingResults"
      description: "Retrieves the results of the most table comparison performed using\
        \ the profiling checks comparison checks."
      operationId: "getTableComparisonProfilingResults"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "The results of the most recent table comparison using the\
            \ profiling checks on a table returned"
          schema:
            $ref: "#/definitions/TableComparisonResultsModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/profiling/errors:
    get:
      tags:
      - "Errors"
      summary: "getTableProfilingErrors"
      description: "Returns the errors related to the most recent check executions\
        \ for all table level data quality profiling checks on a table"
      operationId: "getTableProfilingErrors"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Errors related to the most recent check runs for table level\
            \ data quality profiling checks on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/ErrorsListModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/profiling/model:
    get:
      tags:
      - "Tables"
      summary: "getTableProfilingChecksModel"
      description: "Return a UI friendly model of configurations for all table level\
        \ data quality profiling checks on a table"
      operationId: "getTableProfilingChecksModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of table level data quality profiling checks\
            \ on a table returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTableProfilingChecksModel"
      description: "Updates the data quality profiling checks from a model that contains\
        \ a patch with changes."
      operationId: "updateTableProfilingChecksModel"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality profiling\
          \ checks configuration."
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table level data quality profiling checks successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/profiling/model/basic:
    get:
      tags:
      - "Tables"
      summary: "getTableProfilingChecksBasicModel"
      description: "Return a simplistic UI friendly model of all table level data\
        \ quality profiling checks on a table"
      operationId: "getTableProfilingChecksBasicModel"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "List of table level data quality profiling checks on a table\
            \ returned"
          schema:
            $ref: "#/definitions/CheckContainerListModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/profiling/model/filter/{checkCategory}/{checkName}:
    get:
      tags:
      - "Tables"
      summary: "getTableProfilingChecksModelFilter"
      description: "Return a UI friendly model of configurations for all table level\
        \ data quality profiling checks on a table passing a filter"
      operationId: "getTableProfilingChecksModelFilter"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "checkCategory"
        in: "path"
        description: "Check category"
        required: true
        type: "string"
      - name: "checkName"
        in: "path"
        description: "Check name"
        required: true
        type: "string"
      responses:
        200:
          description: "Configuration of table level data quality profiling checks\
            \ on a table returned"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/profiling/overview:
    get:
      tags:
      - "CheckResultsOverview"
      summary: "getTableProfilingChecksOverview"
      description: "Returns an overview of the most recent check executions for all\
        \ table level data quality profiling checks on a table"
      operationId: "getTableProfilingChecksOverview"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "category"
        in: "query"
        description: "Optional check category"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Optional check name"
        required: false
        type: "string"
      responses:
        200:
          description: "Overview of the most recent check runs for table level data\
            \ quality profiling checks on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsOverviewDataModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/profiling/readouts:
    get:
      tags:
      - "SensorReadouts"
      summary: "getTableProfilingSensorReadouts"
      description: "Returns the complete results of the most recent check executions\
        \ for all table level data quality profiling checks on a table"
      operationId: "getTableProfilingSensorReadouts"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Complete view sensor readouts of recent check runs for table\
            \ level data quality profiling checks on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/SensorReadoutsListModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/profiling/results:
    get:
      tags:
      - "CheckResults"
      summary: "getTableProfilingChecksResults"
      description: "Returns the complete results of the most recent check executions\
        \ for all table level data quality profiling checks on a table"
      operationId: "getTableProfilingChecksResults"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "dataGroup"
        in: "query"
        description: "Data group"
        required: false
        type: "string"
      - name: "monthStart"
        in: "query"
        description: "Month start boundary"
        required: false
        type: "string"
        format: "date"
      - name: "monthEnd"
        in: "query"
        description: "Month end boundary"
        required: false
        type: "string"
        format: "date"
      - name: "checkName"
        in: "query"
        description: "Check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Table comparison name"
        required: false
        type: "string"
      - name: "maxResultsPerCheck"
        in: "query"
        description: "Maximum number of results per check, the default is 100"
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Complete view of the most recent check runs for table level\
            \ data quality profiling checks on a table returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultsListModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/schedulesoverride/{schedulingGroup}:
    get:
      tags:
      - "Tables"
      summary: "getTableSchedulingGroupOverride"
      description: "Return the schedule override configuration for a table"
      operationId: "getTableSchedulingGroupOverride"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "schedulingGroup"
        in: "path"
        description: "Check scheduling group (named schedule)"
        required: true
        type: "string"
        enum:
        - "profiling"
        - "monitoring_daily"
        - "monitoring_monthly"
        - "partitioned_daily"
        - "partitioned_monthly"
      responses:
        200:
          description: "Overridden schedule configuration for a table returned"
          schema:
            $ref: "#/definitions/MonitoringScheduleSpec"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Tables"
      summary: "updateTableSchedulingGroupOverride"
      description: "Updates the overridden schedule configuration of an existing table\
        \ for a named schedule group (named schedule for checks using the same time\
        \ scale)."
      operationId: "updateTableSchedulingGroupOverride"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "schedulingGroup"
        in: "path"
        description: "Check scheduling group (named schedule)"
        required: true
        type: "string"
        enum:
        - "profiling"
        - "monitoring_daily"
        - "monitoring_monthly"
        - "partitioned_daily"
        - "partitioned_monthly"
      - in: "body"
        name: "body"
        description: "Table's overridden schedule configuration to store or an empty\
          \ object to clear the schedule configuration on a table"
        required: false
        schema:
          $ref: "#/definitions/MonitoringScheduleSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table's overridden schedule configuration successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Table not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/statistics:
    get:
      tags:
      - "Tables"
      summary: "getTableStatistics"
      description: "Returns a list of the profiler (statistics) metrics on a chosen\
        \ table captured during the most recent statistics collection."
      operationId: "getTableStatistics"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/TableStatisticsModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/status:
    get:
      tags:
      - "CheckResults"
      summary: "getTableDataQualityStatus"
      description: "Read the most recent results of executed data quality checks on\
        \ the table and return the current table's data quality status - the number\
        \ of failed data quality checks if the table has active data quality issues.\
        \ Also returns the names of data quality checks that did not pass most recently.\
        \ This operation verifies only the status of the most recently executed data\
        \ quality checks. Previous data quality issues are not counted."
      operationId: "getTableDataQualityStatus"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "months"
        in: "query"
        description: "Optional filter - the number of months to review the data quality\
          \ check results. For partitioned checks, it is the number of months to analyze.\
          \ The default value is 1 (which is the current month and 1 previous month)."
        required: false
        type: "integer"
        format: "int32"
      - name: "since"
        in: "query"
        description: "Optional filter that accepts an UTC timestamp to read only data\
          \ quality check results captured since that timestamp."
        required: false
        type: "string"
        format: "date-time"
      - name: "profiling"
        in: "query"
        description: "Optional check type filter to detect the current status of the\
          \ profiling checks results. The default value is false, excluding profiling\
          \ checks from the current table status detection. If enabled, only the status\
          \ of the most recent check result is retrieved."
        required: false
        type: "boolean"
      - name: "monitoring"
        in: "query"
        description: "Optional check type filter to detect the current status of the\
          \ monitoring checks results. The default value is true, including monitoring\
          \ checks in the current table status detection. If enabled, only the status\
          \ of the most recent check result is retrieved."
        required: false
        type: "boolean"
      - name: "partitioned"
        in: "query"
        description: "Optional check type filter to detect the current status of the\
          \ partitioned checks results. The default value is true, including partitioned\
          \ checks in the current table status detection. Detection of the status\
          \ of partitioned checks is different. When enabled, DQOps checks the highest\
          \ severity status of all partitions since the **since** date or within the\
          \ last **months**."
        required: false
        type: "boolean"
      - name: "checkTimeScale"
        in: "query"
        description: "Optional time scale filter for monitoring and partitioned checks\
          \ (values: daily or monthly)."
        required: false
        type: "string"
        enum:
        - "daily"
        - "monthly"
      - name: "dataGroup"
        in: "query"
        description: "Optional data group"
        required: false
        type: "string"
      - name: "checkName"
        in: "query"
        description: "Optional check name"
        required: false
        type: "string"
      - name: "category"
        in: "query"
        description: "Optional check category name"
        required: false
        type: "string"
      - name: "tableComparison"
        in: "query"
        description: "Optional table comparison name"
        required: false
        type: "string"
      - name: "qualityDimension"
        in: "query"
        description: "Optional data quality dimension"
        required: false
        type: "string"
      responses:
        200:
          description: "The most recent data quality status of the requested table"
          schema:
            $ref: "#/definitions/TableCurrentDataQualityStatusModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisonconfigurations:
    get:
      tags:
      - "TableComparisons"
      summary: "getTableComparisonConfigurations"
      description: "Returns the list of table comparison configurations on a compared\
        \ table"
      operationId: "getTableComparisonConfigurations"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "checkType"
        in: "query"
        description: "Optional check type filter (profiling, monitoring, partitioned)."
        required: false
        type: "string"
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      - name: "checkTimeScale"
        in: "query"
        description: "Optional time scale filter for table comparisons specific to\
          \ the monitoring and partitioned checks (values: daily or monthly)."
        required: false
        type: "string"
        enum:
        - "daily"
        - "monthly"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/TableComparisonConfigurationModel"
        404:
          description: "Connection or table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "TableComparisons"
      summary: "createTableComparisonConfiguration"
      description: "Creates a new table comparison configuration added to the compared\
        \ table"
      operationId: "createTableComparisonConfiguration"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison configuration model"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonConfigurationModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New table comparison configuration successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Table comparison configuration with the same name already\
            \ exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisonconfigurations/{tableComparisonConfigurationName}
  : get:
      tags:
      - "TableComparisons"
      summary: "getTableComparisonConfiguration"
      description: "Returns a model of the table comparison configuration"
      operationId: "getTableComparisonConfiguration"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Reference table configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/TableComparisonConfigurationModel"
        404:
          description: "Connection, table or reference table not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "TableComparisons"
      summary: "updateTableComparisonConfiguration"
      description: "Updates a table configuration configuration"
      operationId: "updateTableComparisonConfiguration"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison model with the configuration of the tables\
          \ to compare"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonConfigurationModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table comparison configuration successfully updated"
        404:
          description: "Connection, table or table comparison on the table not found"
        406:
          description: "Incorrect request"
        409:
          description: "Table comparison configuration with the same name already\
            \ exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "TableComparisons"
      summary: "deleteTableComparisonConfiguration"
      description: "Deletes a table comparison configuration from a compared table"
      operationId: "deleteTableComparisonConfiguration"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Reference table configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table comparison configuration removed"
        404:
          description: "Connection or table not found"
        406:
          description: "Invalid request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/monitoring/daily:
    post:
      tags:
      - "TableComparisons"
      summary: "createTableComparisonMonitoringDaily"
      description: "Creates a table comparison configuration using daily monitoring\
        \ checks"
      operationId: "createTableComparisonMonitoringDaily"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison configuration model with the selected checks\
          \ to use for comparison"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New table comparison configuration for daily monitoring checks\
            \ successfully created"
        404:
          description: "Connection, table or table comparison not found"
        406:
          description: "Incorrect request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/monitoring/daily/{tableComparisonConfigurationName}
  : put:
      tags:
      - "TableComparisons"
      summary: "updateTableComparisonMonitoringDaily"
      description: "Updates a table comparison checks monitoring daily"
      operationId: "updateTableComparisonMonitoringDaily"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison configuration model with the selected checks\
          \ to use for comparison"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table comparison daily monitoring checks successfully updated"
        404:
          description: "Connection, table or table comparison not found"
        406:
          description: "Incorrect request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/monitoring/monthly:
    post:
      tags:
      - "TableComparisons"
      summary: "createTableComparisonMonitoringMonthly"
      description: "Creates a table comparison configuration using monthly monitoring\
        \ checks"
      operationId: "createTableComparisonMonitoringMonthly"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison configuration model with the selected checks\
          \ to use for comparison"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New table comparison configuration for monthly monitoring\
            \ checks successfully created"
        404:
          description: "Connection, table or table comparison not found"
        406:
          description: "Incorrect request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/monitoring/monthly/{tableComparisonConfigurationName}
  : put:
      tags:
      - "TableComparisons"
      summary: "updateTableComparisonMonitoringMonthly"
      description: "Updates a table comparison checks monitoring monthly"
      operationId: "updateTableComparisonMonitoringMonthly"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison configuration model with the selected checks\
          \ to use for comparison"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table comparison daily monitoring checks successfully updated"
        404:
          description: "Connection, table or table comparison not found"
        406:
          description: "Incorrect request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/partitioned/daily:
    post:
      tags:
      - "TableComparisons"
      summary: "createTableComparisonPartitionedDaily"
      description: "Creates a table comparison configuration using daily partitioned\
        \ checks"
      operationId: "createTableComparisonPartitionedDaily"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison configuration model with the selected checks\
          \ to use for comparison"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New table comparison configuration for daily partitioned checks\
            \ successfully created"
        404:
          description: "Connection, table or table comparison not found"
        406:
          description: "Incorrect request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/partitioned/daily/{tableComparisonConfigurationName}
  : put:
      tags:
      - "TableComparisons"
      summary: "updateTableComparisonPartitionedDaily"
      description: "Updates a table comparison checks partitioned daily (comparing\
        \ day to day)"
      operationId: "updateTableComparisonPartitionedDaily"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison configuration model with the selected checks\
          \ to use for comparison"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table comparison daily partitioned checks successfully updated"
        404:
          description: "Connection, table or table comparison not found"
        406:
          description: "Incorrect request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/partitioned/monthly:
    post:
      tags:
      - "TableComparisons"
      summary: "createTableComparisonPartitionedMonthly"
      description: "Creates a table comparison configuration using monthly partitioned\
        \ checks"
      operationId: "createTableComparisonPartitionedMonthly"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison configuration model with the selected checks\
          \ to use for comparison"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New table comparison configuration for monthly partitioned\
            \ checks successfully created"
        404:
          description: "Connection, table or table comparison not found"
        406:
          description: "Incorrect request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/partitioned/monthly/{tableComparisonConfigurationName}
  : put:
      tags:
      - "TableComparisons"
      summary: "updateTableComparisonPartitionedMonthly"
      description: "Updates a table comparison checks partitioned monthly (comparing\
        \ month to month)"
      operationId: "updateTableComparisonPartitionedMonthly"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison configuration model with the selected checks\
          \ to use for comparison"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table comparison monthly partitioned checks successfully updated"
        404:
          description: "Connection, table or table comparison not found"
        406:
          description: "Incorrect request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/profiling:
    post:
      tags:
      - "TableComparisons"
      summary: "createTableComparisonProfiling"
      description: "Creates a table comparison configuration using profiling checks"
      operationId: "createTableComparisonProfiling"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison configuration model with the selected checks\
          \ to use for comparison"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New table comparison configuration for profiling checks successfully\
            \ created"
        404:
          description: "Connection, table or table comparison not found"
        406:
          description: "Incorrect request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/profiling/{tableComparisonConfigurationName}
  : put:
      tags:
      - "TableComparisons"
      summary: "updateTableComparisonProfiling"
      description: "Updates a table comparison profiling checks"
      operationId: "updateTableComparisonProfiling"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Table comparison configuration model with the selected checks\
          \ to use for comparison"
        required: false
        schema:
          $ref: "#/definitions/TableComparisonModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Table comparison profiling checks successfully updated"
        404:
          description: "Connection, table or table comparison not found"
        406:
          description: "Incorrect request"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/{tableComparisonConfigurationName}/monitoring/daily
  : get:
      tags:
      - "TableComparisons"
      summary: "getTableComparisonMonitoringDaily"
      description: "Returns a model of the table comparison using daily monitoring\
        \ checks (comparison once a day)"
      operationId: "getTableComparisonMonitoringDaily"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/TableComparisonModel"
        404:
          description: "Connection, table or reference table configuration not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/{tableComparisonConfigurationName}/monitoring/monthly
  : get:
      tags:
      - "TableComparisons"
      summary: "getTableComparisonMonitoringMonthly"
      description: "Returns a model of the table comparison using monthly monitoring\
        \ checks (comparison once a month)"
      operationId: "getTableComparisonMonitoringMonthly"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/TableComparisonModel"
        404:
          description: "Connection, table or reference table configuration not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/{tableComparisonConfigurationName}/partitioned/daily
  : get:
      tags:
      - "TableComparisons"
      summary: "getTableComparisonPartitionedDaily"
      description: "Returns a model of the table comparison using daily partition\
        \ checks (comparing day to day)"
      operationId: "getTableComparisonPartitionedDaily"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/TableComparisonModel"
        404:
          description: "Connection, table or reference table configuration not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/{tableComparisonConfigurationName}/partitioned/monthly
  : get:
      tags:
      - "TableComparisons"
      summary: "getTableComparisonPartitionedMonthly"
      description: "Returns a model of the table comparison using monthly partition\
        \ checks (comparing month to month)"
      operationId: "getTableComparisonPartitionedMonthly"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/TableComparisonModel"
        404:
          description: "Connection, table or reference table configuration not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  ? /api/connections/{connectionName}/schemas/{schemaName}/tables/{tableName}/tablecomparisons/{tableComparisonConfigurationName}/profiling
  : get:
      tags:
      - "TableComparisons"
      summary: "getTableComparisonProfiling"
      description: "Returns a model of the table comparison using profiling checks\
        \ (comparison at any time)"
      operationId: "getTableComparisonProfiling"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      - name: "tableName"
        in: "path"
        description: "Table name"
        required: true
        type: "string"
      - name: "tableComparisonConfigurationName"
        in: "path"
        description: "Table comparison configuration name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/TableComparisonModel"
        404:
          description: "Connection, table or reference table configuration not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/credential/{credentialName}:
    put:
      tags:
      - "SharedCredentials"
      summary: "updateSharedCredential"
      description: "Updates an existing shared credential, replacing the credential's\
        \ file content."
      operationId: "updateSharedCredential"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Shared credential model"
        required: false
        schema:
          $ref: "#/definitions/SharedCredentialModel"
      - name: "credentialName"
        in: "path"
        description: "Credential file name that will be updated"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Shared credential successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Shared credential not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/credentials:
    get:
      tags:
      - "SharedCredentials"
      summary: "getAllSharedCredentials"
      description: "Returns a list of all shared credentials that are present in the\
        \ DQOps user's home .credentials/ folder."
      operationId: "getAllSharedCredentials"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/SharedCredentialListModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "SharedCredentials"
      summary: "createSharedCredential"
      description: "Creates (adds) a new shared credential, which creates a file in\
        \ the DQOps user's home .credentials/ folder named as the credential and with\
        \ the content that is provided in this call."
      operationId: "createSharedCredential"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Shared credential model"
        required: false
        schema:
          $ref: "#/definitions/SharedCredentialModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New shared credential successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Shared credential with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/credentials/{credentialName}:
    get:
      tags:
      - "SharedCredentials"
      summary: "getSharedCredential"
      description: "Returns a shared credential content"
      operationId: "getSharedCredential"
      produces:
      - "application/json"
      parameters:
      - name: "credentialName"
        in: "path"
        description: "Shared credential file name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/SharedCredentialModel"
        404:
          description: "Shared credential not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "SharedCredentials"
      summary: "deleteSharedCredential"
      description: "Deletes a shared credential file from the DQOps user's home .credentials/\
        \ folder."
      operationId: "deleteSharedCredential"
      produces:
      - "application/json"
      parameters:
      - name: "credentialName"
        in: "path"
        description: "Full shared credential name"
        required: true
        type: "string"
      responses:
        200:
          description: "Shared credential file successfully deleted"
          schema:
            $ref: "#/definitions/MonoVoid"
        404:
          description: "Shared credential file not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/credentials/{credentialName}/download:
    get:
      tags:
      - "SharedCredentials"
      summary: "downloadSharedCredential"
      description: "Downloads a shared credential's file"
      operationId: "downloadSharedCredential"
      produces:
      - "application/octet-stream"
      parameters:
      - name: "credentialName"
        in: "path"
        description: "Shared credential file name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              type: "string"
              format: "byte"
        404:
          description: "Shared credential not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/dashboards:
    get:
      tags:
      - "Dashboards"
      summary: "getAllDashboards"
      description: "Returns a list of root folders with dashboards"
      operationId: "getAllDashboards"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/DashboardsFolderSpec"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/dashboards/{folder1}/{folder2}/{dashboardName}:
    get:
      tags:
      - "Dashboards"
      summary: "getDashboardLevel2"
      description: "Returns a single dashboard in the tree of folders with a temporary\
        \ authenticated url"
      operationId: "getDashboardLevel2"
      produces:
      - "application/json"
      parameters:
      - name: "folder1"
        in: "path"
        description: "Root folder name"
        required: true
        type: "string"
      - name: "folder2"
        in: "path"
        description: "Second level folder name"
        required: true
        type: "string"
      - name: "dashboardName"
        in: "path"
        description: "Dashboard name"
        required: true
        type: "string"
      - name: "windowLocationOrigin"
        in: "query"
        description: "Optional url of the DQOps instance, it should be the value of\
          \ window.location.origin."
        required: false
        type: "string"
      responses:
        200:
          description: "Dashboard returned"
          schema:
            $ref: "#/definitions/AuthenticatedDashboardModel"
        401:
          description: "Unauthorized, DQOps Cloud API key is outdated, please run\
            \ \"cloud login\" from the DQOps shell to update the API key"
        404:
          description: "Dashboard not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/dashboards/{folder1}/{folder2}/{folder3}/{dashboardName}:
    get:
      tags:
      - "Dashboards"
      summary: "getDashboardLevel3"
      description: "Returns a single dashboard in the tree of folders with a temporary\
        \ authenticated url"
      operationId: "getDashboardLevel3"
      produces:
      - "application/json"
      parameters:
      - name: "folder1"
        in: "path"
        description: "Root folder name"
        required: true
        type: "string"
      - name: "folder2"
        in: "path"
        description: "Second level folder name"
        required: true
        type: "string"
      - name: "folder3"
        in: "path"
        description: "Third level folder name"
        required: true
        type: "string"
      - name: "dashboardName"
        in: "path"
        description: "Dashboard name"
        required: true
        type: "string"
      - name: "windowLocationOrigin"
        in: "query"
        description: "Optional url of the DQOps instance, it should be the value of\
          \ window.location.origin."
        required: false
        type: "string"
      responses:
        200:
          description: "Dashboard returned"
          schema:
            $ref: "#/definitions/AuthenticatedDashboardModel"
        401:
          description: "Unauthorized, DQOps Cloud API key is outdated, please run\
            \ \"cloud login\" from the DQOps shell to update the API key"
        404:
          description: "Dashboard not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/dashboards/{folder1}/{folder2}/{folder3}/{folder4}/{dashboardName}:
    get:
      tags:
      - "Dashboards"
      summary: "getDashboardLevel4"
      description: "Returns a single dashboard in the tree of folders with a temporary\
        \ authenticated url"
      operationId: "getDashboardLevel4"
      produces:
      - "application/json"
      parameters:
      - name: "folder1"
        in: "path"
        description: "Root folder name"
        required: true
        type: "string"
      - name: "folder2"
        in: "path"
        description: "Second level folder name"
        required: true
        type: "string"
      - name: "folder3"
        in: "path"
        description: "Third level folder name"
        required: true
        type: "string"
      - name: "folder4"
        in: "path"
        description: "Fourth level folder name"
        required: true
        type: "string"
      - name: "dashboardName"
        in: "path"
        description: "Dashboard name"
        required: true
        type: "string"
      - name: "windowLocationOrigin"
        in: "query"
        description: "Optional url of the DQOps instance, it should be the value of\
          \ window.location.origin."
        required: false
        type: "string"
      responses:
        200:
          description: "Dashboard returned"
          schema:
            $ref: "#/definitions/AuthenticatedDashboardModel"
        401:
          description: "Unauthorized, DQOps Cloud API key is outdated, please run\
            \ \"cloud login\" from the DQOps shell to update the API key"
        404:
          description: "Dashboard not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/dashboards/{folder1}/{folder2}/{folder3}/{folder4}/{folder5}/{dashboardName}:
    get:
      tags:
      - "Dashboards"
      summary: "getDashboardLevel5"
      description: "Returns a single dashboard in the tree of folders with a temporary\
        \ authenticated url"
      operationId: "getDashboardLevel5"
      produces:
      - "application/json"
      parameters:
      - name: "folder1"
        in: "path"
        description: "Root folder name"
        required: true
        type: "string"
      - name: "folder2"
        in: "path"
        description: "Second level folder name"
        required: true
        type: "string"
      - name: "folder3"
        in: "path"
        description: "Third level folder name"
        required: true
        type: "string"
      - name: "folder4"
        in: "path"
        description: "Fourth level folder name"
        required: true
        type: "string"
      - name: "folder5"
        in: "path"
        description: "Fifth level folder name"
        required: true
        type: "string"
      - name: "dashboardName"
        in: "path"
        description: "Dashboard name"
        required: true
        type: "string"
      - name: "windowLocationOrigin"
        in: "query"
        description: "Optional url of the DQOps instance, it should be the value of\
          \ window.location.origin."
        required: false
        type: "string"
      responses:
        200:
          description: "Dashboard returned"
          schema:
            $ref: "#/definitions/AuthenticatedDashboardModel"
        401:
          description: "Unauthorized, DQOps Cloud API key is outdated, please run\
            \ \"cloud login\" from the DQOps shell to update the API key"
        404:
          description: "Dashboard not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/dashboards/{folder}/{dashboardName}:
    get:
      tags:
      - "Dashboards"
      summary: "getDashboardLevel1"
      description: "Returns a single dashboard in the tree of folder with a temporary\
        \ authenticated url"
      operationId: "getDashboardLevel1"
      produces:
      - "application/json"
      parameters:
      - name: "folder"
        in: "path"
        description: "Root folder name"
        required: true
        type: "string"
      - name: "dashboardName"
        in: "path"
        description: "Dashboard name"
        required: true
        type: "string"
      - name: "windowLocationOrigin"
        in: "query"
        description: "Optional url of the DQOps instance, it should be the value of\
          \ window.location.origin."
        required: false
        type: "string"
      responses:
        200:
          description: "Dashboard returned"
          schema:
            $ref: "#/definitions/AuthenticatedDashboardModel"
        401:
          description: "Unauthorized, DQOps Cloud API key is outdated, please run\
            \ \"cloud login\" from the DQOps shell to update the API key"
        404:
          description: "Dashboard not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/datasource/connections/{connectionName}/schemas:
    get:
      tags:
      - "DataSources"
      summary: "getRemoteDataSourceSchemas"
      description: "Introspects a list of schemas inside a remote data source, identified\
        \ by an already imported connection."
      operationId: "getRemoteDataSourceSchemas"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      responses:
        200:
          description: "The list of schemas on a remote data source was introspected\
            \ and is returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/SchemaRemoteModel"
        400:
          description: "Error accessing the remote data source"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/datasource/connections/{connectionName}/schemas/{schemaName}/tables:
    get:
      tags:
      - "DataSources"
      summary: "getRemoteDataSourceTables"
      description: "Introspects the list of columns inside a schema on a remote data\
        \ source that is identified by a connection that was added to DQOps."
      operationId: "getRemoteDataSourceTables"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "schemaName"
        in: "path"
        description: "Schema name"
        required: true
        type: "string"
      responses:
        200:
          description: "The list of tables on a remote data source was introspected\
            \ and is returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/RemoteTableListModel"
        400:
          description: "Error accessing the remote source database"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
        404:
          description: "Connection not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/datasource/testconnection:
    post:
      tags:
      - "DataSources"
      summary: "testConnection"
      description: "Checks if the given remote connection can be opened and if the\
        \ credentials are valid"
      operationId: "testConnection"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Basic connection model"
        required: false
        schema:
          $ref: "#/definitions/ConnectionModel"
      - name: "verifyNameUniqueness"
        in: "query"
        description: "Verify if the connection name is unique, the default value is\
          \ true"
        required: false
        type: "boolean"
      responses:
        200:
          description: "Connection was tested, check the status code to see the connection's\
            \ test status"
          schema:
            $ref: "#/definitions/ConnectionTestModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/column:
    get:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "getAllDefaultColumnChecksPatterns"
      description: "Returns a flat list of all column-level default check patterns\
        \ configured for this instance. Default checks are applied on columns dynamically."
      operationId: "getAllDefaultColumnChecksPatterns"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/DefaultColumnChecksPatternListModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/column/{patternName}:
    get:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "getDefaultColumnChecksPattern"
      description: "Returns a default checks pattern definition as a full specification\
        \ object"
      operationId: "getDefaultColumnChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Column pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/DefaultColumnChecksPatternModel"
        404:
          description: "Pattern name not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "createDefaultColumnChecksPattern"
      description: "Creates (adds) a new default column-level checks pattern configuration\
        \ by saving a full specification object."
      operationId: "createDefaultColumnChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Default checks pattern model"
        required: false
        schema:
          $ref: "#/definitions/DefaultColumnChecksPatternModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New checks pattern successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Check pattern with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "updateDefaultColumnChecksPattern"
      description: "Updates an default column-level checks pattern by saving a full\
        \ specification object"
      operationId: "updateDefaultColumnChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Default checks pattern model"
        required: false
        schema:
          $ref: "#/definitions/DefaultColumnChecksPatternModel"
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Default column-level checks pattern successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "deleteDefaultColumnChecksPattern"
      description: "Deletes a default column-level checks pattern"
      operationId: "deleteDefaultColumnChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Default column-level checks pattern successfully deleted"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/column/{patternName}/monitoring/daily:
    get:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "getDefaultMonitoringDailyColumnChecksPattern"
      description: "Returns UI model to show and edit the default configuration of\
        \ the daily monitoring checks that are configured for a check pattern on a\
        \ column level."
      operationId: "getDefaultMonitoringDailyColumnChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "updateDefaultMonitoringDailyColumnChecksPattern"
      description: "New configuration of the default daily monitoring checks on a\
        \ column level. These checks will be applied to columns."
      operationId: "updateDefaultMonitoringDailyColumnChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality daily\
          \ monitoring checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of daily monitoring checks successfully\
            \ updated."
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Default check pattern configuration not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/column/{patternName}/monitoring/monthly:
    get:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "getDefaultMonitoringMonthlyColumnChecksPattern"
      description: "Returns UI model to show and edit the default configuration of\
        \ the monthly monitoring checks that are configured for a check pattern on\
        \ a column level."
      operationId: "getDefaultMonitoringMonthlyColumnChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "updateDefaultMonitoringMonthlyColumnChecksPattern"
      description: "New configuration of the default monthly monitoring checks on\
        \ a column level. These checks will be applied to columns."
      operationId: "updateDefaultMonitoringMonthlyColumnChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality monthly\
          \ monitoring checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of monthly monitoring checks successfully\
            \ updated."
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Default check pattern configuration not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/column/{patternName}/partitioned/daily:
    get:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "getDefaultPartitionedDailyColumnChecksPattern"
      description: "Returns UI model to show and edit the default configuration of\
        \ the daily partitioned checks that are configured for a check pattern on\
        \ a column level."
      operationId: "getDefaultPartitionedDailyColumnChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "updateDefaultPartitionedDailyColumnChecksPattern"
      description: "New configuration of the default daily partitioned checks on a\
        \ column level. These checks will be applied to columns."
      operationId: "updateDefaultPartitionedDailyColumnChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality daily\
          \ partitioned checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of daily partitioned checks successfully\
            \ updated."
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Default check pattern configuration not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/column/{patternName}/partitioned/monthly:
    get:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "getDefaultPartitionedMonthlyColumnChecksPattern"
      description: "Returns UI model to show and edit the default configuration of\
        \ the monthly partitioned checks that are configured for a check pattern on\
        \ a column level."
      operationId: "getDefaultPartitionedMonthlyColumnChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "updateDefaultPartitionedMonthlyColumnChecksPattern"
      description: "New configuration of the default monthly partitioned checks on\
        \ a column level. These checks will be applied to columns."
      operationId: "updateDefaultPartitionedMonthlyColumnChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality monthly\
          \ partitioned checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of monthly partitioned checks successfully\
            \ updated."
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Default check pattern configuration not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/column/{patternName}/profiling:
    get:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "getDefaultProfilingColumnChecksPattern"
      description: "Returns UI model to show and edit the default configuration of\
        \ the profiling checks that are configured for a check pattern on a column\
        \ level."
      operationId: "getDefaultProfilingColumnChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "updateDefaultProfilingColumnChecksPattern"
      description: "New configuration of the default profiling checks on a column\
        \ level. These checks will be applied to columns."
      operationId: "updateDefaultProfilingColumnChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality profiling\
          \ checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of profiling checks successfully\
            \ updated."
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Default check pattern configuration not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/column/{patternName}/target:
    get:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "getDefaultColumnChecksPatternTarget"
      description: "Returns a default checks pattern definition"
      operationId: "getDefaultColumnChecksPatternTarget"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Column pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/DefaultColumnChecksPatternListModel"
        404:
          description: "Pattern name not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "createDefaultColumnChecksPatternTarget"
      description: "Creates (adds) a new default column-level checks pattern configuration."
      operationId: "createDefaultColumnChecksPatternTarget"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Default checks pattern model with only the target filters"
        required: false
        schema:
          $ref: "#/definitions/DefaultColumnChecksPatternListModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New checks pattern successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Check pattern with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultColumnCheckPatterns"
      summary: "updateDefaultColumnChecksPatternTarget"
      description: "Updates an default column-level checks pattern, changing only\
        \ the target object"
      operationId: "updateDefaultColumnChecksPatternTarget"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Default checks pattern model"
        required: false
        schema:
          $ref: "#/definitions/DefaultColumnChecksPatternListModel"
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Default column-level checks pattern successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/table:
    get:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "getAllDefaultTableChecksPatterns"
      description: "Returns a flat list of all table-level default check patterns\
        \ configured for this instance. Default checks are applied on tables dynamically."
      operationId: "getAllDefaultTableChecksPatterns"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/DefaultTableChecksPatternListModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/table/{patternName}:
    get:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "getDefaultTableChecksPattern"
      description: "Returns a default checks pattern definition as a full specification\
        \ object"
      operationId: "getDefaultTableChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Table pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/DefaultTableChecksPatternModel"
        404:
          description: "Pattern name not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "createDefaultTableChecksPattern"
      description: "Creates (adds) a new default table-level checks pattern configuration\
        \ by saving a full specification object."
      operationId: "createDefaultTableChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Default checks pattern model"
        required: false
        schema:
          $ref: "#/definitions/DefaultTableChecksPatternModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New checks pattern successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Check pattern with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "updateDefaultTableChecksPattern"
      description: "Updates an default table-level checks pattern by saving a full\
        \ specification object"
      operationId: "updateDefaultTableChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Default checks pattern model"
        required: false
        schema:
          $ref: "#/definitions/DefaultTableChecksPatternModel"
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Default table-level checks pattern successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "deleteDefaultTableChecksPattern"
      description: "Deletes a default table-level checks pattern"
      operationId: "deleteDefaultTableChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Default table-level checks pattern successfully deleted"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/table/{patternName}/monitoring/daily:
    get:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "getDefaultMonitoringDailyTableChecksPattern"
      description: "Returns UI model to show and edit the default configuration of\
        \ the daily monitoring checks that are configured for a check pattern on a\
        \ table level."
      operationId: "getDefaultMonitoringDailyTableChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "updateDefaultMonitoringDailyTableChecksPattern"
      description: "New configuration of the default daily monitoring checks on a\
        \ table level. These checks will be applied to tables."
      operationId: "updateDefaultMonitoringDailyTableChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality daily\
          \ monitoring checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of daily monitoring checks successfully\
            \ updated."
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Default check pattern configuration not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/table/{patternName}/monitoring/monthly:
    get:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "getDefaultMonitoringMonthlyTableChecksPattern"
      description: "Returns UI model to show and edit the default configuration of\
        \ the monthly monitoring checks that are configured for a check pattern on\
        \ a table level."
      operationId: "getDefaultMonitoringMonthlyTableChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "updateDefaultMonitoringMonthlyTableChecksPattern"
      description: "New configuration of the default monthly monitoring checks on\
        \ a table level. These checks will be applied to tables."
      operationId: "updateDefaultMonitoringMonthlyTableChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality monthly\
          \ monitoring checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of monthly monitoring checks successfully\
            \ updated."
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Default check pattern configuration not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/table/{patternName}/partitioned/daily:
    get:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "getDefaultPartitionedDailyTableChecksPattern"
      description: "Returns UI model to show and edit the default configuration of\
        \ the daily partitioned checks that are configured for a check pattern on\
        \ a table level."
      operationId: "getDefaultPartitionedDailyTableChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "updateDefaultPartitionedDailyTableChecksPattern"
      description: "New configuration of the default daily partitioned checks on a\
        \ table level. These checks will be applied to tables."
      operationId: "updateDefaultPartitionedDailyTableChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality daily\
          \ partitioned checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of daily partitioned checks successfully\
            \ updated."
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Default check pattern configuration not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/table/{patternName}/partitioned/monthly:
    get:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "getDefaultPartitionedMonthlyTableChecksPattern"
      description: "Returns UI model to show and edit the default configuration of\
        \ the monthly partitioned checks that are configured for a check pattern on\
        \ a table level."
      operationId: "getDefaultPartitionedMonthlyTableChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "updateDefaultPartitionedMonthlyTableChecksPattern"
      description: "New configuration of the default monthly partitioned checks on\
        \ a table level. These checks will be applied to tables."
      operationId: "updateDefaultPartitionedMonthlyTableChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality monthly\
          \ partitioned checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of monthly partitioned checks successfully\
            \ updated."
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Default check pattern configuration not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/table/{patternName}/profiling:
    get:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "getDefaultProfilingTableChecksPattern"
      description: "Returns UI model to show and edit the default configuration of\
        \ the profiling checks that are configured for a check pattern on a table\
        \ level."
      operationId: "getDefaultProfilingTableChecksPattern"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckContainerModel"
        404:
          description: "Default checks pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "updateDefaultProfilingTableChecksPattern"
      description: "New configuration of the default profiling checks on a table level.\
        \ These checks will be applied to tables."
      operationId: "updateDefaultProfilingTableChecksPattern"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Model with the changes to be applied to the data quality profiling\
          \ checks configuration"
        required: false
        schema:
          $ref: "#/definitions/CheckContainerModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of profiling checks successfully\
            \ updated."
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Default check pattern configuration not found"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/default/checks/table/{patternName}/target:
    get:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "getDefaultTableChecksPatternTarget"
      description: "Returns a default checks pattern definition"
      operationId: "getDefaultTableChecksPatternTarget"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Table pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/DefaultTableChecksPatternListModel"
        404:
          description: "Pattern name not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "createDefaultTableChecksPatternTarget"
      description: "Creates (adds) a new default table-level checks pattern configuration."
      operationId: "createDefaultTableChecksPatternTarget"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Default checks pattern model with only the target filters"
        required: false
        schema:
          $ref: "#/definitions/DefaultTableChecksPatternListModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New checks pattern successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Check pattern with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "DefaultTableCheckPatterns"
      summary: "updateDefaultTableChecksPatternTarget"
      description: "Updates an default table-level checks pattern, changing only the\
        \ target object"
      operationId: "updateDefaultTableChecksPatternTarget"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Default checks pattern model"
        required: false
        schema:
          $ref: "#/definitions/DefaultTableChecksPatternListModel"
      - name: "patternName"
        in: "path"
        description: "Pattern name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Default table-level checks pattern successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Pattern not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/defaults/defaultschedule/{schedulingGroup}:
    get:
      tags:
      - "Defaults"
      summary: "getDefaultSchedules"
      description: "Returns spec to show and edit the default configuration of schedules."
      operationId: "getDefaultSchedule"
      produces:
      - "application/json"
      parameters:
      - name: "schedulingGroup"
        in: "path"
        description: "Check scheduling group (named schedule)"
        required: true
        type: "string"
        enum:
        - "profiling"
        - "monitoring_daily"
        - "monitoring_monthly"
        - "partitioned_daily"
        - "partitioned_monthly"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/MonitoringScheduleSpec"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Defaults"
      summary: "updateDefaultSchedules"
      description: "New configuration of the default schedules."
      operationId: "updateDefaultSchedules"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Spec with default schedules changes to be applied to the default\
          \ configuration."
        required: false
        schema:
          $ref: "#/definitions/MonitoringScheduleSpec"
      - name: "schedulingGroup"
        in: "path"
        description: "Check scheduling group (named schedule)"
        required: true
        type: "string"
        enum:
        - "profiling"
        - "monitoring_daily"
        - "monitoring_monthly"
        - "partitioned_daily"
        - "partitioned_monthly"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of schedules successfully updated."
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/defaults/defaultwebhooks:
    get:
      tags:
      - "Defaults"
      summary: "getDefaultWebhooks"
      description: "Returns spec to show and edit the default configuration of webhooks."
      operationId: "getDefaultWebhooks"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/IncidentWebhookNotificationsSpec"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Defaults"
      summary: "updateDefaultWebhooks"
      description: "New configuration of the default webhooks."
      operationId: "updateDefaultWebhooks"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Spec with default notification webhooks changes to be applied\
          \ to the default configuration"
        required: false
        schema:
          $ref: "#/definitions/IncidentWebhookNotificationsSpec"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "The default configuration of notification webhooks successfully\
            \ updated."
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/definitions/checks:
    get:
      tags:
      - "Checks"
      summary: "getCheckFolderTree"
      description: "Returns a tree of all checks available in DQOps, both built-in\
        \ checks and user defined or customized checks."
      operationId: "getCheckFolderTree"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/CheckDefinitionFolderModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/definitions/rules:
    get:
      tags:
      - "Rules"
      summary: "getRuleFolderTree"
      description: "Returns a tree of all rules available in DQOps, both built-in\
        \ rules and user defined or customized rules."
      operationId: "getRuleFolderTree"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/RuleFolderModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/definitions/sensors:
    get:
      tags:
      - "Sensors"
      summary: "getSensorFolderTree"
      description: "Returns a tree of all sensors available in DQOps, both built-in\
        \ sensors and user defined or customized sensors."
      operationId: "getSensorFolderTree"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/SensorFolderModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/dictionaries:
    get:
      tags:
      - "Dictionaries"
      summary: "getAllDictionaries"
      description: "Returns a list of all data dictionary CSV files that are present\
        \ in the DQOps user's home dictionaries/ folder."
      operationId: "getAllDictionaries"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/DataDictionaryListModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "Dictionaries"
      summary: "createDictionary"
      description: "Creates (adds) a new data dictionary CSV file, which creates a\
        \ file in the DQOps user's home dictionaries/ folder named as the dictionary\
        \ and with the content that is provided in this call."
      operationId: "createDictionary"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Data dictionary model"
        required: false
        schema:
          $ref: "#/definitions/DataDictionaryModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New data dictionary successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Data dictionary with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/dictionaries/{dictionaryName}:
    get:
      tags:
      - "Dictionaries"
      summary: "getDictionary"
      description: "Returns the content of a data dictionary CSV file as a model object"
      operationId: "getDictionary"
      produces:
      - "application/json"
      parameters:
      - name: "dictionaryName"
        in: "path"
        description: "Data dictionary CSV file name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/DataDictionaryModel"
        404:
          description: "Data dictionary not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Dictionaries"
      summary: "updateDictionary"
      description: "Updates an existing data dictionary CSV file, replacing the dictionary's\
        \ file content."
      operationId: "updateDictionary"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Data dictionary model"
        required: false
        schema:
          $ref: "#/definitions/DataDictionaryModel"
      - name: "dictionaryName"
        in: "path"
        description: "Data dictionary file name that will be updated"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Data dictionary successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Data dictionary not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "Dictionaries"
      summary: "deleteDictionary"
      description: "Deletes a data dictionary CSV file from the DQOps user's home\
        \ dictionaries/ folder."
      operationId: "deleteDictionary"
      produces:
      - "application/json"
      parameters:
      - name: "dictionaryName"
        in: "path"
        description: "Data dictionary name"
        required: true
        type: "string"
      responses:
        200:
          description: "Data dictionary CSV file successfully deleted"
          schema:
            $ref: "#/definitions/MonoVoid"
        404:
          description: "Data dictionary file not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/dictionaries/{dictionaryName}/download:
    get:
      tags:
      - "Dictionaries"
      summary: "downloadDictionary"
      description: "Downloads a data dictionary CSV file"
      operationId: "downloadDictionary"
      produces:
      - "text/csv"
      parameters:
      - name: "dictionaryName"
        in: "path"
        description: "Data dictionary CSV file name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              type: "string"
              format: "byte"
        404:
          description: "Data dictionary not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/environment/issueapikey:
    get:
      tags:
      - "Environment"
      summary: "issueApiKey"
      description: "Issues a local API Key for the calling user. This API Key can\
        \ be used to authenticate using the DQOps REST API client. This API Key should\
        \ be passed in the \"Authorization\" HTTP header in the format \"Authorization:\
        \ Bearer <api_key>\"."
      operationId: "issueApiKey"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "string"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/environment/profile:
    get:
      tags:
      - "Environment"
      summary: "getUserProfile"
      description: "Returns the profile of the current user."
      operationId: "getUserProfile"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/DqoUserProfileModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/environment/settings:
    get:
      tags:
      - "Environment"
      summary: "getDqoSettings"
      description: "Returns all effective DQOps configuration settings."
      operationId: "getDqoSettings"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/DqoSettingsModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/incidents/{connectionName}:
    get:
      tags:
      - "Incidents"
      summary: "findRecentIncidentsOnConnection"
      description: "Returns a list of recent data quality incidents."
      operationId: "findRecentIncidentsOnConnection"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "months"
        in: "query"
        description: "Number of recent months to load, the default is 3 months"
        required: false
        type: "integer"
        format: "int32"
      - name: "open"
        in: "query"
        description: "Returns open incidents, when the parameter is missing, the default\
          \ value is true"
        required: false
        type: "boolean"
      - name: "acknowledged"
        in: "query"
        description: "Returns acknowledged incidents, when the parameter is missing,\
          \ the default value is true"
        required: false
        type: "boolean"
      - name: "resolved"
        in: "query"
        description: "Returns resolved incidents, when the parameter is missing, the\
          \ default value is false"
        required: false
        type: "boolean"
      - name: "muted"
        in: "query"
        description: "Returns muted incidents, when the parameter is missing, the\
          \ default value is false"
        required: false
        type: "boolean"
      - name: "page"
        in: "query"
        description: "Page number, the first page is 1"
        required: false
        type: "integer"
        format: "int32"
      - name: "limit"
        in: "query"
        description: "Page size, the default is 50 rows"
        required: false
        type: "integer"
        format: "int32"
      - name: "filter"
        in: "query"
        description: "Optional full text search filter that supports *prefix, suffix*\
          \ and nest*ed filter expressions"
        required: false
        type: "string"
      - name: "order"
        in: "query"
        description: "Optional sort order, the default sort order is by the number\
          \ of failed data quality checks"
        required: false
        type: "string"
        enum:
        - "table"
        - "tablePriority"
        - "firstSeen"
        - "lastSeen"
        - "dataGroup"
        - "qualityDimension"
        - "checkName"
        - "highestSeverity"
        - "failedChecksCount"
      - name: "direction"
        in: "query"
        description: "Optional sort direction, the default sort direction is ascending"
        required: false
        type: "string"
        enum:
        - "asc"
        - "desc"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/IncidentModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/incidents/{connectionName}/{year}/{month}/{incidentId}:
    get:
      tags:
      - "Incidents"
      summary: "getIncident"
      description: "Return a single data quality incident's details."
      operationId: "getIncident"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "year"
        in: "path"
        description: "Year when the incident was first seen"
        required: true
        type: "integer"
        format: "int32"
      - name: "month"
        in: "path"
        description: "Month when the incident was first seen"
        required: true
        type: "integer"
        format: "int32"
      - name: "incidentId"
        in: "path"
        description: "Incident id"
        required: true
        type: "string"
      responses:
        200:
          description: "Incident returned"
          schema:
            $ref: "#/definitions/IncidentModel"
        404:
          description: "Incident not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/incidents/{connectionName}/{year}/{month}/{incidentId}/histogram:
    get:
      tags:
      - "Incidents"
      summary: "getIncidentHistogram"
      description: "Generates histograms of data quality issues for each day, returning\
        \ the number of data quality issues on that day. The other histograms are\
        \ by a column name and by a check name."
      operationId: "getIncidentHistogram"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "year"
        in: "path"
        description: "Year when the incident was first seen"
        required: true
        type: "integer"
        format: "int32"
      - name: "month"
        in: "path"
        description: "Month when the incident was first seen"
        required: true
        type: "integer"
        format: "int32"
      - name: "incidentId"
        in: "path"
        description: "Incident id"
        required: true
        type: "string"
      - name: "filter"
        in: "query"
        description: "Optional full text search filter that supports *prefix, suffix*\
          \ and nest*ed filter expressions"
        required: false
        type: "string"
      - name: "days"
        in: "query"
        description: "Optional filter for a number of recent days to read the related\
          \ issues"
        required: false
        type: "integer"
        format: "int32"
      - name: "date"
        in: "query"
        description: "Optional date filter"
        required: false
        type: "string"
        format: "date"
      - name: "column"
        in: "query"
        description: "Optional column name filter"
        required: false
        type: "string"
      - name: "check"
        in: "query"
        description: "Optional check name filter"
        required: false
        type: "string"
      responses:
        200:
          description: "Incidents' histograms returned"
          schema:
            $ref: "#/definitions/IncidentIssueHistogramModel"
        404:
          description: "Incident not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/incidents/{connectionName}/{year}/{month}/{incidentId}/issues:
    get:
      tags:
      - "Incidents"
      summary: "getIncidentIssues"
      description: "Return a paged list of failed data quality check results that\
        \ are related to an incident."
      operationId: "getIncidentIssues"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "year"
        in: "path"
        description: "Year when the incident was first seen"
        required: true
        type: "integer"
        format: "int32"
      - name: "month"
        in: "path"
        description: "Month when the incident was first seen"
        required: true
        type: "integer"
        format: "int32"
      - name: "incidentId"
        in: "path"
        description: "Incident id"
        required: true
        type: "string"
      - name: "page"
        in: "query"
        description: "Page number, the first page is 1"
        required: false
        type: "integer"
        format: "int32"
      - name: "limit"
        in: "query"
        description: "Page size, the default is 50 rows"
        required: false
        type: "integer"
        format: "int32"
      - name: "filter"
        in: "query"
        description: "Optional filter"
        required: false
        type: "string"
      - name: "days"
        in: "query"
        description: "Optional filter for a number of recent days to read the related\
          \ issues"
        required: false
        type: "integer"
        format: "int32"
      - name: "date"
        in: "query"
        description: "Optional filter to return data quality issues only for a given\
          \ date. The date should be an ISO8601 formatted date, it is treated as the\
          \ timezone of the DQOps server."
        required: false
        type: "string"
        format: "date"
      - name: "column"
        in: "query"
        description: "Optional column name filter"
        required: false
        type: "string"
      - name: "check"
        in: "query"
        description: "Optional check name filter"
        required: false
        type: "string"
      - name: "order"
        in: "query"
        description: "Optional sort order, the default sort order is by the execution\
          \ date"
        required: false
        type: "string"
        enum:
        - "executedAt"
        - "checkHash"
        - "checkCategory"
        - "checkName"
        - "checkDisplayName"
        - "checkType"
        - "actualValue"
        - "expectedValue"
        - "severity"
        - "columnName"
        - "dataGroup"
        - "timeGradient"
        - "timePeriod"
        - "qualityDimension"
        - "sensorName"
      - name: "direction"
        in: "query"
        description: "Optional sort direction, the default sort direction is ascending"
        required: false
        type: "string"
        enum:
        - "asc"
        - "desc"
      responses:
        200:
          description: "Incident returned"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/CheckResultEntryModel"
        404:
          description: "Incident not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/incidents/{connectionName}/{year}/{month}/{incidentId}/issueurl:
    post:
      tags:
      - "Incidents"
      summary: "setIncidentIssueUrl"
      description: "Changes the incident's issueUrl to a new status."
      operationId: "setIncidentIssueUrl"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "year"
        in: "path"
        description: "Year when the incident was first seen"
        required: true
        type: "integer"
        format: "int32"
      - name: "month"
        in: "path"
        description: "Month when the incident was first seen"
        required: true
        type: "integer"
        format: "int32"
      - name: "incidentId"
        in: "path"
        description: "Incident id"
        required: true
        type: "string"
      - name: "issueUrl"
        in: "query"
        description: "New incident's issueUrl"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Data quality incident's issueUrl successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/incidents/{connectionName}/{year}/{month}/{incidentId}/status:
    post:
      tags:
      - "Incidents"
      summary: "setIncidentStatus"
      description: "Changes the incident's status to a new status."
      operationId: "setIncidentStatus"
      produces:
      - "application/json"
      parameters:
      - name: "connectionName"
        in: "path"
        description: "Connection name"
        required: true
        type: "string"
      - name: "year"
        in: "path"
        description: "Year when the incident was first seen"
        required: true
        type: "integer"
        format: "int32"
      - name: "month"
        in: "path"
        description: "Month when the incident was first seen"
        required: true
        type: "integer"
        format: "int32"
      - name: "incidentId"
        in: "path"
        description: "Incident id"
        required: true
        type: "string"
      - name: "status"
        in: "query"
        description: "New incident status, supported values: open, acknowledged, resolved,\
          \ muted"
        required: true
        type: "string"
        enum:
        - "open"
        - "acknowledged"
        - "resolved"
        - "muted"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Data quality incident's status successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Connection was not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/incidentstat:
    get:
      tags:
      - "Incidents"
      summary: "findConnectionIncidentStats"
      description: "Returns a list of connection names with incident statistics -\
        \ the count of recent open incidents."
      operationId: "findConnectionIncidentStats"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/IncidentsPerConnectionModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/ishealthy:
    get:
      tags:
      - "Healthcheck"
      summary: "isHealthy"
      description: "Checks if the DQOps instance is healthy and operational. Returns\
        \ a text \"OK\" and a HTTP status code 200 when the service is active and\
        \ can accept jobs,  or returns a text \"UNAVAILABLE\" and a HTTP status code\
        \ 503 when the service is still starting or is shutting down."
      operationId: "isHealthy"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "string"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
        503:
          description: "DQOps instance is not healthy or is still starting"
  /api/jobs/collectstatistics/table:
    post:
      tags:
      - "Jobs"
      summary: "collectStatisticsOnTable"
      description: "Starts a new background job that will run selected data statistics\
        \ collectors for the entire table"
      operationId: "collectStatisticsOnTable"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Data statistics collectors filter"
        required: false
        schema:
          $ref: "#/definitions/StatisticsCollectorSearchFilters"
      - name: "jobBusinessKey"
        in: "query"
        description: "Optional job business key that is a user assigned unique job\
          \ id, used to check the job status by looking up the job by a user assigned\
          \ identifier, instead of the DQOps assigned job identifier."
        required: false
        type: "string"
      - name: "wait"
        in: "query"
        description: "Wait until the statistic collection job finishes to run, the\
          \ default value is true (queue a background job and wait for the job to\
          \ finish, up to waitTimeout seconds)"
        required: false
        type: "boolean"
      - name: "waitTimeout"
        in: "query"
        description: "The wait timeout in seconds, when the wait timeout elapses and\
          \ the job is still running, only the job id is returned without the results.\
          \ The default timeout is 120 seconds, but it can be reconfigured (see the\
          \ 'dqo' cli command documentation)."
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/CollectStatisticsQueueJobResult"
        201:
          description: "New job that will run data statistics collection was added\
            \ to the queue"
          schema:
            $ref: "#/definitions/CollectStatisticsQueueJobResult"
        400:
          description: "Bad request, adjust before retrying"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/collectstatistics/withgrouping:
    post:
      tags:
      - "Jobs"
      summary: "collectStatisticsOnDataGroups"
      description: "Starts a new background job that will run selected data statistics\
        \ collectors on tables, calculating separate metric for each data grouping"
      operationId: "collectStatisticsOnDataGroups"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Data statistics collectors filter"
        required: false
        schema:
          $ref: "#/definitions/StatisticsCollectorSearchFilters"
      - name: "jobBusinessKey"
        in: "query"
        description: "Optional job business key that is a user assigned unique job\
          \ id, used to check the job status by looking up the job by a user assigned\
          \ identifier, instead of the DQOps assigned job identifier."
        required: false
        type: "string"
      - name: "wait"
        in: "query"
        description: "Wait until the statistic collection job finishes to run, the\
          \ default value is true (queue a background job and wait for the job to\
          \ finish, up to waitTimeout seconds)"
        required: false
        type: "boolean"
      - name: "waitTimeout"
        in: "query"
        description: "The wait timeout in seconds, when the wait timeout elapses and\
          \ the job is still running, only the job id is returned without the results.\
          \ The default timeout is 120 seconds, but it can be reconfigured (see the\
          \ 'dqo' cli command documentation)."
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/CollectStatisticsQueueJobResult"
        201:
          description: "New job that will run data statistics collection was added\
            \ to the queue"
          schema:
            $ref: "#/definitions/CollectStatisticsQueueJobResult"
        400:
          description: "Bad request, adjust before retrying"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/deletestoreddata:
    post:
      tags:
      - "Jobs"
      summary: "deleteStoredData"
      description: "Starts a new background job that will delete stored data about\
        \ check results, sensor readouts etc."
      operationId: "deleteStoredData"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Delete stored data job parameters"
        required: false
        schema:
          $ref: "#/definitions/DeleteStoredDataQueueJobParameters"
      - name: "jobBusinessKey"
        in: "query"
        description: "Optional job business key that is a user assigned unique job\
          \ id, used to check the job status by looking up the job by a user assigned\
          \ identifier, instead of the DQOps assigned job identifier."
        required: false
        type: "string"
      - name: "wait"
        in: "query"
        description: "Wait until the import tables job finishes to run, the default\
          \ value is true (queue a background job and wait for the job to finish,\
          \ up to waitTimeout seconds)"
        required: false
        type: "boolean"
      - name: "waitTimeout"
        in: "query"
        description: "The wait timeout in seconds, when the wait timeout elapses and\
          \ the delete stored data job is still running, only the job id is returned\
          \ without the results. The default timeout is 120 seconds, but it can be\
          \ reconfigured (see the 'dqo' cli command documentation)."
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/DeleteStoredDataQueueJobResult"
        201:
          description: "New job that will delete stored registry data was added to\
            \ the queue"
          schema:
            $ref: "#/definitions/DeleteStoredDataQueueJobResult"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/importtables:
    post:
      tags:
      - "Jobs"
      summary: "importTables"
      description: "Starts a new background job that will import selected tables."
      operationId: "importTables"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Import tables job parameters"
        required: false
        schema:
          $ref: "#/definitions/ImportTablesQueueJobParameters"
      - name: "jobBusinessKey"
        in: "query"
        description: "Optional job business key that is a user assigned unique job\
          \ id, used to check the job status by looking up the job by a user assigned\
          \ identifier, instead of the DQOps assigned job identifier."
        required: false
        type: "string"
      - name: "wait"
        in: "query"
        description: "Wait until the import tables job finishes to run, the default\
          \ value is true (queue a background job and wait for the job to finish,\
          \ up to waitTimeout seconds)"
        required: false
        type: "boolean"
      - name: "waitTimeout"
        in: "query"
        description: "The wait timeout in seconds, when the wait timeout elapses and\
          \ the import tables job is still running, only the job id is returned without\
          \ the results. The default timeout is 120 seconds, but it can be reconfigured\
          \ (see the 'dqo' cli command documentation)."
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/ImportTablesQueueJobResult"
        201:
          description: "New job that will import selected tables was added to the\
            \ queue"
          schema:
            $ref: "#/definitions/ImportTablesQueueJobResult"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/jobchangessince/{sequenceNumber}:
    get:
      tags:
      - "Jobs"
      summary: "getJobChangesSince"
      description: "Retrieves an incremental list of job changes (new jobs or job\
        \ status changes)"
      operationId: "getJobChangesSince"
      produces:
      - "application/json"
      parameters:
      - name: "sequenceNumber"
        in: "path"
        description: "Change sequence number to get job changes after that sequence"
        required: true
        type: "integer"
        format: "int64"
      responses:
        200:
          description: "A list of all queued and finished jobs returned. Call jobchangessince/{sequenceNumber}\
            \ to receive incremental changes."
          schema:
            $ref: "#/definitions/DqoJobQueueIncrementalSnapshotModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/jobs:
    get:
      tags:
      - "Jobs"
      summary: "getAllJobs"
      description: "Retrieves a list of all queued and recently finished jobs."
      operationId: "getAllJobs"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "A list of all queued and finished jobs returned. Call jobchangessince/{changeSequence}\
            \ to receive incremental changes."
          schema:
            $ref: "#/definitions/DqoJobQueueInitialSnapshotModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/jobs/{jobId}:
    get:
      tags:
      - "Jobs"
      summary: "getJob"
      description: "Retrieves the current status of a single job, identified by a\
        \ job id."
      operationId: "getJob"
      produces:
      - "application/json"
      parameters:
      - name: "jobId"
        in: "path"
        description: "Job id"
        required: true
        type: "string"
      responses:
        200:
          description: "Retrieves the current status of a single job, identified by\
            \ a job id."
          schema:
            $ref: "#/definitions/DqoJobHistoryEntryModel"
        404:
          description: "The job was not found or it has finished and was already been\
            \ removed from the job history store."
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "Jobs"
      summary: "cancelJob"
      description: "Cancels a running job"
      operationId: "cancelJob"
      produces:
      - "application/json"
      parameters:
      - name: "jobId"
        in: "path"
        description: "Job id"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Job was cancelled"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/jobs/{jobId}/wait:
    get:
      tags:
      - "Jobs"
      summary: "waitForJob"
      description: "Waits for a job to finish. Returns the status of a finished job\
        \ or a current state of a job that is still running, but the wait timeout\
        \ elapsed."
      operationId: "waitForJob"
      produces:
      - "application/json"
      parameters:
      - name: "jobId"
        in: "path"
        description: "Job id"
        required: true
        type: "string"
      - name: "waitTimeout"
        in: "query"
        description: "The wait timeout in seconds, when the wait timeout elapses and\
          \ the job is still running, the method returns the job model that is not\
          \ yet finished and has no results. The default timeout is 120 seconds, but\
          \ it can be reconfigured (see the 'dqo' cli command documentation)."
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "The job status was returned. If the response is returned before\
            \ the wait timeout, the response will contain information about a finished\
            \ job. When the wait timeout has elapsed, the job status could be still\
            \ queued or running."
          schema:
            $ref: "#/definitions/DqoJobHistoryEntryModel"
        404:
          description: "The job was not found or it has finished and was already been\
            \ removed from the job history store."
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/runchecks:
    post:
      tags:
      - "Jobs"
      summary: "runChecks"
      description: "Starts a new background job that will run selected data quality\
        \ checks"
      operationId: "runChecks"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Data quality check run configuration (target checks and an optional\
          \ time range)"
        required: false
        schema:
          $ref: "#/definitions/RunChecksParameters"
      - name: "jobBusinessKey"
        in: "query"
        description: "Optional job business key that is a user assigned unique job\
          \ id, used to check the job status by looking up the job by a user assigned\
          \ identifier, instead of the DQOps assigned job identifier."
        required: false
        type: "string"
      - name: "wait"
        in: "query"
        description: "Wait until the checks finish to run, the default value is true\
          \ (queue a background job and wait for the job to finish, up to waitTimeout\
          \ seconds)"
        required: false
        type: "boolean"
      - name: "waitTimeout"
        in: "query"
        description: "The wait timeout in seconds, when the wait timeout elapses and\
          \ the checks are still running, only the job id is returned without the\
          \ results. The default timeout is 120 seconds, but it can be reconfigured\
          \ (see the 'dqo' cli command documentation)."
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/RunChecksQueueJobResult"
        201:
          description: "New job that will run data quality checks was added to the\
            \ queue"
          schema:
            $ref: "#/definitions/RunChecksQueueJobResult"
        400:
          description: "Bad request, adjust before retrying"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/runchecks/{jobId}/wait:
    get:
      tags:
      - "Jobs"
      summary: "waitForRunChecksJob"
      description: "Waits for a job to finish. Returns the status of a finished job\
        \ or a current state of a job that is still running, but the wait timeout\
        \ elapsed."
      operationId: "waitForRunChecksJob"
      produces:
      - "application/json"
      parameters:
      - name: "jobId"
        in: "path"
        description: "Job id, it can be a job business key assigned to the job or\
          \ a job id generated by DQOps"
        required: true
        type: "string"
      - name: "waitTimeout"
        in: "query"
        description: "The wait timeout in seconds, when the wait timeout elapses and\
          \ the job is still running, the method returns the job model that is not\
          \ yet finished and has no results. The default timeout is 120 seconds, but\
          \ it can be reconfigured (see the 'dqo' cli command documentation)."
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "Run checks job information returned. When the wait timeout\
            \ has elapsed, the job status could be still queued or running and the\
            \ result will be missing."
          schema:
            $ref: "#/definitions/RunChecksQueueJobResult"
        404:
          description: "The job was not found or it has finished and was already been\
            \ removed from the job history store."
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/scheduler/isrunning:
    get:
      tags:
      - "Jobs"
      summary: "isCronSchedulerRunning"
      description: "Checks if the DQOps internal CRON scheduler is running and processing\
        \ jobs scheduled using cron expressions."
      operationId: "isCronSchedulerRunning"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "The cron scheduler status was checked and returned"
          schema:
            type: "boolean"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/scheduler/status/start:
    post:
      tags:
      - "Jobs"
      summary: "startCronScheduler"
      description: "Starts the job scheduler that runs monitoring jobs that are scheduled\
        \ by assigning cron expressions."
      operationId: "startCronScheduler"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "The cron scheduler was started or was already running"
          schema:
            $ref: "#/definitions/MonoVoid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/scheduler/status/stop:
    post:
      tags:
      - "Jobs"
      summary: "stopCronScheduler"
      description: "Stops the job scheduler that runs monitoring jobs that are scheduled\
        \ by assigning cron expressions."
      operationId: "stopCronScheduler"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "The cron scheduler was stopped or was already not running"
          schema:
            $ref: "#/definitions/MonoVoid"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/jobs/synchronize:
    post:
      tags:
      - "Jobs"
      summary: "synchronizeFolders"
      description: "Starts multiple file synchronization jobs that will synchronize\
        \ files from selected DQOps User home folders to the DQOps Cloud. The default\
        \ synchronization mode is a full synchronization (upload local files, download\
        \ new files from the cloud)."
      operationId: "synchronizeFolders"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Selection of folders that should be synchronized to the DQOps\
          \ Cloud"
        required: false
        schema:
          $ref: "#/definitions/SynchronizeMultipleFoldersDqoQueueJobParameters"
      - name: "jobBusinessKey"
        in: "query"
        description: "Optional job business key that is a user assigned unique job\
          \ id, used to check the job status by looking up the job by a user assigned\
          \ identifier, instead of the DQOps assigned job identifier."
        required: false
        type: "string"
      - name: "wait"
        in: "query"
        description: "Wait until the synchronize multiple folders job finishes to\
          \ run, the default value is true (queue a background job and wait for the\
          \ job to finish, up to waitTimeout seconds)"
        required: false
        type: "boolean"
      - name: "waitTimeout"
        in: "query"
        description: "The wait timeout in seconds, when the wait timeout elapses and\
          \ the synchronization with the DQOps Cloud is still running, only the job\
          \ id is returned without the results. The default timeout is 120 seconds,\
          \ but it can be reconfigured (see the 'dqo' cli command documentation)."
        required: false
        type: "integer"
        format: "int32"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/SynchronizeMultipleFoldersQueueJobResult"
        201:
          description: "New jobs that will synchronize folders were added to the queue"
          schema:
            $ref: "#/definitions/SynchronizeMultipleFoldersQueueJobResult"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/labels/columns:
    get:
      tags:
      - "Labels"
      summary: "getAllLabelsForColumns"
      description: "Returns a list of all labels applied to columns, including the\
        \ count of assignments to these data assets."
      operationId: "getAllLabelsForColumns"
      produces:
      - "application/json"
      parameters:
      - name: "page"
        in: "query"
        description: "Page number, the first page is 1"
        required: false
        type: "integer"
        format: "int32"
      - name: "limit"
        in: "query"
        description: "Page size, the default is 100 rows, but paging is disabled is\
          \ neither page and limit parameters are provided"
        required: false
        type: "integer"
        format: "int32"
      - name: "prefix"
        in: "query"
        description: "Optional filter for the prefix of labels. For example, when\
          \ the prefix is \"address\", this operation will return labels \"address/city\"\
          \ and \"address/country\", but not \"address\"."
        required: false
        type: "string"
      - name: "filter"
        in: "query"
        description: "Optional table name filter"
        required: false
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/LabelModel"
        404:
          description: "Label prefix not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/labels/connections:
    get:
      tags:
      - "Labels"
      summary: "getAllLabelsForConnections"
      description: "Returns a list of all labels applied to the connections to data\
        \ sources, including the count of assignments to these data assets."
      operationId: "getAllLabelsForConnections"
      produces:
      - "application/json"
      parameters:
      - name: "page"
        in: "query"
        description: "Page number, the first page is 1"
        required: false
        type: "integer"
        format: "int32"
      - name: "limit"
        in: "query"
        description: "Page size, the default is 100 rows, but paging is disabled is\
          \ neither page and limit parameters are provided"
        required: false
        type: "integer"
        format: "int32"
      - name: "prefix"
        in: "query"
        description: "Optional filter for the prefix of labels. For example, when\
          \ the prefix is \"address\", this operation will return labels \"address/city\"\
          \ and \"address/country\", but not \"address\"."
        required: false
        type: "string"
      - name: "filter"
        in: "query"
        description: "Optional table name filter"
        required: false
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/LabelModel"
        404:
          description: "Label prefix not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/labels/tables:
    get:
      tags:
      - "Labels"
      summary: "getAllLabelsForTables"
      description: "Returns a list of all labels applied to tables, including the\
        \ count of assignments to these data assets."
      operationId: "getAllLabelsForTables"
      produces:
      - "application/json"
      parameters:
      - name: "page"
        in: "query"
        description: "Page number, the first page is 1"
        required: false
        type: "integer"
        format: "int32"
      - name: "limit"
        in: "query"
        description: "Page size, the default is 100 rows, but paging is disabled is\
          \ neither page and limit parameters are provided"
        required: false
        type: "integer"
        format: "int32"
      - name: "prefix"
        in: "query"
        description: "Optional filter for the prefix of labels. For example, when\
          \ the prefix is \"address\", this operation will return labels \"address/city\"\
          \ and \"address/country\", but not \"address\"."
        required: false
        type: "string"
      - name: "filter"
        in: "query"
        description: "Optional table name filter"
        required: false
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/LabelModel"
        404:
          description: "Label prefix not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/logs/debug:
    post:
      tags:
      - "LogShipping"
      summary: "logDebug"
      description: "Logs an information message in the server's logs as a debug severity\
        \ log entry."
      operationId: "logDebug"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Log entry"
        required: false
        schema:
          $ref: "#/definitions/ExternalLogEntry"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Log entry was logged on the server"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/logs/error:
    post:
      tags:
      - "LogShipping"
      summary: "logError"
      description: "Logs an information message in the server's logs as an error severity\
        \ log entry."
      operationId: "logError"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Log entry"
        required: false
        schema:
          $ref: "#/definitions/ExternalLogEntry"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Log entry was logged on the server"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/logs/info:
    post:
      tags:
      - "LogShipping"
      summary: "logInfo"
      description: "Logs an information message in the server's logs as an info severity\
        \ log entry."
      operationId: "logInfo"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Log entry"
        required: false
        schema:
          $ref: "#/definitions/ExternalLogEntry"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Log entry was logged on the server"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/logs/warn:
    post:
      tags:
      - "LogShipping"
      summary: "logWarn"
      description: "Logs an information message in the server's logs as a warn severity\
        \ log entry."
      operationId: "logWarn"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Log entry"
        required: false
        schema:
          $ref: "#/definitions/ExternalLogEntry"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Log entry was logged on the server"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/mypassword:
    put:
      tags:
      - "Users"
      summary: "changeCallerPassword"
      description: "Changes the password of the calling user. When the user is identified\
        \ by the DQOps local API key, it is the user whose email is stored in the\
        \ DQOps API Key."
      operationId: "changeCallerPassword"
      consumes:
      - "text/plain"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "New Password"
        required: false
        schema:
          type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "Password successfully updated"
        403:
          description: "DQOps instance is not authenticated to DQOps Cloud"
        406:
          description: "Rejected, missing required fields or the required fields are\
            \ empty"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/rules:
    get:
      tags:
      - "Rules"
      summary: "getAllRules"
      description: "Returns a flat list of all rules available in DQOps, both built-in\
        \ rules and user defined or customized rules."
      operationId: "getAllRules"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/RuleListModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/rules/{fullRuleName}:
    get:
      tags:
      - "Rules"
      summary: "getRule"
      description: "Returns a rule definition"
      operationId: "getRule"
      produces:
      - "application/json"
      parameters:
      - name: "fullRuleName"
        in: "path"
        description: "Full rule name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/RuleModel"
        404:
          description: "Rule name not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "Rules"
      summary: "createRule"
      description: "Creates (adds) a new custom rule given the rule definition."
      operationId: "createRule"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "fullRuleName"
        in: "path"
        description: "Full rule name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Rule model"
        required: false
        schema:
          $ref: "#/definitions/RuleModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New custom rule successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Custom rule with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Rules"
      summary: "updateRule"
      description: "Updates an existing rule, making a custom rule definition if it\
        \ is not present"
      operationId: "updateRule"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "Rule model"
        required: false
        schema:
          $ref: "#/definitions/RuleModel"
      - name: "fullRuleName"
        in: "path"
        description: "Full rule name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Custom rule successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Rule not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "Rules"
      summary: "deleteRule"
      description: "Deletes a custom rule definition"
      operationId: "deleteRule"
      produces:
      - "application/json"
      parameters:
      - name: "fullRuleName"
        in: "path"
        description: "Full rule name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Custom rule definition successfully deleted"
        404:
          description: "Custom rule not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/search/columns:
    get:
      tags:
      - "Search"
      summary: "findColumns"
      description: "Finds columns in any data source and schema"
      operationId: "findColumns"
      produces:
      - "application/json"
      parameters:
      - name: "connection"
        in: "query"
        description: "Optional connection name filter, accepts filters in the form:\
          \ fullname, *suffix, prefix*, *contains*."
        required: false
        type: "string"
      - name: "schema"
        in: "query"
        description: "Optional schema name filter, accepts filters in the form: fullname,\
          \ *suffix, prefix*, *contains*."
        required: false
        type: "string"
      - name: "table"
        in: "query"
        description: "Optional table name filter"
        required: false
        type: "string"
      - name: "column"
        in: "query"
        description: "Optional column name filter"
        required: false
        type: "string"
      - name: "columnType"
        in: "query"
        description: "Optional physical column's data type filter"
        required: false
        type: "string"
      - name: "label"
        in: "query"
        description: "Optional labels to filter the columns"
        required: false
        type: "array"
        items:
          type: "string"
        collectionFormat: "multi"
      - name: "page"
        in: "query"
        description: "Page number, the first page is 1"
        required: false
        type: "integer"
        format: "int32"
      - name: "limit"
        in: "query"
        description: "Page size, the default is 100 rows, but paging is disabled is\
          \ neither page and limit parameters are provided"
        required: false
        type: "integer"
        format: "int32"
      - name: "checkType"
        in: "query"
        description: "Optional parameter for the check type, when provided, returns\
          \ the results for data quality dimensions for the data quality checks of\
          \ that type"
        required: false
        type: "string"
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/ColumnListModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/search/tables:
    get:
      tags:
      - "Search"
      summary: "findTables"
      description: "Finds tables in any data source and schema"
      operationId: "findTables"
      produces:
      - "application/json"
      parameters:
      - name: "connection"
        in: "query"
        description: "Optional connection name filter, accepts filters in the form:\
          \ fullname, *suffix, prefix*, *contains*."
        required: false
        type: "string"
      - name: "schema"
        in: "query"
        description: "Optional schema name filter, accepts filters in the form: fullname,\
          \ *suffix, prefix*, *contains*."
        required: false
        type: "string"
      - name: "table"
        in: "query"
        description: "Optional table name filter"
        required: false
        type: "string"
      - name: "label"
        in: "query"
        description: "Optional labels to filter the tables"
        required: false
        type: "array"
        items:
          type: "string"
        collectionFormat: "multi"
      - name: "page"
        in: "query"
        description: "Page number, the first page is 1"
        required: false
        type: "integer"
        format: "int32"
      - name: "limit"
        in: "query"
        description: "Page size, the default is 100 rows, but paging is disabled is\
          \ neither page and limit parameters are provided"
        required: false
        type: "integer"
        format: "int32"
      - name: "checkType"
        in: "query"
        description: "Optional parameter for the check type, when provided, returns\
          \ the results for data quality dimensions for the data quality checks of\
          \ that type"
        required: false
        type: "string"
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/TableListModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/sensors:
    get:
      tags:
      - "Sensors"
      summary: "getAllSensors"
      description: "Returns a flat list of all sensors available in DQOps, both built-in\
        \ sensors and user defined or customized sensors."
      operationId: "getAllSensors"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/SensorListModel"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/sensors/{fullSensorName}:
    get:
      tags:
      - "Sensors"
      summary: "getSensor"
      description: "Returns a sensor model"
      operationId: "getSensor"
      produces:
      - "application/json"
      parameters:
      - name: "fullSensorName"
        in: "path"
        description: "Full sensor name"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/SensorModel"
        404:
          description: "Sensor name not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "Sensors"
      summary: "createSensor"
      description: "Creates (adds) a new sensor given sensor information."
      operationId: "createSensor"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "fullSensorName"
        in: "path"
        description: "Full sensor name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Dictionary of sensor definitions"
        required: false
        schema:
          $ref: "#/definitions/SensorModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New sensor successfully created"
        400:
          description: "Bad request, adjust before retrying"
        406:
          description: "Rejected, missing required fields"
        409:
          description: "Sensor with the same name already exists"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Sensors"
      summary: "updateSensor"
      description: "Updates an existing sensor, making a custom sensor definition\
        \ if it is not present. \nRemoves sensor if custom definition is same as Dqo\
        \ Home sensor"
      operationId: "updateSensor"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "fullSensorName"
        in: "path"
        description: "Full sensor name"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "Dictionary of sensor definitions"
        required: false
        schema:
          $ref: "#/definitions/SensorModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Sensor model successfully updated"
        400:
          description: "Bad request, adjust before retrying"
        404:
          description: "Sensor not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "Sensors"
      summary: "deleteSensor"
      description: "Deletes a custom sensor definition"
      operationId: "deleteSensor"
      produces:
      - "application/json"
      parameters:
      - name: "fullSensorName"
        in: "path"
        description: "Full sensor name"
        required: true
        type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        204:
          description: "Custom sensor definition successfully deleted"
        404:
          description: "Custom sensor not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/timezones:
    get:
      tags:
      - "Timezones"
      summary: "getAvailableZoneIds"
      description: "Returns a list of available time zone ids"
      operationId: "getAvailableZoneIds"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              type: "string"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/users:
    get:
      tags:
      - "Users"
      summary: "getAllUsers"
      description: "Returns a list of all users."
      operationId: "getAllUsers"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "OK"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/DqoCloudUserModel"
        403:
          description: "DQOps instance is not authenticated to DQOps Cloud"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    post:
      tags:
      - "Users"
      summary: "createUser"
      description: "Creates (adds) a new user to a multi-user account."
      operationId: "createUser"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - in: "body"
        name: "body"
        description: "User model"
        required: false
        schema:
          $ref: "#/definitions/DqoCloudUserModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "New user successfully added"
        400:
          description: "User limit exceeded"
        403:
          description: "DQOps instance is not authenticated to DQOps Cloud"
        406:
          description: "Rejected, missing required fields"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/users/{email}:
    get:
      tags:
      - "Users"
      summary: "getUser"
      description: "Returns the user model that describes the role of a user identified\
        \ by an email"
      operationId: "getUser"
      produces:
      - "application/json"
      parameters:
      - name: "email"
        in: "path"
        description: "User's email"
        required: true
        type: "string"
      responses:
        200:
          description: "OK"
          schema:
            $ref: "#/definitions/DqoCloudUserModel"
        403:
          description: "DQOps instance is not authenticated to DQOps Cloud"
        404:
          description: "User not found"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    put:
      tags:
      - "Users"
      summary: "updateUser"
      description: "Updates a user in a multi-user account. The user's email cannot\
        \ be changed."
      operationId: "updateUser"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "email"
        in: "path"
        description: "User's email"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "User model"
        required: false
        schema:
          $ref: "#/definitions/DqoCloudUserModel"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "User successfully updated"
        403:
          description: "DQOps instance is not authenticated to DQOps Cloud"
        406:
          description: "Rejected, missing required fields or the email does not match"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
    delete:
      tags:
      - "Users"
      summary: "deleteUser"
      description: "Deletes a user from a multi-user account."
      operationId: "deleteUser"
      produces:
      - "application/json"
      parameters:
      - name: "email"
        in: "path"
        description: "User's email"
        required: true
        type: "string"
      responses:
        200:
          description: "User deleted"
          schema:
            $ref: "#/definitions/MonoVoid"
        403:
          description: "DQOps instance is not authenticated to DQOps Cloud"
        404:
          description: "User not found"
        406:
          description: "User's email is not provided"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
  /api/users/{email}/password:
    put:
      tags:
      - "Users"
      summary: "changeUserPassword"
      description: "Changes the password of a user identified by the email."
      operationId: "changeUserPassword"
      consumes:
      - "text/plain"
      produces:
      - "application/json"
      parameters:
      - name: "email"
        in: "path"
        description: "User's email"
        required: true
        type: "string"
      - in: "body"
        name: "body"
        description: "New Password"
        required: false
        schema:
          type: "string"
      responses:
        200:
          description: "successful operation"
          schema:
            $ref: "#/definitions/MonoVoid"
        201:
          description: "Password successfully updated"
        403:
          description: "DQOps instance is not authenticated to DQOps Cloud"
        406:
          description: "Rejected, missing required fields or the required fields are\
            \ empty"
        500:
          description: "Internal Server Error"
          schema:
            $ref: "#/definitions/SpringErrorPayload"
      security:
      - authorization_bearer_api_key: []
securityDefinitions:
  authorization_bearer_api_key:
    description: "API Key passed as \"Bearer <api_key>\". Two types of API Keys are\
      \ supported. The first type is an API Key issued by DQOps Cloud for single user\
      \ instances. The second type is a locally issued API Key that is signed by this\
      \ DQOps instance. Issue the API Key from the user's profile screen."
    type: "apiKey"
    name: "Authorization"
    in: "header"
definitions:
  AllChecksPatchParameters:
    type: "object"
    properties:
      check_search_filters:
        description: "Filters addressing basic tree search parameters. These filters\
          \ takes precedence over other selectors."
        $ref: "#/definitions/CheckSearchFilters"
      check_model_patch:
        description: "Sample configured check model which will pasted onto selected\
          \ checks."
        $ref: "#/definitions/CheckModel"
      selected_tables_to_columns:
        type: "object"
        description: "List of concrete table and column names which will be the target.\
          \ Column mappings are ignored for table level checks. This filter is applied\
          \ at the end."
        additionalProperties:
          type: "array"
          items:
            type: "string"
      override_conflicts:
        type: "boolean"
        description: "Override existing configurations if they're present. If false,\
          \ apply updates only to the fields for which no configuration exists."
    description: "Parameter object for creating pruned patch trees of all checks that\
      \ fit the filters."
  AnomalyDifferencingPercentileMovingAverageRuleError05PctParametersSpec:
    type: "object"
    properties:
      anomaly_percent:
        type: "number"
        format: "double"
        description: "The probability (in percent) that the current sensor readout\
          \ (measure) is an anomaly, because the value is outside the regular range\
          \ of previous readouts. The default time window of 90 time periods (days,\
          \ etc.) is used, but at least 30 readouts must exist to run the calculation."
  AnomalyDifferencingPercentileMovingAverageRuleFatal01PctParametersSpec:
    type: "object"
    properties:
      anomaly_percent:
        type: "number"
        format: "double"
        description: "The probability (in percent) that the current sensor readout\
          \ (measure) is an anomaly, because the value is outside the regular range\
          \ of previous readouts. The default time window of 90 time periods (days,\
          \ etc.) is used, but at least 30 readouts must exist to run the calculation."
  AnomalyDifferencingPercentileMovingAverageRuleWarning1PctParametersSpec:
    type: "object"
    properties:
      anomaly_percent:
        type: "number"
        format: "double"
        description: "The probability (in percent) that the current sensor readout\
          \ (measure) is an anomaly, because the value is outside the regular range\
          \ of previous readouts. The default time window of 90 time periods (days,\
          \ etc.) is used, but at least 30 readouts must exist to run the calculation."
  AnomalyStationaryPercentileMovingAverageRuleError05PctParametersSpec:
    type: "object"
    properties:
      anomaly_percent:
        type: "number"
        format: "double"
        description: "The probability (in percent) that the current sensor readout\
          \ (measure) is an anomaly, because the value is outside the regular range\
          \ of previous readouts. The default time window of 90 time periods (days,\
          \ etc.) is used, but at least 30 readouts must exist to run the calculation."
  AnomalyStationaryPercentileMovingAverageRuleFatal01PctParametersSpec:
    type: "object"
    properties:
      anomaly_percent:
        type: "number"
        format: "double"
        description: "The probability (in percent) that the current sensor readout\
          \ (measure) is an anomaly, because the value is outside the regular range\
          \ of previous readouts. The default time window of 90 time periods (days,\
          \ etc.) is used, but at least 30 readouts must exist to run the calculation."
  AnomalyStationaryPercentileMovingAverageRuleWarning1PctParametersSpec:
    type: "object"
    properties:
      anomaly_percent:
        type: "number"
        format: "double"
        description: "The probability (in percent) that the current sensor readout\
          \ (measure) is an anomaly, because the value is outside the regular range\
          \ of previous readouts. The default time window of 90 time periods (days,\
          \ etc.) is used, but at least 30 readouts must exist to run the calculation."
  AuthenticatedDashboardModel:
    type: "object"
    properties:
      folder_path:
        type: "string"
        description: "Folder path"
      dashboard:
        description: "Dashboard model with an unauthenticated url"
        $ref: "#/definitions/DashboardSpec"
      authenticated_dashboard_url:
        type: "string"
        description: "Dashboard authenticated url with a short lived refresh token"
    description: "Describes a single authenticated dashboard."
  BetweenFloatsRuleParametersSpec:
    type: "object"
    properties:
      from:
        type: "number"
        format: "double"
        description: "Minimum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
      to:
        type: "number"
        format: "double"
        description: "Maximum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  BetweenIntsRuleParametersSpec:
    type: "object"
    properties:
      from:
        type: "integer"
        format: "int64"
        description: "Minimum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
      to:
        type: "integer"
        format: "int64"
        description: "Maximum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  BetweenPercentRuleParametersSpec:
    type: "object"
    properties:
      min_percent:
        type: "number"
        format: "double"
        description: "Minimum accepted percentage of rows passing the check (inclusive)."
      max_percent:
        type: "number"
        format: "double"
        description: "Maximum accepted percentage of rows passing the check (inclusive)."
  BigQueryParametersSpec:
    type: "object"
    properties:
      source_project_id:
        type: "string"
        description: "Source GCP project ID. This is the project that has datasets\
          \ that will be imported."
      jobs_create_project:
        type: "string"
        description: "Configures the way how to select the project that will be used\
          \ to start BigQuery jobs and will be used for billing. The user/service\
          \ identified by the credentials must have bigquery.jobs.create permission\
          \ in that project."
        enum:
        - "create_jobs_in_source_project"
        - "create_jobs_in_default_project_from_credentials"
        - "create_jobs_in_selected_billing_project_id"
      billing_project_id:
        type: "string"
        description: "Billing GCP project ID. This is the project used as the default\
          \ GCP project. The calling user must have a bigquery.jobs.create permission\
          \ in this project."
      authentication_mode:
        type: "string"
        description: "Authentication mode to the Google Cloud."
        enum:
        - "google_application_credentials"
        - "json_key_content"
        - "json_key_path"
      json_key_content:
        type: "string"
        description: "JSON key content. Use an environment variable that contains\
          \ the content of the key as ${KEY_ENV} or a name of a secret in the GCP\
          \ Secret Manager: ${sm://key-secret-name}. Requires the authentication-mode:\
          \ json_key_content."
      json_key_path:
        type: "string"
        description: "A path to the JSON key file. Requires the authentication-mode:\
          \ json_key_path."
      quota_project_id:
        type: "string"
        description: "Quota GCP project ID."
  BulkCheckDeactivateParameters:
    type: "object"
    properties:
      check_search_filters:
        description: "Filters addressing basic tree search parameters. These filters\
          \ takes precedence over other selectors."
        $ref: "#/definitions/CheckSearchFilters"
      selected_tables_to_columns:
        type: "object"
        description: "List of concrete table and column names which will be the target.\
          \ Column mappings are ignored for table level checks. This filter is applied\
          \ at the end."
        additionalProperties:
          type: "array"
          items:
            type: "string"
    description: "Parameter object for deactivating all checks that fit the filters."
  ChangePercent1DayRule10ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to a readout\
          \ 1 day ago (inclusive)."
      exact_day:
        type: "boolean"
        description: "When the exact_day parameter is unchecked (exact_day: false),\
          \ the rule search for the most recent sensor readouts from the past 60 days\
          \ and compares them. If the parameter is selected (exact_day: true), the\
          \ rule compares only with the results from the past 1 day. If no results\
          \ are found from that time, no results or errors will be generated."
  ChangePercent1DayRule20ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to a readout\
          \ 1 day ago (inclusive)."
      exact_day:
        type: "boolean"
        description: "When the exact_day parameter is unchecked (exact_day: false),\
          \ the rule search for the most recent sensor readouts from the past 60 days\
          \ and compares them. If the parameter is selected (exact_day: true), the\
          \ rule compares only with the results from the past 1 day. If no results\
          \ are found from that time, no results or errors will be generated."
  ChangePercent1DayRule50ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to a readout\
          \ 1 day ago (inclusive)."
      exact_day:
        type: "boolean"
        description: "When the exact_day parameter is unchecked (exact_day: false),\
          \ the rule search for the most recent sensor readouts from the past 60 days\
          \ and compares them. If the parameter is selected (exact_day: true), the\
          \ rule compares only with the results from the past 1 day. If no results\
          \ are found from that time, no results or errors will be generated."
  ChangePercent30DaysRule10ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to a readout\
          \ 30 days ago (inclusive)."
      exact_day:
        type: "boolean"
        description: "When the exact_day parameter is unchecked (exact_day: false),\
          \ rule searches for the most recent sensor readouts from the past 60 days\
          \ and compares them. If the parameter is selected (exact_day: true), the\
          \ rule compares only with the results from the past 30 days. If no results\
          \ are found from that time, no results or errors will be generated."
  ChangePercent30DaysRule20ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to a readout\
          \ 30 days ago (inclusive)."
      exact_day:
        type: "boolean"
        description: "When the exact_day parameter is unchecked (exact_day: false),\
          \ rule searches for the most recent sensor readouts from the past 60 days\
          \ and compares them. If the parameter is selected (exact_day: true), the\
          \ rule compares only with the results from the past 30 days. If no results\
          \ are found from that time, no results or errors will be generated."
  ChangePercent30DaysRule50ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to a readout\
          \ 30 days ago (inclusive)."
      exact_day:
        type: "boolean"
        description: "When the exact_day parameter is unchecked (exact_day: false),\
          \ rule searches for the most recent sensor readouts from the past 60 days\
          \ and compares them. If the parameter is selected (exact_day: true), the\
          \ rule compares only with the results from the past 30 days. If no results\
          \ are found from that time, no results or errors will be generated."
  ChangePercent7DaysRule10ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to a readout\
          \ 7 days ago (inclusive)."
      exact_day:
        type: "boolean"
        description: "When the exact_day parameter is unchecked (exact_day: false),\
          \ rule searches for the most recent sensor readouts from the past 60 days\
          \ and compares them. If the parameter is selected (exact_day: true), the\
          \ rule compares only with the results from the past 7 days. If no results\
          \ are found from that time, no results or errors will be generated."
  ChangePercent7DaysRule20ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to a readout\
          \ 7 days ago (inclusive)."
      exact_day:
        type: "boolean"
        description: "When the exact_day parameter is unchecked (exact_day: false),\
          \ rule searches for the most recent sensor readouts from the past 60 days\
          \ and compares them. If the parameter is selected (exact_day: true), the\
          \ rule compares only with the results from the past 7 days. If no results\
          \ are found from that time, no results or errors will be generated."
  ChangePercent7DaysRule50ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to a readout\
          \ 7 days ago (inclusive)."
      exact_day:
        type: "boolean"
        description: "When the exact_day parameter is unchecked (exact_day: false),\
          \ rule searches for the most recent sensor readouts from the past 60 days\
          \ and compares them. If the parameter is selected (exact_day: true), the\
          \ rule compares only with the results from the past 7 days. If no results\
          \ are found from that time, no results or errors will be generated."
  ChangePercentRule10ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to previous readout\
          \ (inclusive)."
  ChangePercentRule20ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to previous readout\
          \ (inclusive)."
  ChangePercentRule50ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Percentage of maximum accepted change compared to previous readout\
          \ (inclusive)."
  CheckConfigurationModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      schema_name:
        type: "string"
        description: "Schema name."
      table_name:
        type: "string"
        description: "Table name."
      column_name:
        type: "string"
        description: "Column name, if the check is set up on a column."
      check_target:
        type: "string"
        description: "Check target (table or column)."
        enum:
        - "table"
        - "column"
      check_type:
        type: "string"
        description: "Check type (profiling, monitoring, partitioned)."
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      check_time_scale:
        type: "string"
        description: "Check timescale (for monitoring and partitioned checks)."
        enum:
        - "daily"
        - "monthly"
      category_name:
        type: "string"
        description: "Category to which this check belongs."
      check_name:
        type: "string"
        description: "Check name that is used in YAML file."
      sensor_parameters:
        type: "array"
        description: "List of fields for editing the sensor parameters."
        items:
          $ref: "#/definitions/FieldModel"
      table_level_filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query for every check on\
          \ this table."
      sensor_level_filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query for this check."
      warning:
        description: "Rule parameters for the warning severity rule."
        $ref: "#/definitions/RuleParametersModel"
      error:
        description: "Rule parameters for the error severity rule."
        $ref: "#/definitions/RuleParametersModel"
      fatal:
        description: "Rule parameters for the fatal severity rule."
        $ref: "#/definitions/RuleParametersModel"
      disabled:
        type: "boolean"
        description: "Whether the check has been disabled."
      configured:
        type: "boolean"
        description: "Whether the check is configured (not null)."
    description: "Model containing fundamental configuration of a single data quality\
      \ check."
  CheckContainerListModel:
    type: "object"
    properties:
      checks:
        type: "array"
        description: "Simplistic list of all data quality checks."
        items:
          $ref: "#/definitions/CheckListModel"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can edit the check."
      can_run_checks:
        type: "boolean"
        description: "Boolean flag that decides if the current user can run checks."
      can_delete_data:
        type: "boolean"
        description: "Boolean flag that decides if the current user can delete data\
          \ (results)."
    description: "Simplistic model that returns the list of data quality checks, their\
      \ names, categories and \"configured\" flag."
  CheckContainerModel:
    type: "object"
    properties:
      categories:
        type: "array"
        description: "List of all data quality categories that contain data quality\
          \ checks inside."
        items:
          $ref: "#/definitions/QualityCategoryModel"
      effective_schedule:
        description: "Model of configured schedule enabled on the check container."
        $ref: "#/definitions/EffectiveScheduleModel"
      effective_schedule_enabled_status:
        type: "string"
        description: "State of the effective scheduling on the check container."
        enum:
        - "enabled"
        - "disabled"
        - "not_configured"
        - "overridden_by_checks"
      partition_by_column:
        type: "string"
        description: "The name of the column that partitioned checks will use for\
          \ the time period partitioning. Important only for partitioned checks."
      run_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to start the job."
        $ref: "#/definitions/CheckSearchFilters"
      data_clean_job_template:
        description: "Configured parameters for the \"data clean\" job that after\
          \ being supplied with a time range should be pushed to the job queue in\
          \ order to remove stored results connected with this check container"
        $ref: "#/definitions/DeleteStoredDataQueueJobParameters"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can edit the check."
      can_run_checks:
        type: "boolean"
        description: "Boolean flag that decides if the current user can run checks."
      can_delete_data:
        type: "boolean"
        description: "Boolean flag that decides if the current user can delete data\
          \ (results)."
    description: "Model that returns the form definition and the form data to edit\
      \ all data quality checks divided by categories."
  CheckContainerTypeModel:
    type: "object"
    properties:
      check_type:
        type: "string"
        description: "Check type."
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      check_time_scale:
        type: "string"
        description: "Check timescale."
        enum:
        - "daily"
        - "monthly"
    description: "Model identifying the check type and timescale of checks belonging\
      \ to a container."
  CheckCurrentDataQualityStatusModel:
    type: "object"
    properties:
      current_severity:
        type: "string"
        description: "The data quality issue severity for this data quality check.\
          \ An additional value *execution_error* is used to tell that the check,\
          \ sensor or rule failed to execute due to insufficient  permissions to the\
          \ table or an error in the sensor's template or a Python rule. For partitioned\
          \ checks, it is the highest severity of all results for all partitions (time\
          \ periods) in the analyzed time range."
        enum:
        - "valid"
        - "warning"
        - "error"
        - "fatal"
        - "execution_error"
      highest_historical_severity:
        type: "string"
        description: "The highest severity of previous executions of this data quality\
          \ issue in the analyzed time range. It can be different from the *current_severity*\
          \ if the data quality issue was solved and the most recently data quality\
          \ issue did not detect it anymore. For partitioned checks, this field returns\
          \ the same value as the *current_severity*, because data quality issues\
          \ in older partitions are still valid."
        enum:
        - "valid"
        - "warning"
        - "error"
        - "fatal"
      last_executed_at:
        type: "integer"
        format: "int64"
        description: "The UTC timestamp when the check was recently executed."
      column_name:
        type: "string"
        description: "Optional column name for column-level data quality checks."
      check_type:
        type: "string"
        description: "The check type: profiling, monitoring, partitioned."
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      time_scale:
        type: "string"
        description: "The check time scale for *monitoring* and *partitioned* check\
          \ types. The time scales are *daily* and *monthly*. The profiling checks\
          \ do not have a time scale."
        enum:
        - "daily"
        - "monthly"
      category:
        type: "string"
        description: "Check category name, such as nulls, schema, strings, volume."
      quality_dimension:
        type: "string"
        description: "Data quality dimension, such as Completeness, Uniqueness, Validity."
      executed_checks:
        type: "integer"
        format: "int32"
        description: "The total number of most recent checks that were executed on\
          \ the column. Table comparison checks that are comparing groups of data\
          \ are counted as the number of compared data groups."
      valid_results:
        type: "integer"
        format: "int32"
        description: "The number of most recent valid data quality checks that passed\
          \ without raising any issues."
      warnings:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising a warning severity data quality issue."
      errors:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising an error severity data quality issue."
      fatals:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising a fatal severity data quality issue."
      execution_errors:
        type: "integer"
        format: "int32"
        description: "The number of data quality check execution errors that were\
          \ reported due to access issues to the data source, invalid mapping in DQOps,\
          \ invalid queries in data quality sensors or invalid python rules. When\
          \ an execution error is reported, the configuration of a data quality check\
          \ on a column must be updated."
    description: "The most recent data quality status for a single data quality check.\
      \ If data grouping is enabled, the *current_severity* will be the highest data\
      \ quality issue status from all data quality results for all data groups. For\
      \ partitioned checks, it is the highest severity of all results for all partitions\
      \ (time periods) in the analyzed time range."
  CheckDefinitionFolderModel:
    type: "object"
    properties:
      folders:
        type: "object"
        description: "A dictionary of nested folders with data quality checks. The\
          \ keys are the folder names."
        additionalProperties:
          $ref: "#/definitions/CheckDefinitionFolderModel"
      checks:
        type: "array"
        description: "List of data quality checks defined in this folder."
        items:
          $ref: "#/definitions/CheckDefinitionListModel"
    description: "Check folder list model with a list of data quality checks in this\
      \ folder or a list of nested folders."
  CheckDefinitionListModel:
    type: "object"
    properties:
      check_name:
        type: "string"
        description: "Check name"
      full_check_name:
        type: "string"
        description: "Full check name"
      custom:
        type: "boolean"
        description: "This check has is a custom check or was customized by the user."
      built_in:
        type: "boolean"
        description: "This check is provided with DQOps as a built-in check."
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Data quality check definition list model."
  CheckDefinitionModel:
    type: "object"
    properties:
      check_name:
        type: "string"
        description: "Check name"
      sensor_name:
        type: "string"
        description: "Sensor name"
      rule_name:
        type: "string"
        description: "Rule name"
      help_text:
        type: "string"
        description: "Help text that is shown in the check editor that describes the\
          \ purpose and usage of the check"
      friendly_name:
        type: "string"
        description: "An alternative check's name that is shown on the check editor."
      standard:
        type: "boolean"
        description: "This is a standard data quality check that is always shown on\
          \ the data quality checks editor screen. Non-standard data quality checks\
          \ (when the value is false) are advanced checks that are shown when the\
          \ user decides to expand the list of checks."
      custom:
        type: "boolean"
        description: "This check has is a custom check or was customized by the user."
      built_in:
        type: "boolean"
        description: "This check is provided with DQOps as a built-in check."
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Data quality check definition model"
  CheckListModel:
    type: "object"
    properties:
      check_category:
        type: "string"
        description: "Check category."
      check_name:
        type: "string"
        description: "Data quality check name that is used in YAML."
      help_text:
        type: "string"
        description: "Help text that describes the data quality check."
      configured:
        type: "boolean"
        description: "True if the data quality check is configured (not null). When\
          \ saving the data quality check configuration, set the flag to true for\
          \ storing the check."
    description: "Simplistic model that returns a single data quality check, its name\
      \ and \"configured\" flag"
  CheckModel:
    type: "object"
    properties:
      check_name:
        type: "string"
        description: "Data quality check name that is used in YAML."
      help_text:
        type: "string"
        description: "Help text that describes the data quality check."
      display_name:
        type: "string"
        description: "User assigned display name that is shown instead of the original\
          \ data quality check name."
      friendly_name:
        type: "string"
        description: "An alternative check's name that is shown on the check editor\
          \ as a hint."
      sensor_parameters:
        type: "array"
        description: "List of fields for editing the sensor parameters."
        items:
          $ref: "#/definitions/FieldModel"
      sensor_name:
        type: "string"
        description: "Full sensor name. This field is for information purposes and\
          \ can be used to create additional custom checks that reuse the same data\
          \ quality sensor."
      quality_dimension:
        type: "string"
        description: "Data quality dimension used for tagging the results of this\
          \ data quality checks."
      rule:
        description: "Threshold (alerting) rules defined for a check."
        $ref: "#/definitions/RuleThresholdsModel"
      supports_grouping:
        type: "boolean"
        description: "The data quality check supports a custom data grouping configuration."
      standard:
        type: "boolean"
        description: "This is a standard data quality check that is always shown on\
          \ the data quality checks editor screen. Non-standard data quality checks\
          \ (when the value is false) are advanced checks that are shown when the\
          \ user decides to expand the list of checks."
      default_check:
        type: "boolean"
        description: "This is a check that was applied on-the-fly, because it is configured\
          \ as a default data observability check and can be run, but it is not configured\
          \ in the table YAML."
      data_grouping_override:
        description: "Data grouping configuration for this check. When a data grouping\
          \ configuration is assigned at a check level, it overrides the data grouping\
          \ configuration from the table level. Data grouping is configured in two\
          \ cases: (1) the data in the table should be analyzed with a GROUP BY condition,\
          \ to analyze different groups of rows using separate time series, for example\
          \ a table contains data from multiple countries and there is a 'country'\
          \ column used for partitioning. (2) a static data grouping configuration\
          \ is assigned to a table, when the data is partitioned at a table level\
          \ (similar tables store the same information, but for different countries,\
          \ etc.). "
        $ref: "#/definitions/DataGroupingConfigurationSpec"
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      effective_schedule:
        description: "Model of configured schedule enabled on the check level."
        $ref: "#/definitions/EffectiveScheduleModel"
      schedule_enabled_status:
        type: "string"
        description: "State of the scheduling override for this check."
        enum:
        - "enabled"
        - "disabled"
        - "not_configured"
        - "overridden_by_checks"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled checks are executed.\
          \ The sensor should be disabled if it should not work, but the configuration\
          \ of the sensor and rules should be preserved in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      configured:
        type: "boolean"
        description: "True if the data quality check is configured (not null). When\
          \ saving the data quality check configuration, set the flag to true for\
          \ storing the check."
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      run_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to start the job."
        $ref: "#/definitions/CheckSearchFilters"
      data_clean_job_template:
        description: "Configured parameters for the \"data clean\" job that after\
          \ being supplied with a time range should be pushed to the job queue in\
          \ order to remove stored results connected with this check."
        $ref: "#/definitions/DeleteStoredDataQueueJobParameters"
      data_grouping_configuration:
        type: "string"
        description: "The name of a data grouping configuration defined at a table\
          \ that should be used for this check."
      check_target:
        type: "string"
        description: "Type of the check's target (column, table)."
        enum:
        - "table"
        - "column"
      configuration_requirements_errors:
        type: "array"
        description: "List of configuration errors that must be fixed before the data\
          \ quality check can be executed."
        items:
          type: "string"
      similar_checks:
        type: "array"
        description: "List of similar checks in other check types or in other time\
          \ scales."
        items:
          $ref: "#/definitions/SimilarCheckModel"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can edit the check."
      can_run_checks:
        type: "boolean"
        description: "Boolean flag that decides if the current user can run checks."
      can_delete_data:
        type: "boolean"
        description: "Boolean flag that decides if the current user can delete data\
          \ (results)."
      check_hash:
        type: "integer"
        format: "int64"
        description: "The check hash code that identifies the check instance."
    description: "Model that returns the form definition and the form data to edit\
      \ a single data quality check."
  CheckResultEntryModel:
    type: "object"
    properties:
      id:
        type: "string"
        description: "Check result primary key"
      checkHash:
        type: "integer"
        format: "int64"
        description: "Check hash, do not set a value when writing results to DQOps"
      checkCategory:
        type: "string"
        description: "Check category name"
      checkName:
        type: "string"
        description: "Check name"
      checkDisplayName:
        type: "string"
        description: "Check display name"
      checkType:
        type: "string"
        description: "Check type"
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      actualValue:
        type: "number"
        format: "double"
        description: "Actual value"
      expectedValue:
        type: "number"
        format: "double"
        description: "Expected value"
      warningLowerBound:
        type: "number"
        format: "double"
        description: "Warning lower bound"
      warningUpperBound:
        type: "number"
        format: "double"
        description: "Warning upper bound"
      errorLowerBound:
        type: "number"
        format: "double"
        description: "Error lower bound"
      errorUpperBound:
        type: "number"
        format: "double"
        description: "Error upper bound"
      fatalLowerBound:
        type: "number"
        format: "double"
        description: "Fatal lower bound"
      fatalUpperBound:
        type: "number"
        format: "double"
        description: "Fatal upper bound"
      severity:
        type: "integer"
        format: "int32"
        description: "Issue severity, 0 - valid, 1 - warning, 2 - error, 3 - fatal"
      columnName:
        type: "string"
        description: "Column name"
      dataGroup:
        type: "string"
        description: "Data group name"
      durationMs:
        type: "integer"
        format: "int32"
        description: "Duration (ms)"
      executedAt:
        type: "integer"
        format: "int64"
        description: "Executed at timestamp"
      timeGradient:
        type: "string"
        description: "Time gradient"
        enum:
        - "year"
        - "quarter"
        - "month"
        - "week"
        - "day"
        - "hour"
        - "millisecond"
      timePeriod:
        type: "string"
        format: "date-time"
        description: "Time period"
      includeInKpi:
        type: "boolean"
        description: "Include in KPI"
      includeInSla:
        type: "boolean"
        description: "Include in SLA"
      provider:
        type: "string"
        description: "Provider name"
      qualityDimension:
        type: "string"
        description: "Data quality dimension"
      sensorName:
        type: "string"
        description: "Sensor name"
      tableComparison:
        type: "string"
        description: "Table comparison name"
  CheckResultsListModel:
    type: "object"
    properties:
      checkHash:
        type: "integer"
        format: "int64"
        description: "Check hash"
      checkCategory:
        type: "string"
        description: "Check category name"
      checkName:
        type: "string"
        description: "Check name"
      checkDisplayName:
        type: "string"
        description: "Check display name"
      checkType:
        type: "string"
        description: "Check type"
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      dataGroups:
        type: "array"
        description: "Data groups list"
        items:
          type: "string"
      dataGroup:
        type: "string"
        description: "Selected data group"
      checkResultEntries:
        type: "array"
        description: "Single check results"
        items:
          $ref: "#/definitions/CheckResultEntryModel"
  CheckResultsOverviewDataModel:
    type: "object"
    properties:
      checkHash:
        type: "integer"
        format: "int64"
        description: "Check hash."
      checkCategory:
        type: "string"
        description: "Check category name."
      checkName:
        type: "string"
        description: "Check name."
      comparisonName:
        type: "string"
        description: "Optional table comparison name for table comparison checks only."
      timePeriods:
        type: "array"
        description: "List of time periods for the results, returned as a local time,\
          \ sorted from the newest to the oldest."
        items:
          type: "string"
          format: "date-time"
      timePeriodsUtc:
        type: "array"
        description: "List of time periods for the results, returned as absolute UTC\
          \ time."
        items:
          type: "integer"
          format: "int64"
      executedAtTimestamps:
        type: "array"
        description: "List of absolute timestamp (UTC) when the check was executed\
          \ or an error was raised."
        items:
          type: "integer"
          format: "int64"
      timePeriodDisplayTexts:
        type: "array"
        description: "List of time periods, sorted descending, returned as a text\
          \ with a possible time zone."
        items:
          type: "string"
      statuses:
        type: "array"
        description: "List of check severity levels or an error status, indexes with\
          \ the severity levels match the time periods."
        items:
          type: "string"
          enum:
          - "valid"
          - "warning"
          - "error"
          - "fatal"
          - "execution_error"
      dataGroups:
        type: "array"
        description: "List of data group names. Identifies the data group with the\
          \ highest severity or error result."
        items:
          type: "string"
      results:
        type: "array"
        description: "List of sensor results. Returns the data quality result readout\
          \ for the data group with the alert of the highest severity level."
        items:
          type: "number"
          format: "double"
  CheckSearchFilters:
    type: "object"
    properties:
      connection:
        type: "string"
        description: "The connection (data source) name. Supports search patterns\
          \ in the format: 'source\\*', '\\*_prod', 'prefix\\*suffix'."
      fullTableName:
        type: "string"
        description: "The schema and table name. It is provided as *<schema_name>.<table_name>*,\
          \ for example *public.fact_sales*. The schema and table name accept patterns\
          \ both in the schema name and table name parts. Sample patterns are: 'schema_name.tab_prefix_\\\
          *', 'schema_name.*', '*.*', 'schema_name.\\*_customer', 'schema_name.tab_\\\
          *_suffix'."
      enabled:
        type: "boolean"
        description: "A boolean flag to target enabled tables, columns or checks.\
          \ When the value of this field is not set, the default value of this field\
          \ is *true*, targeting only tables, columns and checks that are not implicitly\
          \ disabled."
      tags:
        type: "array"
        description: "An array of tags assigned to the table. All tags must be present\
          \ on a table to match. The tags can use patterns:  'prefix\\*', '\\*suffix',\
          \ 'prefix\\*suffix'. The tags are assigned to the table on the data grouping\
          \ screen when any of the data grouping hierarchy level is assigned a static\
          \ value, which is a tag."
        items:
          type: "string"
      labels:
        type: "array"
        description: "An array of labels assigned to the table. All labels must be\
          \ present on a table to match. The labels can use patterns:  'prefix\\*',\
          \ '\\*suffix', 'prefix\\*suffix'. The labels are assigned on the labels\
          \ screen and stored in the *labels* node in the *.dqotable.yaml* file."
        items:
          type: "string"
      maxResults:
        type: "integer"
        format: "int32"
        description: "Optional limit for the maximum number of results to return."
      column:
        type: "string"
        description: "The column name. This field accepts search patterns in the format:\
          \ 'fk_\\*', '\\*_id', 'prefix\\*suffix'."
      columnDataType:
        type: "string"
        description: "The column data type that was imported from the data source\
          \ and is stored in the [columns -> column_name -> type_snapshot -> column_type](/docs/reference/yaml/TableYaml/#columntypesnapshotspec)\
          \ field in the *.dqotable.yaml* file."
      columnNullable:
        type: "boolean"
        description: "Optional filter to find only nullable (when the value is *true*)\
          \ or not nullable (when the value is *false*) columns, based on the value\
          \ of the [columns -> column_name -> type_snapshot -> nullable](/docs/reference/yaml/TableYaml/#columntypesnapshotspec)\
          \ field in the *.dqotable.yaml* file."
      checkTarget:
        type: "string"
        description: "The target type of object to run checks. Supported values are:\
          \ *table* to run only table level checks or *column* to run only column\
          \ level checks."
        enum:
        - "table"
        - "column"
      checkType:
        type: "string"
        description: "The target type of checks to run. Supported values are *profiling*,\
          \ *monitoring* and *partitioned*."
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      timeScale:
        type: "string"
        description: "The time scale of *monitoring* or *partitioned* checks to run.\
          \ Supports running only *daily* or *monthly* checks. Daily monitoring checks\
          \ will replace today's value for all captured check results."
        enum:
        - "daily"
        - "monthly"
      checkCategory:
        type: "string"
        description: "The target check category, for example: *nulls*, *volume*, *anomaly*."
      qualityDimension:
        type: "string"
        description: "The target data quality dimension, for example: *Completeness*,\
          \ *Accuracy*, *Consistency*, *Timeliness*, *Availability*."
      tableComparisonName:
        type: "string"
        description: "The name of a configured table comparison. When the table comparison\
          \ is provided, DQOps will only perform table comparison checks that compare\
          \ data between tables."
      checkName:
        type: "string"
        description: "The target check name to run only this named check. Uses the\
          \ short check name which is the name of the deepest folder in the *checks*\
          \ folder. This field supports search patterns such as: 'profiling_\\*',\
          \ '\\*_count', 'profiling_\\*_percent'."
      sensorName:
        type: "string"
        description: "The target sensor name to run only data quality checks that\
          \ are using this sensor. Uses the full sensor name which is the full folder\
          \ path within the *sensors* folder. This field supports search patterns\
          \ such as: 'table/volume/row_\\*', '\\*_count', 'table/volume/prefix_\\\
          *_suffix'."
      checkHierarchyIdsModels:
        type: "array"
        items:
          $ref: "#/definitions/HierarchyIdModel"
    description: "Target data quality checks filter, identifies which checks on which\
      \ tables and columns should be executed."
  CheckTemplate:
    type: "object"
    properties:
      check_target:
        type: "string"
        description: "Check target (table, column)"
        enum:
        - "table"
        - "column"
      check_category:
        type: "string"
        description: "Data quality check category."
      check_name:
        type: "string"
        description: "Data quality check name that is used in YAML."
      help_text:
        type: "string"
        description: "Help text that describes the data quality check."
      check_container_type:
        description: "Check type with time-scale."
        $ref: "#/definitions/CheckContainerTypeModel"
      sensor_name:
        type: "string"
        description: "Full sensor name."
      check_model:
        description: "Template of the check model with the sensor parameters and rule\
          \ parameters"
        $ref: "#/definitions/CheckModel"
      sensor_parameters_definitions:
        type: "array"
        description: "List of sensor parameter fields definitions."
        items:
          $ref: "#/definitions/ParameterDefinitionSpec"
      rule_parameters_definitions:
        type: "array"
        description: "List of threshold (alerting) rule's parameters definitions (for\
          \ a single rule, regardless of severity)."
        items:
          $ref: "#/definitions/ParameterDefinitionSpec"
    description: "Model depicting a named data quality check that can potentially\
      \ be enabled, regardless to its position in hierarchy tree."
  CloudSynchronizationFoldersStatusModel:
    type: "object"
    properties:
      sources:
        type: "string"
        description: "The synchronization status of the \"sources\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      sensors:
        type: "string"
        description: "The synchronization status of the \"sensors\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      rules:
        type: "string"
        description: "The synchronization status of the \"rules\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      checks:
        type: "string"
        description: "The synchronization status of the \"checks\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      settings:
        type: "string"
        description: "The synchronization status of the \"settings\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      credentials:
        type: "string"
        description: "The synchronization status of the \".credentials\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      dictionaries:
        type: "string"
        description: "The synchronization status of the \"dictionaries\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      patterns:
        type: "string"
        description: "The synchronization status of the \"patterns\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      data_sensor_readouts:
        type: "string"
        description: "The synchronization status of the \".data/sensor_readouts\"\
          \ folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      data_check_results:
        type: "string"
        description: "The synchronization status of the \".data/check_results\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      data_statistics:
        type: "string"
        description: "The synchronization status of the \".data/statistics\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      data_errors:
        type: "string"
        description: "The synchronization status of the \".data/errors\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
      data_incidents:
        type: "string"
        description: "The synchronization status of the \".data/incidents\" folder."
        enum:
        - "unchanged"
        - "changed"
        - "synchronizing"
  CollectStatisticsOnTableQueueJobParameters:
    type: "object"
    properties:
      connection:
        type: "string"
        description: "The name of the target connection."
      max_jobs_per_connection:
        type: "integer"
        format: "int32"
        description: "The maximum number of concurrent 'run checks on table' jobs\
          \ that can be run on this connection. Limits the number of concurrent jobs."
      table:
        description: "The full physical name (schema.table) of the target table."
        $ref: "#/definitions/PhysicalTableName"
      statistics_collector_search_filters:
        description: "Statistics collectors search filters that identify the type\
          \ of statistics collector to run."
        $ref: "#/definitions/StatisticsCollectorSearchFilters"
      data_scope:
        type: "string"
        description: "The target scope of collecting statistics. Statistics can be\
          \ collected for the entire table or for each data grouping separately."
        enum:
        - "table"
        - "data_group"
      dummy_sensor_execution:
        type: "boolean"
        description: "Boolean flag that enables a dummy statistics collection (sensors\
          \ are executed, but the statistics results are not written to the parquet\
          \ files)."
      collect_statistics_result:
        description: "The summary of the statistics collection job after if finished.\
          \ Returns the number of collectors analyzed, columns analyzed, statistics\
          \ results captured."
        $ref: "#/definitions/CollectStatisticsResult"
  CollectStatisticsQueueJobParameters:
    type: "object"
    properties:
      statistics_collector_search_filters:
        description: "Statistics collectors search filters that identify the type\
          \ of statistics collector to run."
        $ref: "#/definitions/StatisticsCollectorSearchFilters"
      data_scope:
        type: "string"
        description: "The target scope of collecting statistics. Statistics can be\
          \ collected for the entire table or for each data grouping separately."
        enum:
        - "table"
        - "data_group"
      dummy_sensor_execution:
        type: "boolean"
        description: "Boolean flag that enables a dummy statistics collection (sensors\
          \ are executed, but the statistics results are not written to the parquet\
          \ files)."
      collect_statistics_result:
        description: "The summary of the statistics collection job after if finished.\
          \ Returns the number of collectors analyzed, columns analyzed, statistics\
          \ results captured."
        $ref: "#/definitions/CollectStatisticsResult"
  CollectStatisticsQueueJobResult:
    type: "object"
    properties:
      jobId:
        description: "Job id that identifies a job that was started on the DQOps job\
          \ queue."
        $ref: "#/definitions/DqoQueueJobId"
      result:
        description: "Optional result object that is returned only when the wait parameter\
          \ was true and the \"collect statistics\" job has finished. Contains the\
          \ summary result of collecting basic statistics, including the number of\
          \ statistics collectors (queries) that managed to capture metrics about\
          \ the table(s). "
        $ref: "#/definitions/CollectStatisticsResult"
      status:
        type: "string"
        description: "Job status"
        enum:
        - "queued"
        - "running"
        - "waiting"
        - "finished"
        - "failed"
        - "cancel_requested"
        - "cancelled"
    description: "Object returned from the operation that queues a \"collect statistics\"\
      \ job. The result contains the job id that was started and optionally can also\
      \ contain the result of collecting the statistics  if the operation was started\
      \ with wait=true parameter to wait for the \"collect statistics\" job to finish."
  CollectStatisticsResult:
    type: "object"
    properties:
      executed_statistics_collectors:
        type: "integer"
        format: "int32"
        description: "The total count of all executed statistics collectors."
      total_collectors_executed:
        type: "integer"
        format: "int32"
        description: "The count of executed statistics collectors."
      columns_analyzed:
        type: "integer"
        format: "int32"
        description: "The count of columns for which DQOps executed a collector and\
          \ tried to read the statistics."
      columns_successfully_analyzed:
        type: "integer"
        format: "int32"
        description: "The count of columns for which DQOps managed to obtain statistics."
      total_collectors_failed:
        type: "integer"
        format: "int32"
        description: "The count of statistics collectors that failed to execute."
      total_collected_results:
        type: "integer"
        format: "int32"
        description: "The total number of results that were collected."
    description: "Returns the result with the summary of the statistics collected."
  ColumnAcceptedValuesDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_text_found_in_set_percent:
        description: "The check measures the percentage of rows whose value in a tested\
          \ column is one of values from a list of expected values or the column value\
          \ is null. Verifies that the percentage of rows having a valid column value\
          \ does not exceed the minimum accepted percentage. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextFoundInSetPercentCheckSpec"
      daily_number_found_in_set_percent:
        description: "The check measures the percentage of rows whose value in a tested\
          \ column is one of values from a list of expected values or the column value\
          \ is null. Verifies that the percentage of rows having a valid column value\
          \ does not exceed the minimum accepted percentage. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberFoundInSetPercentCheckSpec"
      daily_expected_text_values_in_use_count:
        description: "Verifies that the expected string values were found in the column.\
          \ Raises a data quality issue when too many expected values were not found\
          \ (were missing). Stores the most recent captured value for each day when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnExpectedTextValuesInUseCountCheckSpec"
      daily_expected_texts_in_top_values_count:
        description: "Verifies that the top X most popular column values contain all\
          \ values from a list of expected values. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnExpectedTextsInTopValuesCountCheckSpec"
      daily_expected_numbers_in_use_count:
        description: "Verifies that the expected numeric values were found in the\
          \ column. Raises a data quality issue when too many expected values were\
          \ not found (were missing). Stores the most recent captured value for each\
          \ day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnExpectedNumbersInUseCountCheckSpec"
      daily_text_valid_country_code_percent:
        description: "Verifies that the percentage of valid country codes in a text\
          \ column does not fall below the minimum accepted percentage. Stores the\
          \ most recent captured value for each day when the data quality check was\
          \ evaluated."
        $ref: "#/definitions/ColumnTextValidCountryCodePercentCheckSpec"
      daily_text_valid_currency_code_percent:
        description: "Verifies that the percentage of valid currency codes in a text\
          \ column does not fall below the minimum accepted percentage. Stores the\
          \ most recent captured value for each day when the data quality check was\
          \ evaluated."
        $ref: "#/definitions/ColumnTextValidCurrencyCodePercentCheckSpec"
  ColumnAcceptedValuesDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_text_found_in_set_percent:
        description: "The check measures the percentage of rows whose value in a tested\
          \ column is one of values from a list of expected values or the column value\
          \ is null. Verifies that the percentage of rows having a valid column value\
          \ does not exceed the minimum accepted percentage. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/ColumnTextFoundInSetPercentCheckSpec"
      daily_partition_number_found_in_set_percent:
        description: "The check measures the percentage of rows whose value in a tested\
          \ column is one of values from a list of expected values or the column value\
          \ is null. Verifies that the percentage of rows having a valid column value\
          \ does not exceed the minimum accepted percentage. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/ColumnNumberFoundInSetPercentCheckSpec"
      daily_partition_expected_text_values_in_use_count:
        description: "Verifies that the expected string values were found in the column.\
          \ Raises a data quality issue when too many expected values were not found\
          \ (were missing). Stores a separate data quality check result for each daily\
          \ partition."
        $ref: "#/definitions/ColumnExpectedTextValuesInUseCountCheckSpec"
      daily_partition_expected_texts_in_top_values_count:
        description: "Verifies that the top X most popular column values contain all\
          \ values from a list of expected values. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnExpectedTextsInTopValuesCountCheckSpec"
      daily_partition_expected_numbers_in_use_count:
        description: "Verifies that the expected numeric values were found in the\
          \ column. Raises a data quality issue when too many expected values were\
          \ not found (were missing). Stores a separate data quality check result\
          \ for each daily partition."
        $ref: "#/definitions/ColumnExpectedNumbersInUseCountCheckSpec"
      daily_partition_text_valid_country_code_percent:
        description: "Verifies that the percentage of valid country codes in a text\
          \ column does not fall below the minimum accepted percentage. Analyzes every\
          \ daily partition and creates a separate data quality check result with\
          \ the time period value that identifies the daily partition."
        $ref: "#/definitions/ColumnTextValidCountryCodePercentCheckSpec"
      daily_partition_text_valid_currency_code_percent:
        description: "Verifies that the percentage of valid currency codes in a text\
          \ column does not fall below the minimum accepted percentage. Analyzes every\
          \ daily partition and creates a separate data quality check result with\
          \ the time period value that identifies the daily partition."
        $ref: "#/definitions/ColumnTextValidCurrencyCodePercentCheckSpec"
  ColumnAcceptedValuesMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_text_found_in_set_percent:
        description: "The check measures the percentage of rows whose value in a tested\
          \ column is one of values from a list of expected values or the column value\
          \ is null. Verifies that the percentage of rows having a valid column value\
          \ does not exceed the minimum accepted percentage. Stores the most recent\
          \ captured value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextFoundInSetPercentCheckSpec"
      monthly_number_found_in_set_percent:
        description: "The check measures the percentage of rows whose value in a tested\
          \ column is one of values from a list of expected values or the column value\
          \ is null. Verifies that the percentage of rows having a valid column value\
          \ does not exceed the minimum accepted percentage. Stores the most recent\
          \ captured value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberFoundInSetPercentCheckSpec"
      monthly_expected_text_values_in_use_count:
        description: "Verifies that the expected string values were found in the column.\
          \ Raises a data quality issue when too many expected values were not found\
          \ (were missing). Stores the most recent captured value for each month when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnExpectedTextValuesInUseCountCheckSpec"
      monthly_expected_texts_in_top_values_count:
        description: "Verifies that the top X most popular column values contain all\
          \ values from a list of expected values. Stores the most recent captured\
          \ value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnExpectedTextsInTopValuesCountCheckSpec"
      monthly_expected_numbers_in_use_count:
        description: "Verifies that the expected numeric values were found in the\
          \ column. Raises a data quality issue when too many expected values were\
          \ not found (were missing). Stores the most recent captured value for each\
          \ month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnExpectedNumbersInUseCountCheckSpec"
      monthly_text_valid_country_code_percent:
        description: "Verifies that the percentage of valid country codes in a text\
          \ column does not fall below the minimum accepted percentage. Stores the\
          \ most recent captured value for each month when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnTextValidCountryCodePercentCheckSpec"
      monthly_text_valid_currency_code_percent:
        description: "Verifies that the percentage of valid currency codes in a text\
          \ column does not fall below the minimum accepted percentage. Stores the\
          \ most recent captured value for each month when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnTextValidCurrencyCodePercentCheckSpec"
  ColumnAcceptedValuesMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_text_found_in_set_percent:
        description: "The check measures the percentage of rows whose value in a tested\
          \ column is one of values from a list of expected values or the column value\
          \ is null. Verifies that the percentage of rows having a valid column value\
          \ does not exceed the minimum accepted percentage. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/ColumnTextFoundInSetPercentCheckSpec"
      monthly_partition_number_found_in_set_percent:
        description: "The check measures the percentage of rows whose value in a tested\
          \ column is one of values from a list of expected values or the column value\
          \ is null. Verifies that the percentage of rows having a valid column value\
          \ does not exceed the minimum accepted percentage. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNumberFoundInSetPercentCheckSpec"
      monthly_partition_expected_text_values_in_use_count:
        description: "Verifies that the expected string values were found in the column.\
          \ Raises a data quality issue when too many expected values were not found\
          \ (were missing). Stores a separate data quality check result for each monthly\
          \ partition."
        $ref: "#/definitions/ColumnExpectedTextValuesInUseCountCheckSpec"
      monthly_partition_expected_texts_in_top_values_count:
        description: "Verifies that the top X most popular column values contain all\
          \ values from a list of expected values. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnExpectedTextsInTopValuesCountCheckSpec"
      monthly_partition_expected_numbers_in_use_count:
        description: "Verifies that the expected numeric values were found in the\
          \ column. Raises a data quality issue when too many expected values were\
          \ not found (were missing). Stores a separate data quality check result\
          \ for each monthly partition."
        $ref: "#/definitions/ColumnExpectedNumbersInUseCountCheckSpec"
      monthly_partition_text_valid_country_code_percent:
        description: "Verifies that the percentage of valid country codes in a text\
          \ column does not fall below the minimum accepted percentage. Analyzes every\
          \ monthly partition and creates a separate data quality check result with\
          \ the time period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnTextValidCountryCodePercentCheckSpec"
      monthly_partition_text_valid_currency_code_percent:
        description: "Verifies that the percentage of valid currency codes in a text\
          \ column does not fall below the minimum accepted percentage. Analyzes every\
          \ monthly partition and creates a separate data quality check result with\
          \ the time period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnTextValidCurrencyCodePercentCheckSpec"
  ColumnAcceptedValuesProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_text_found_in_set_percent:
        description: "The check measures the percentage of rows whose value in a tested\
          \ column is one of values from a list of expected values or the column value\
          \ is null. Verifies that the percentage of rows having a valid column value\
          \ does not exceed the minimum accepted percentage."
        $ref: "#/definitions/ColumnTextFoundInSetPercentCheckSpec"
      profile_number_found_in_set_percent:
        description: "The check measures the percentage of rows whose value in a tested\
          \ column is one of values from a list of expected values or the column value\
          \ is null. Verifies that the percentage of rows having a valid column value\
          \ does not exceed the minimum accepted percentage."
        $ref: "#/definitions/ColumnNumberFoundInSetPercentCheckSpec"
      profile_expected_text_values_in_use_count:
        description: "Verifies that the expected string values were found in the column.\
          \ Raises a data quality issue when too many expected values were not found\
          \ (were missing)."
        $ref: "#/definitions/ColumnExpectedTextValuesInUseCountCheckSpec"
      profile_expected_texts_in_top_values_count:
        description: "Verifies that the top X most popular column values contain all\
          \ values from a list of expected values."
        $ref: "#/definitions/ColumnExpectedTextsInTopValuesCountCheckSpec"
      profile_expected_numbers_in_use_count:
        description: "Verifies that the expected numeric values were found in the\
          \ column. Raises a data quality issue when too many expected values were\
          \ not found (were missing)."
        $ref: "#/definitions/ColumnExpectedNumbersInUseCountCheckSpec"
      profile_text_valid_country_code_percent:
        description: "Verifies that the percentage of valid country codes in a text\
          \ column does not fall below the minimum accepted percentage"
        $ref: "#/definitions/ColumnTextValidCountryCodePercentCheckSpec"
      profile_text_valid_currency_code_percent:
        description: "Verifies that the percentage of valid currency codes in a text\
          \ column does not fall below the minimum accepted percentage"
        $ref: "#/definitions/ColumnTextValidCurrencyCodePercentCheckSpec"
  ColumnAcceptedValuesTextFoundInSetPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      expected_values:
        type: "array"
        description: "A list of expected values that must be present in a string column,\
          \ only values from this list are accepted and rows having these values in\
          \ the tested column are counted as valid rows."
        items:
          type: "string"
  ColumnAccuracyDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_total_sum_match_percent:
        description: "Verifies that the percentage of difference in total sum of a\
          \ column in a table and total sum of a column of another table does not\
          \ exceed the set number. Stores the most recent captured value for each\
          \ day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnAccuracyTotalSumMatchPercentCheckSpec"
      daily_total_min_match_percent:
        description: "Verifies that the percentage of difference in total min of a\
          \ column in a table and total min of a column of another table does not\
          \ exceed the set number. Stores the most recent captured value for each\
          \ day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnAccuracyTotalMinMatchPercentCheckSpec"
      daily_total_max_match_percent:
        description: "Verifies that the percentage of difference in total max of a\
          \ column in a table and total max of a column of another table does not\
          \ exceed the set number. Stores the most recent captured value for each\
          \ day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnAccuracyTotalMaxMatchPercentCheckSpec"
      daily_total_average_match_percent:
        description: "Verifies that the percentage of difference in total average\
          \ of a column in a table and total average of a column of another table\
          \ does not exceed the set number. Stores the most recent captured value\
          \ for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnAccuracyTotalAverageMatchPercentCheckSpec"
      daily_total_not_null_count_match_percent:
        description: "Verifies that the percentage of difference in total not null\
          \ count of a column in a table and total not null count of a column of another\
          \ table does not exceed the set number. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnAccuracyTotalNotNullCountMatchPercentCheckSpec"
  ColumnAccuracyMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_total_sum_match_percent:
        description: "Verifies that the percentage of difference in total sum of a\
          \ column in a table and total sum of a column of another table does not\
          \ exceed the set number. Stores the most recent check result for each month\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnAccuracyTotalSumMatchPercentCheckSpec"
      monthly_total_min_match_percent:
        description: "Verifies that the percentage of difference in total min of a\
          \ column in a table and total min of a column of another table does not\
          \ exceed the set number. Stores the most recent check result for each month\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnAccuracyTotalMinMatchPercentCheckSpec"
      monthly_total_max_match_percent:
        description: "Verifies that the percentage of difference in total max of a\
          \ column in a table and total max of a column of another table does not\
          \ exceed the set number. Stores the most recent check result for each month\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnAccuracyTotalMaxMatchPercentCheckSpec"
      monthly_total_average_match_percent:
        description: "Verifies that the percentage of difference in total average\
          \ of a column in a table and total average of a column of another table\
          \ does not exceed the set number. Stores the most recent check result for\
          \ each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnAccuracyTotalAverageMatchPercentCheckSpec"
      monthly_total_not_null_count_match_percent:
        description: "Verifies that the percentage of difference in total not null\
          \ count of a column in a table and total not null count of a column of another\
          \ table does not exceed the set number. Stores the most recent check result\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnAccuracyTotalNotNullCountMatchPercentCheckSpec"
  ColumnAccuracyProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_total_sum_match_percent:
        description: "Verifies that percentage of the difference in total sum of a\
          \ column in a table and total sum of a column of another table does not\
          \ exceed the set number."
        $ref: "#/definitions/ColumnAccuracyTotalSumMatchPercentCheckSpec"
      profile_total_min_match_percent:
        description: "Verifies that the percentage of difference in total min of a\
          \ column in a table and total min of a column of another table does not\
          \ exceed the set number."
        $ref: "#/definitions/ColumnAccuracyTotalMinMatchPercentCheckSpec"
      profile_total_max_match_percent:
        description: "Verifies that the percentage of difference in total max of a\
          \ column in a table and total max of a column of another table does not\
          \ exceed the set number."
        $ref: "#/definitions/ColumnAccuracyTotalMaxMatchPercentCheckSpec"
      profile_total_average_match_percent:
        description: "Verifies that the percentage of difference in total average\
          \ of a column in a table and total average of a column of another table\
          \ does not exceed the set number."
        $ref: "#/definitions/ColumnAccuracyTotalAverageMatchPercentCheckSpec"
      profile_total_not_null_count_match_percent:
        description: "Verifies that the percentage of difference in total not null\
          \ count of a column in a table and total not null count of a column of another\
          \ table does not exceed the set number. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnAccuracyTotalNotNullCountMatchPercentCheckSpec"
  ColumnAccuracyTotalAverageMatchPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters. Fill the parameters to provide\
          \ the name of the referenced table and the referenced column."
        $ref: "#/definitions/ColumnAccuracyTotalAverageMatchPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of difference\
          \ of average of a table column and of a average of another table column\
          \ that raises a data quality error (alert)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  ColumnAccuracyTotalAverageMatchPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      referenced_table:
        type: "string"
        description: "The name of the reference table. DQOps accepts the name in two\
          \ forms: a fully qualified name including the schema name, for example landing_zone.customer_raw,\
          \ or only a table name. When only a table name is used, DQOps assumes that\
          \ the table is in the same schema as the analyzed table, and prefixes the\
          \ name with the schema and optionally database name."
      referenced_column:
        type: "string"
        description: "The name of a column in the reference table. DQOps calculates\
          \ an aggregate value on that column and compares it with the value in the\
          \ analyzed table."
  ColumnAccuracyTotalMaxMatchPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters. Fill the parameters to provide\
          \ the name of the referenced table and the referenced column."
        $ref: "#/definitions/ColumnAccuracyTotalMaxMatchPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of difference\
          \ of max of a table column and of a max of another table column that raises\
          \ a data quality error (alert)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  ColumnAccuracyTotalMaxMatchPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      referenced_table:
        type: "string"
        description: "The name of the reference table. DQOps accepts the name in two\
          \ forms: a fully qualified name including the schema name, for example landing_zone.customer_raw,\
          \ or only a table name. When only a table name is used, DQOps assumes that\
          \ the table is in the same schema as the analyzed table, and prefixes the\
          \ name with the schema and optionally database name."
      referenced_column:
        type: "string"
        description: "The name of a column in the reference table. DQOps calculates\
          \ an aggregate value on that column and compares it with the value in the\
          \ analyzed table."
  ColumnAccuracyTotalMinMatchPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters. Fill the parameters to provide\
          \ the name of the referenced table and the referenced column."
        $ref: "#/definitions/ColumnAccuracyTotalMinMatchPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of difference\
          \ of min of a table column and of a min of another table column that raises\
          \ a data quality error (alert)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  ColumnAccuracyTotalMinMatchPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      referenced_table:
        type: "string"
        description: "The name of the reference table. DQOps accepts the name in two\
          \ forms: a fully qualified name including the schema name, for example landing_zone.customer_raw,\
          \ or only a table name. When only a table name is used, DQOps assumes that\
          \ the table is in the same schema as the analyzed table, and prefixes the\
          \ name with the schema and optionally database name."
      referenced_column:
        type: "string"
        description: "The name of a column in the reference table. DQOps calculates\
          \ an aggregate value on that column and compares it with the value in the\
          \ analyzed table."
  ColumnAccuracyTotalNotNullCountMatchPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters. Fill the parameters to provide\
          \ the name of the referenced table and the referenced column."
        $ref: "#/definitions/ColumnAccuracyTotalNotNullCountMatchPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of difference\
          \ of row count of a table column and of a row count of another table column\
          \ that raises a data quality error (alert)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  ColumnAccuracyTotalNotNullCountMatchPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      referenced_table:
        type: "string"
        description: "The name of the reference table. DQOps accepts the name in two\
          \ forms: a fully qualified name including the schema name, for example landing_zone.customer_raw,\
          \ or only a table name. When only a table name is used, DQOps assumes that\
          \ the table is in the same schema as the analyzed table, and prefixes the\
          \ name with the schema and optionally database name."
      referenced_column:
        type: "string"
        description: "The name of a column in the reference table. DQOps calculates\
          \ an aggregate value on that column and compares it with the value in the\
          \ analyzed table."
  ColumnAccuracyTotalSumMatchPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters. Fill the parameters to provide\
          \ the name of the referenced table and the referenced column."
        $ref: "#/definitions/ColumnAccuracyTotalSumMatchPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of difference\
          \ of sum of a table column and of a sum of another table column that raises\
          \ a data quality error (alert)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  ColumnAccuracyTotalSumMatchPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      referenced_table:
        type: "string"
        description: "The name of the reference table. DQOps accepts the name in two\
          \ forms: a fully qualified name including the schema name, for example landing_zone.customer_raw,\
          \ or only a table name. When only a table name is used, DQOps assumes that\
          \ the table is in the same schema as the analyzed table, and prefixes the\
          \ name with the schema and optionally database name."
      referenced_column:
        type: "string"
        description: "The name of a column in the reference table. DQOps calculates\
          \ an aggregate value on that column and compares it with the value in the\
          \ analyzed table."
  ColumnAnomalyDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_sum_anomaly:
        description: "Verifies that the sum in a column changes in a rate within a\
          \ percentile boundary during the last 90 days."
        $ref: "#/definitions/ColumnSumAnomalyDifferencingCheckSpec"
      daily_mean_anomaly:
        description: "Verifies that the mean value in a column changes in a rate within\
          \ a percentile boundary during the last 90 days."
        $ref: "#/definitions/ColumnMeanAnomalyStationaryCheckSpec"
      daily_median_anomaly:
        description: "Verifies that the median in a column changes in a rate within\
          \ a percentile boundary during the last 90 days."
        $ref: "#/definitions/ColumnMedianAnomalyStationaryCheckSpec"
      daily_min_anomaly:
        description: "Detects new outliers, which are new minimum values, much below\
          \ the last known minimum value. If the minimum value is constantly changing,\
          \ detects outliers as the biggest change of the minimum value during the\
          \ last 90 days."
        $ref: "#/definitions/ColumnMinAnomalyDifferencingCheckSpec"
      daily_max_anomaly:
        description: "Detects new outliers, which are new maximum values, much above\
          \ the last known maximum value. If the maximum value is constantly changing,\
          \ detects outliers as the biggest change of the maximum value during the\
          \ last 90 days."
        $ref: "#/definitions/ColumnMaxAnomalyDifferencingCheckSpec"
      daily_mean_change:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since the last readout."
        $ref: "#/definitions/ColumnMeanChangeCheckSpec"
      daily_median_change:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout."
        $ref: "#/definitions/ColumnMedianChangeCheckSpec"
      daily_sum_change:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout."
        $ref: "#/definitions/ColumnSumChangeCheckSpec"
      daily_mean_change_1_day:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since last readout from yesterday."
        $ref: "#/definitions/ColumnMeanChange1DayCheckSpec"
      daily_mean_change_7_days:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since last readout from last week."
        $ref: "#/definitions/ColumnMeanChange7DaysCheckSpec"
      daily_mean_change_30_days:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since last readout from last month."
        $ref: "#/definitions/ColumnMeanChange30DaysCheckSpec"
      daily_median_change_1_day:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout from yesterday."
        $ref: "#/definitions/ColumnMedianChange1DayCheckSpec"
      daily_median_change_7_days:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout from the last week."
        $ref: "#/definitions/ColumnMedianChange7DaysCheckSpec"
      daily_median_change_30_days:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout from the last month."
        $ref: "#/definitions/ColumnMedianChange30DaysCheckSpec"
      daily_sum_change_1_day:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout from yesterday."
        $ref: "#/definitions/ColumnSumChange1DayCheckSpec"
      daily_sum_change_7_days:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout from the last week."
        $ref: "#/definitions/ColumnSumChange7DaysCheckSpec"
      daily_sum_change_30_days:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout from the last month."
        $ref: "#/definitions/ColumnSumChange30DaysCheckSpec"
  ColumnAnomalyDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_sum_anomaly:
        description: "Verifies that the sum in a column is within a percentile from\
          \ measurements made during the last 90 days. Calculates the sum of each\
          \ daily partition and detect anomalies between daily partitions."
        $ref: "#/definitions/ColumnSumAnomalyStationaryPartitionCheckSpec"
      daily_partition_mean_anomaly:
        description: "Verifies that the mean value in a column is within a percentile\
          \ from measurements made during the last 90 days. Calculates the mean (average)\
          \ of each daily partition and detect anomalies between daily partitions."
        $ref: "#/definitions/ColumnMeanAnomalyStationaryCheckSpec"
      daily_partition_median_anomaly:
        description: "Verifies that the median in a column is within a percentile\
          \ from measurements made during the last 90 days. Calculates the median\
          \ of each daily partition and detect anomalies between daily partitions."
        $ref: "#/definitions/ColumnMedianAnomalyStationaryCheckSpec"
      daily_partition_min_anomaly:
        description: "Detects new outliers, which are new minimum values, much below\
          \ the last known minimum value. If the minimum value is constantly changing,\
          \ detects outliers as the biggest change of the minimum value during the\
          \ last 90 days. Finds the minimum value of each daily partition and detect\
          \ anomalies between daily partitions."
        $ref: "#/definitions/ColumnMinAnomalyStationaryCheckSpec"
      daily_partition_max_anomaly:
        description: "Detects new outliers, which are new maximum values, much above\
          \ the last known maximum value. If the maximum value is constantly changing,\
          \ detects outliers as the biggest change of the maximum value during the\
          \ last 90 days. Finds the maximum value of each daily partition and detect\
          \ anomalies between daily partitions."
        $ref: "#/definitions/ColumnMaxAnomalyStationaryCheckSpec"
      daily_partition_mean_change:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since last readout."
        $ref: "#/definitions/ColumnMeanChangeCheckSpec"
      daily_partition_median_change:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout."
        $ref: "#/definitions/ColumnMedianChangeCheckSpec"
      daily_partition_sum_change:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout."
        $ref: "#/definitions/ColumnSumChangeCheckSpec"
      daily_partition_mean_change_1_day:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since the last readout from yesterday."
        $ref: "#/definitions/ColumnMeanChange1DayCheckSpec"
      daily_partition_mean_change_7_days:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since the last readout from the last week."
        $ref: "#/definitions/ColumnMeanChange7DaysCheckSpec"
      daily_partition_mean_change_30_days:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since the last readout from the last month."
        $ref: "#/definitions/ColumnMeanChange30DaysCheckSpec"
      daily_partition_median_change_1_day:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout from yesterday."
        $ref: "#/definitions/ColumnMedianChange1DayCheckSpec"
      daily_partition_median_change_7_days:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout from the last week."
        $ref: "#/definitions/ColumnMedianChange7DaysCheckSpec"
      daily_partition_median_change_30_days:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout from the last month."
        $ref: "#/definitions/ColumnMedianChange30DaysCheckSpec"
      daily_partition_sum_change_1_day:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout from yesterday."
        $ref: "#/definitions/ColumnSumChange1DayCheckSpec"
      daily_partition_sum_change_7_days:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout from the last week."
        $ref: "#/definitions/ColumnSumChange7DaysCheckSpec"
      daily_partition_sum_change_30_days:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout from the last month."
        $ref: "#/definitions/ColumnSumChange30DaysCheckSpec"
  ColumnAnomalyProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_sum_anomaly:
        description: "Verifies that the sum in a column changes in a rate within a\
          \ percentile boundary during the last 90 days."
        $ref: "#/definitions/ColumnSumAnomalyDifferencingCheckSpec"
      profile_mean_anomaly:
        description: "Verifies that the mean value in a column changes in a rate within\
          \ a percentile boundary during the last 90 days."
        $ref: "#/definitions/ColumnMeanAnomalyStationaryCheckSpec"
      profile_median_anomaly:
        description: "Verifies that the median in a column changes in a rate within\
          \ a percentile boundary during the last 90 days."
        $ref: "#/definitions/ColumnMedianAnomalyStationaryCheckSpec"
      profile_min_anomaly:
        description: "Detects new outliers, which are new minimum values, much below\
          \ the last known minimum value. If the minimum value is constantly changing,\
          \ detects outliers as the biggest change of the minimum value during the\
          \ last 90 days."
        $ref: "#/definitions/ColumnMinAnomalyDifferencingCheckSpec"
      profile_max_anomaly:
        description: "Detects new outliers, which are new maximum values, much above\
          \ the last known maximum value. If the maximum value is constantly changing,\
          \ detects outliers as the biggest change of the maximum value during the\
          \ last 90 days."
        $ref: "#/definitions/ColumnMaxAnomalyDifferencingCheckSpec"
      profile_mean_change:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since the last readout."
        $ref: "#/definitions/ColumnMeanChangeCheckSpec"
      profile_median_change:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout."
        $ref: "#/definitions/ColumnMedianChangeCheckSpec"
      profile_sum_change:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout."
        $ref: "#/definitions/ColumnSumChangeCheckSpec"
      profile_mean_change_1_day:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since the last readout from yesterday."
        $ref: "#/definitions/ColumnMeanChange1DayCheckSpec"
      profile_mean_change_7_days:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since the last readout from the last week."
        $ref: "#/definitions/ColumnMeanChange7DaysCheckSpec"
      profile_mean_change_30_days:
        description: "Verifies that the mean value in a column changed in a fixed\
          \ rate since the last readout from the last month."
        $ref: "#/definitions/ColumnMeanChange30DaysCheckSpec"
      profile_median_change_1_day:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout from yesterday."
        $ref: "#/definitions/ColumnMedianChange1DayCheckSpec"
      profile_median_change_7_days:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout from the last week."
        $ref: "#/definitions/ColumnMedianChange7DaysCheckSpec"
      profile_median_change_30_days:
        description: "Verifies that the median in a column changed in a fixed rate\
          \ since the last readout from the last month."
        $ref: "#/definitions/ColumnMedianChange30DaysCheckSpec"
      profile_sum_change_1_day:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout from yesterday."
        $ref: "#/definitions/ColumnSumChange1DayCheckSpec"
      profile_sum_change_7_days:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout from last week."
        $ref: "#/definitions/ColumnSumChange7DaysCheckSpec"
      profile_sum_change_30_days:
        description: "Verifies that the sum in a column changed in a fixed rate since\
          \ the last readout from last month."
        $ref: "#/definitions/ColumnSumChange30DaysCheckSpec"
  ColumnBoolDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_true_percent:
        description: "Measures the percentage of **true** values in a boolean column\
          \ and verifies that it is within the accepted range. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTruePercentCheckSpec"
      daily_false_percent:
        description: "Measures the percentage of **false** values in a boolean column\
          \ and verifies that it is within the accepted range. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnFalsePercentCheckSpec"
  ColumnBoolDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_true_percent:
        description: "Measures the percentage of **true** values in a boolean column\
          \ and verifies that it is within the accepted range. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/ColumnTruePercentCheckSpec"
      daily_partition_false_percent:
        description: "Measures the percentage of **false** values in a boolean column\
          \ and verifies that it is within the accepted range. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/ColumnFalsePercentCheckSpec"
  ColumnBoolFalsePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnBoolMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_true_percent:
        description: "Measures the percentage of **true** values in a boolean column\
          \ and verifies that it is within the accepted range. Stores the most recent\
          \ check result for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTruePercentCheckSpec"
      monthly_false_percent:
        description: "Measures the percentage of **false** values in a boolean column\
          \ and verifies that it is within the accepted range. Stores the most recent\
          \ check result for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnFalsePercentCheckSpec"
  ColumnBoolMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_true_percent:
        description: "Measures the percentage of **true** values in a boolean column\
          \ and verifies that it is within the accepted range. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/ColumnTruePercentCheckSpec"
      monthly_partition_false_percent:
        description: "Measures the percentage of **false** values in a boolean column\
          \ and verifies that it is within the accepted range. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/ColumnFalsePercentCheckSpec"
  ColumnBoolProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_true_percent:
        description: "Measures the percentage of **true** values in a boolean column\
          \ and verifies that it is within the accepted range."
        $ref: "#/definitions/ColumnTruePercentCheckSpec"
      profile_false_percent:
        description: "Measures the percentage of **false** values in a boolean column\
          \ and verifies that it is within the accepted range."
        $ref: "#/definitions/ColumnFalsePercentCheckSpec"
  ColumnBoolTruePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnColumnExistsSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnColumnTypeHashSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnComparisonDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      reference_column:
        type: "string"
        description: "The name of the reference column name in the reference table.\
          \ It is the column to which the current column is compared to."
      daily_sum_match:
        description: "Verifies that percentage of the difference between the sum of\
          \ values in a tested column in a parent table and the sum of a values in\
          \ a column in the reference table. The difference must be below defined\
          \ percentage thresholds. Stores the most recent captured value for each\
          \ day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonSumMatchCheckSpec"
      daily_min_match:
        description: "Verifies that percentage of the difference between the minimum\
          \ value in a tested column in a parent table and the minimum value in a\
          \ column in the reference table. The difference must be below defined percentage\
          \ thresholds. Stores the most recent captured value for each day when the\
          \ data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonMinMatchCheckSpec"
      daily_max_match:
        description: "Verifies that percentage of the difference between the maximum\
          \ value in a tested column in a parent table and the maximum value in a\
          \ column in the reference table. The difference must be below defined percentage\
          \ thresholds. Stores the most recent captured value for each day when the\
          \ data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonMaxMatchCheckSpec"
      daily_mean_match:
        description: "Verifies that percentage of the difference between the mean\
          \ (average) value in a tested column in a parent table and the mean (average)\
          \ value in a column in the reference table. The difference must be below\
          \ defined percentage thresholds. Stores the most recent captured value for\
          \ each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonMeanMatchCheckSpec"
      daily_not_null_count_match:
        description: "Verifies that percentage of the difference between the count\
          \ of not null values in a tested column in a parent table and the count\
          \ of not null values in a column in the reference table. The difference\
          \ must be below defined percentage thresholds. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonNotNullCountMatchCheckSpec"
      daily_null_count_match:
        description: "Verifies that percentage of the difference between the count\
          \ of null values in a tested column in a parent table and the count of null\
          \ values in a column in the reference table. The difference must be below\
          \ defined percentage thresholds. Stores the most recent captured value for\
          \ each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonNullCountMatchCheckSpec"
  ColumnComparisonDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      reference_column:
        type: "string"
        description: "The name of the reference column name in the reference table.\
          \ It is the column to which the current column is compared to."
      daily_partition_sum_match:
        description: "Verifies that percentage of the difference between the sum of\
          \ values in a tested column in a parent table and the sum of a values in\
          \ a column in the reference table. The difference must be below defined\
          \ percentage thresholds. Compares each daily partition (each day of data)\
          \ between the compared table and the reference table (the source of truth)."
        $ref: "#/definitions/ColumnComparisonSumMatchCheckSpec"
      daily_partition_min_match:
        description: "Verifies that percentage of the difference between the minimum\
          \ value in a tested column in a parent table and the minimum value in a\
          \ column in the reference table. The difference must be below defined percentage\
          \ thresholds. Compares each daily partition (each day of data) between the\
          \ compared table and the reference table (the source of truth)."
        $ref: "#/definitions/ColumnComparisonMinMatchCheckSpec"
      daily_partition_max_match:
        description: "Verifies that percentage of the difference between the maximum\
          \ value in a tested column in a parent table and the maximum value in a\
          \ column in the reference table. The difference must be below defined percentage\
          \ thresholds. Compares each daily partition (each day of data) between the\
          \ compared table and the reference table (the source of truth)."
        $ref: "#/definitions/ColumnComparisonMaxMatchCheckSpec"
      daily_partition_mean_match:
        description: "Verifies that percentage of the difference between the mean\
          \ (average) value in a tested column in a parent table and the mean (average)\
          \ value in a column in the reference table. The difference must be below\
          \ defined percentage thresholds. Compares each daily partition (each day\
          \ of data) between the compared table and the reference table (the source\
          \ of truth)."
        $ref: "#/definitions/ColumnComparisonMeanMatchCheckSpec"
      daily_partition_not_null_count_match:
        description: "Verifies that percentage of the difference between the count\
          \ of not null values in a tested column in a parent table and the count\
          \ of not null values in a column in the reference table. The difference\
          \ must be below defined percentage thresholds. Compares each daily partition\
          \ (each day of data) between the compared table and the reference table\
          \ (the source of truth)."
        $ref: "#/definitions/ColumnComparisonNotNullCountMatchCheckSpec"
      daily_partition_null_count_match:
        description: "Verifies that percentage of the difference between the count\
          \ of null values in a tested column in a parent table and the count of null\
          \ values in a column in the reference table. The difference must be below\
          \ defined percentage thresholds. Compares each daily partition (each day\
          \ of data) between the compared table and the reference table (the source\
          \ of truth)."
        $ref: "#/definitions/ColumnComparisonNullCountMatchCheckSpec"
  ColumnComparisonMaxMatchCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sum sensor parameters."
        $ref: "#/definitions/ColumnNumericMaxSensorParametersSpec"
      warning:
        description: "Warning level threshold to raise a data quality incident with\
          \ a warning severity level when the maximum values in the column in the\
          \ parent table and the maximum value in the compared column (in the reference\
          \ table) do not match. The alert is generated for every compared group of\
          \ rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Error level threshold to raise a data quality incident with\
          \ an error severity level when the maximum values in the column in the parent\
          \ table and the maximum value in the compared column (in the reference table)\
          \ do not match. The alert is generated for every compared group of rows\
          \ (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Fatal level threshold to raise a data quality incident with\
          \ a fatal severity level when the maximum values in the column in the parent\
          \ table and the maximum value in the compared column (in the reference table)\
          \ do not match. The alert is generated for every compared group of rows\
          \ (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  ColumnComparisonMeanMatchCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sum sensor parameters."
        $ref: "#/definitions/ColumnNumericMeanSensorParametersSpec"
      warning:
        description: "Warning level threshold to raise a data quality incident with\
          \ a warning severity level when the mean (average) of the values in the\
          \ column in the parent table and the mean (average) of values in the compared\
          \ column (in the reference table) do not match. The alert is generated for\
          \ every compared group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Error level threshold to raise a data quality incident with\
          \ an error severity level when the mean (average) of the values in the column\
          \ in the parent table and the mean (average) of values in the compared column\
          \ (in the reference table) do not match. The alert is generated for every\
          \ compared group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Fatal level threshold to raise a data quality incident with\
          \ a fatal severity level when the mean (average) of the values in the column\
          \ in the parent table and the mean (average) of values in the compared column\
          \ (in the reference table) do not match. The alert is generated for every\
          \ compared group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  ColumnComparisonMinMatchCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sum sensor parameters."
        $ref: "#/definitions/ColumnNumericMinSensorParametersSpec"
      warning:
        description: "Warning level threshold to raise a data quality incident with\
          \ a warning severity level when the minimum values in the column in the\
          \ parent table and the minimum value in the compared column (in the reference\
          \ table) do not match. The alert is generated for every compared group of\
          \ rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Error level threshold to raise a data quality incident with\
          \ an error severity level when the minimum values in the column in the parent\
          \ table and the minimum value in the compared column (in the reference table)\
          \ do not match. The alert is generated for every compared group of rows\
          \ (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Fatal level threshold to raise a data quality incident with\
          \ a fatal severity level when the minimum values in the column in the parent\
          \ table and the minimum value in the compared column (in the reference table)\
          \ do not match. The alert is generated for every compared group of rows\
          \ (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  ColumnComparisonModel:
    type: "object"
    properties:
      compared_column_name:
        type: "string"
        description: "The name of the compared column in the compared table (the tested\
          \ table). The REST API returns all columns defined in the metadata."
      reference_column_name:
        type: "string"
        description: "The name of the reference column in the reference table (the\
          \ source of truth). Set the name of the reference column to enable comparison\
          \ between the compared and the reference columns."
      compare_min:
        description: "The column compare configuration for comparing the minimum value\
          \ between the compared (tested) column and the reference column. Leave null\
          \ when the measure is not compared."
        $ref: "#/definitions/CompareThresholdsModel"
      compare_max:
        description: "The column compare configuration for comparing the maximum value\
          \ between the compared (tested) column and the reference column. Leave null\
          \ when the measure is not compared."
        $ref: "#/definitions/CompareThresholdsModel"
      compare_sum:
        description: "The column compare configuration for comparing the sum of values\
          \ between the compared (tested) column and the reference column. Leave null\
          \ when the measure is not compared."
        $ref: "#/definitions/CompareThresholdsModel"
      compare_mean:
        description: "The column compare configuration for comparing the mean (average)\
          \ value between the compared (tested) column and the reference column. Leave\
          \ null when the measure is not compared."
        $ref: "#/definitions/CompareThresholdsModel"
      compare_null_count:
        description: "The column compare configuration for comparing the count of\
          \ null values between the compared (tested) column and the reference column.\
          \ Leave null when the measure is not compared."
        $ref: "#/definitions/CompareThresholdsModel"
      compare_not_null_count:
        description: "The column compare configuration for comparing the count of\
          \ not null values between the compared (tested) column and the reference\
          \ column. Leave null when the measure is not compared."
        $ref: "#/definitions/CompareThresholdsModel"
    description: "The column to column comparison model used to select which measures\
      \ (min, max, sum, mean, null count, not nul count) are compared for this column\
      \ between the compared (tested) column and the reference column from the reference\
      \ table."
  ColumnComparisonMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      reference_column:
        type: "string"
        description: "The name of the reference column name in the reference table.\
          \ It is the column to which the current column is compared to."
      monthly_sum_match:
        description: "Verifies that percentage of the difference between the sum of\
          \ values in a tested column in a parent table and the sum of a values in\
          \ a column in the reference table. The difference must be below defined\
          \ percentage thresholds. Stores the most recent captured value for each\
          \ month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonSumMatchCheckSpec"
      monthly_min_match:
        description: "Verifies that percentage of the difference between the minimum\
          \ value in a tested column in a parent table and the minimum value in a\
          \ column in the reference table. The difference must be below defined percentage\
          \ thresholds. Stores the most recent captured value for each month when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonMinMatchCheckSpec"
      monthly_max_match:
        description: "Verifies that percentage of the difference between the maximum\
          \ value in a tested column in a parent table and the maximum value in a\
          \ column in the reference table. The difference must be below defined percentage\
          \ thresholds. Stores the most recent captured value for each month when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonMaxMatchCheckSpec"
      monthly_mean_match:
        description: "Verifies that percentage of the difference between the mean\
          \ (average) value in a tested column in a parent table and the mean (average)\
          \ value in a column in the reference table. The difference must be below\
          \ defined percentage thresholds. Stores the most recent captured value for\
          \ each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonMeanMatchCheckSpec"
      monthly_not_null_count_match:
        description: "Verifies that percentage of the difference between the count\
          \ of not null values in a tested column in a parent table and the count\
          \ of not null values in a column in the reference table. The difference\
          \ must be below defined percentage thresholds. Stores the most recent captured\
          \ value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonNotNullCountMatchCheckSpec"
      monthly_null_count_match:
        description: "Verifies that percentage of the difference between the count\
          \ of null values in a tested column in a parent table and the count of null\
          \ values in a column in the reference table. The difference must be below\
          \ defined percentage thresholds. Stores the most recent captured value for\
          \ each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnComparisonNullCountMatchCheckSpec"
  ColumnComparisonMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      reference_column:
        type: "string"
        description: "The name of the reference column name in the reference table.\
          \ It is the column to which the current column is compared to."
      monthly_partition_sum_match:
        description: "Verifies that percentage of the difference between the sum of\
          \ values in a tested column in a parent table and the sum of a values in\
          \ a column in the reference table. The difference must be below defined\
          \ percentage thresholds. Compares each monthly partition (each month of\
          \ data) between the compared table and the reference table (the source of\
          \ truth)."
        $ref: "#/definitions/ColumnComparisonSumMatchCheckSpec"
      monthly_partition_min_match:
        description: "Verifies that percentage of the difference between the minimum\
          \ value in a tested column in a parent table and the minimum value in a\
          \ column in the reference table. The difference must be below defined percentage\
          \ thresholds. Compares each monthly partition (each month of data) between\
          \ the compared table and the reference table (the source of truth)."
        $ref: "#/definitions/ColumnComparisonMinMatchCheckSpec"
      monthly_partition_max_match:
        description: "Verifies that percentage of the difference between the maximum\
          \ value in a tested column in a parent table and the maximum value in a\
          \ column in the reference table. The difference must be below defined percentage\
          \ thresholds. Compares each monthly partition (each month of data) between\
          \ the compared table and the reference table (the source of truth)."
        $ref: "#/definitions/ColumnComparisonMaxMatchCheckSpec"
      monthly_partition_mean_match:
        description: "Verifies that percentage of the difference between the mean\
          \ (average) value in a tested column in a parent table and the mean (average)\
          \ value in a column in the reference table. The difference must be below\
          \ defined percentage thresholds. Compares each monthly partition (each month\
          \ of data) between the compared table and the reference table (the source\
          \ of truth)."
        $ref: "#/definitions/ColumnComparisonMeanMatchCheckSpec"
      monthly_partition_not_null_count_match:
        description: "Verifies that percentage of the difference between the count\
          \ of not null values in a tested column in a parent table and the count\
          \ of not null values in a column in the reference table. The difference\
          \ must be below defined percentage thresholds. Compares each monthly partition\
          \ (each month of data) between the compared table and the reference table\
          \ (the source of truth)."
        $ref: "#/definitions/ColumnComparisonNotNullCountMatchCheckSpec"
      monthly_partition_null_count_match:
        description: "Verifies that percentage of the difference between the count\
          \ of null values in a tested column in a parent table and the count of null\
          \ values in a column in the reference table. The difference must be below\
          \ defined percentage thresholds. Compares each monthly partition (each month\
          \ of data) between the compared table and the reference table (the source\
          \ of truth)."
        $ref: "#/definitions/ColumnComparisonNullCountMatchCheckSpec"
  ColumnComparisonNotNullCountMatchCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sum sensor parameters."
        $ref: "#/definitions/ColumnNullsNotNullsCountSensorParametersSpec"
      warning:
        description: "Warning level threshold to raise a data quality incident with\
          \ a warning severity level when the count of not null values in the column\
          \ in the parent table and the count of not null values in the compared column\
          \ (in the reference table) do not match. The alert is generated for every\
          \ compared group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Error level threshold to raise a data quality incident with\
          \ an error severity level when the count of not null values in the column\
          \ in the parent table and the count of not null values in the compared column\
          \ (in the reference table) do not match. The alert is generated for every\
          \ compared group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Fatal level threshold to raise a data quality incident with\
          \ a fatal severity level when the count of not null values in the column\
          \ in the parent table and the count of not null values in the compared column\
          \ (in the reference table) do not match. The alert is generated for every\
          \ compared group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  ColumnComparisonNullCountMatchCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sum sensor parameters."
        $ref: "#/definitions/ColumnNullsNullsCountSensorParametersSpec"
      warning:
        description: "Warning level threshold to raise a data quality incident with\
          \ a warning severity level when the count of null values in the column in\
          \ the parent table and the count of null values in the compared column (in\
          \ the reference table) do not match. The alert is generated for every compared\
          \ group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Error level threshold to raise a data quality incident with\
          \ an error severity level when the count of null values in the column in\
          \ the parent table and the count of null values in the compared column (in\
          \ the reference table) do not match. The alert is generated for every compared\
          \ group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Fatal level threshold to raise a data quality incident with\
          \ a fatal severity level when the count of null values in the column in\
          \ the parent table and the count of null values in the compared column (in\
          \ the reference table) do not match. The alert is generated for every compared\
          \ group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  ColumnComparisonProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      reference_column:
        type: "string"
        description: "The name of the reference column name in the reference table.\
          \ It is the column to which the current column is compared to."
      profile_sum_match:
        description: "Verifies that percentage of the difference between the sum of\
          \ values in a tested column in a parent table and the sum of a values in\
          \ a column in the reference table. The difference must be below defined\
          \ percentage thresholds."
        $ref: "#/definitions/ColumnComparisonSumMatchCheckSpec"
      profile_min_match:
        description: "Verifies that percentage of the difference between the minimum\
          \ value in a tested column in a parent table and the minimum value in a\
          \ column in the reference table. The difference must be below defined percentage\
          \ thresholds."
        $ref: "#/definitions/ColumnComparisonMinMatchCheckSpec"
      profile_max_match:
        description: "Verifies that percentage of the difference between the maximum\
          \ value in a tested column in a parent table and the maximum value in a\
          \ column in the reference table. The difference must be below defined percentage\
          \ thresholds."
        $ref: "#/definitions/ColumnComparisonMaxMatchCheckSpec"
      profile_mean_match:
        description: "Verifies that percentage of the difference between the mean\
          \ (average) value in a tested column in a parent table and the mean (average)\
          \ value in a column in the reference table. The difference must be below\
          \ defined percentage thresholds."
        $ref: "#/definitions/ColumnComparisonMeanMatchCheckSpec"
      profile_not_null_count_match:
        description: "Verifies that percentage of the difference between the count\
          \ of not null values in a tested column in a parent table and the count\
          \ of not null values in a column in the reference table. The difference\
          \ must be below defined percentage thresholds."
        $ref: "#/definitions/ColumnComparisonNotNullCountMatchCheckSpec"
      profile_null_count_match:
        description: "Verifies that percentage of the difference between the count\
          \ of null values in a tested column in a parent table and the count of null\
          \ values in a column in the reference table. The difference must be below\
          \ defined percentage thresholds."
        $ref: "#/definitions/ColumnComparisonNullCountMatchCheckSpec"
  ColumnComparisonSumMatchCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sum sensor parameters."
        $ref: "#/definitions/ColumnNumericSumSensorParametersSpec"
      warning:
        description: "Warning level threshold to raise a data quality incident with\
          \ a warning severity level when the sum of the values in the column in the\
          \ parent table and the sum of values in the compared column (in the reference\
          \ table) do not match. The alert is generated for every compared group of\
          \ rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Error level threshold to raise a data quality incident with\
          \ an error severity level when the sum of the values in the column in the\
          \ parent table and the sum of values in the compared column (in the reference\
          \ table) do not match. The alert is generated for every compared group of\
          \ rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Fatal level threshold to raise a data quality incident with\
          \ a fatal severity level when the sum of the values in the column in the\
          \ parent table and the sum of values in the compared column (in the reference\
          \ table) do not match. The alert is generated for every compared group of\
          \ rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  ColumnConversionsDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_text_parsable_to_boolean_percent:
        description: "Verifies that the percentage of text values that are parsable\
          \ to a boolean value does not fall below the minimum accepted percentage,\
          \ text values identified as boolean placeholders are: 0, 1, true, false,\
          \ t, f, yes, no, y, n. Stores the most recent captured value for each day\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextParsableToBooleanPercentCheckSpec"
      daily_text_parsable_to_integer_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ an integer value in a column does not fall below the minimum accepted\
          \ percentage. Stores the most recent captured value for each day when the\
          \ data quality check was evaluated."
        $ref: "#/definitions/ColumnTextParsableToIntegerPercentCheckSpec"
      daily_text_parsable_to_float_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ a float value in a column does not fall below the minimum accepted percentage.\
          \ Stores the most recent captured value for each day when the data quality\
          \ check was evaluated."
        $ref: "#/definitions/ColumnTextParsableToFloatPercentCheckSpec"
      daily_text_parsable_to_date_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ a date value in a column does not fall below the minimum accepted percentage.\
          \ DQOps uses a safe_cast when possible, otherwise the text is verified using\
          \ a regular expression. Stores the most recent captured value for each day\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextParsableToDatePercentCheckSpec"
  ColumnConversionsDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_text_parsable_to_boolean_percent:
        description: "Verifies that the percentage of text values that are parsable\
          \ to a boolean value does not fall below the minimum accepted percentage,\
          \ text values identified as boolean placeholders are: 0, 1, true, false,\
          \ t, f, yes, no, y, n. Analyzes every daily partition and creates a separate\
          \ data quality check result with the time period value that identifies the\
          \ daily partition."
        $ref: "#/definitions/ColumnTextParsableToBooleanPercentCheckSpec"
      daily_partition_text_parsable_to_integer_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ an integer value in a column does not fall below the minimum accepted\
          \ percentage. Analyzes every daily partition and creates a separate data\
          \ quality check result with the time period value that identifies the daily\
          \ partition."
        $ref: "#/definitions/ColumnTextParsableToIntegerPercentCheckSpec"
      daily_partition_text_parsable_to_float_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ a float value in a column does not fall below the minimum accepted percentage.\
          \ Analyzes every daily partition and creates a separate data quality check\
          \ result with the time period value that identifies the daily partition."
        $ref: "#/definitions/ColumnTextParsableToFloatPercentCheckSpec"
      daily_partition_text_parsable_to_date_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ a date value in a column does not fall below the minimum accepted percentage.\
          \ DQOps uses a safe_cast when possible, otherwise the text is verified using\
          \ a regular expression. Analyzes every daily partition and creates a separate\
          \ data quality check result with the time period value that identifies the\
          \ daily partition."
        $ref: "#/definitions/ColumnTextParsableToDatePercentCheckSpec"
  ColumnConversionsMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_text_parsable_to_boolean_percent:
        description: "Verifies that the percentage of text values that are parsable\
          \ to a boolean value does not fall below the minimum accepted percentage,\
          \ text values identified as boolean placeholders are: 0, 1, true, false,\
          \ t, f, yes, no, y, n. Stores the most recent captured value for each month\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextParsableToBooleanPercentCheckSpec"
      monthly_text_parsable_to_integer_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ an integer value in a column does not fall below the minimum accepted\
          \ percentage. Stores the most recent captured value for each month when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextParsableToIntegerPercentCheckSpec"
      monthly_text_parsable_to_float_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ a float value in a column does not fall below the minimum accepted percentage.\
          \ Stores the most recent captured value for each month when the data quality\
          \ check was evaluated."
        $ref: "#/definitions/ColumnTextParsableToFloatPercentCheckSpec"
      monthly_text_parsable_to_date_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ a date value in a column does not fall below the minimum accepted percentage.\
          \ DQOps uses a safe_cast when possible, otherwise the text is verified using\
          \ a regular expression. Stores the most recent captured value for each month\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextParsableToDatePercentCheckSpec"
  ColumnConversionsMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_text_parsable_to_boolean_percent:
        description: "Verifies that the percentage of text values that are parsable\
          \ to a boolean value does not fall below the minimum accepted percentage,\
          \ text values identified as boolean placeholders are: 0, 1, true, false,\
          \ t, f, yes, no, y, n. Analyzes every monthly partition and creates a separate\
          \ data quality check result with the time period value that identifies the\
          \ monthly partition."
        $ref: "#/definitions/ColumnTextParsableToBooleanPercentCheckSpec"
      monthly_partition_text_parsable_to_integer_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ an integer value in a column does not fall below the minimum accepted\
          \ percentage. Analyzes every monthly partition and creates a separate data\
          \ quality check result with the time period value that identifies the monthly\
          \ partition."
        $ref: "#/definitions/ColumnTextParsableToIntegerPercentCheckSpec"
      monthly_partition_text_parsable_to_float_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ a float value in a column does not fall below the minimum accepted percentage.\
          \ Analyzes every monthly partition and creates a separate data quality check\
          \ result with the time period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnTextParsableToFloatPercentCheckSpec"
      monthly_partition_text_parsable_to_date_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ a date value in a column does not fall below the minimum accepted percentage.\
          \ DQOps uses a safe_cast when possible, otherwise the text is verified using\
          \ a regular expression. Analyzes every monthly partition and creates a separate\
          \ data quality check result with the time period value that identifies the\
          \ monthly partition."
        $ref: "#/definitions/ColumnTextParsableToDatePercentCheckSpec"
  ColumnConversionsProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_text_parsable_to_boolean_percent:
        description: "Verifies that the percentage of text values that are parsable\
          \ to a boolean value does not fall below the minimum accepted percentage,\
          \ text values identified as boolean placeholders are: 0, 1, true, false,\
          \ t, f, yes, no, y, n."
        $ref: "#/definitions/ColumnTextParsableToBooleanPercentCheckSpec"
      profile_text_parsable_to_integer_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ an integer value in a column does not fall below the minimum accepted\
          \ percentage"
        $ref: "#/definitions/ColumnTextParsableToIntegerPercentCheckSpec"
      profile_text_parsable_to_float_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ a float value in a column does not fall below the minimum accepted percentage"
        $ref: "#/definitions/ColumnTextParsableToFloatPercentCheckSpec"
      profile_text_parsable_to_date_percent:
        description: "Verifies that the percentage text values that are parsable to\
          \ a date value in a column does not fall below the minimum accepted percentage.\
          \ DQOps uses a safe_cast when possible, otherwise the text is verified using\
          \ a regular expression"
        $ref: "#/definitions/ColumnTextParsableToDatePercentCheckSpec"
  ColumnCurrentDataQualityStatusModel:
    type: "object"
    properties:
      current_severity:
        type: "string"
        description: "The most recent data quality issue severity for this column.\
          \ When the table is monitored using data grouping, it is the highest issue\
          \ severity of all recently analyzed data groups. For partitioned checks,\
          \ it is the highest severity of all results for all partitions (time periods)\
          \ in the analyzed time range."
        enum:
        - "valid"
        - "warning"
        - "error"
        - "fatal"
      highest_historical_severity:
        type: "string"
        description: "The highest severity of previous executions of this data quality\
          \ issue in the analyzed time range. It can be different from the *current_severity*\
          \ if the data quality issue was solved and the most recently data quality\
          \ issue did not detect it anymore. For partitioned checks, this field returns\
          \ the same value as the *current_severity*, because data quality issues\
          \ in older partitions are still valid."
        enum:
        - "valid"
        - "warning"
        - "error"
        - "fatal"
      last_check_executed_at:
        type: "integer"
        format: "int64"
        description: "The UTC timestamp when the most recent data quality check was\
          \ executed on the column."
      executed_checks:
        type: "integer"
        format: "int32"
        description: "The total number of most recent checks that were executed on\
          \ the column. Table comparison checks that are comparing groups of data\
          \ are counted as the number of compared data groups."
      valid_results:
        type: "integer"
        format: "int32"
        description: "The number of most recent valid data quality checks that passed\
          \ without raising any issues."
      warnings:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising a warning severity data quality issue."
      errors:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising an error severity data quality issue."
      fatals:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising a fatal severity data quality issue."
      execution_errors:
        type: "integer"
        format: "int32"
        description: "The number of data quality check execution errors that were\
          \ reported due to access issues to the data source, invalid mapping in DQOps,\
          \ invalid queries in data quality sensors or invalid python rules. When\
          \ an execution error is reported, the configuration of a data quality check\
          \ on a column must be updated."
      checks:
        type: "object"
        description: "The dictionary of statuses for data quality checks. The keys\
          \ are data quality check names, the values are the current data quality\
          \ check statuses that describe the most current status."
        additionalProperties:
          $ref: "#/definitions/CheckCurrentDataQualityStatusModel"
      dimensions:
        type: "object"
        description: "Dictionary of the current data quality statues for each data\
          \ quality dimension."
        additionalProperties:
          $ref: "#/definitions/DimensionCurrentDataQualityStatusModel"
    description: "The column's most recent data quality status. It is a summary of\
      \ the results of the most recently executed data quality checks on the column.\
      \ Verify the value of the current_severity to see if there are any data quality\
      \ issues on the column."
  ColumnCustomSqlDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_sql_condition_failed_on_column:
        description: "Verifies that a custom SQL expression is met for each row. Counts\
          \ the number of rows where the expression is not satisfied, and raises an\
          \ issue if too many failures were detected. This check is used also to compare\
          \ values between the current column and another column: `{alias}.{column}\
          \ > col_tax`. Stores the most recent captured count of failed rows for each\
          \ day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnSqlConditionFailedCheckSpec"
      daily_sql_condition_passed_percent_on_column:
        description: "Verifies that a minimum percentage of rows passed a custom SQL\
          \ condition (expression). Reference the current column by using tokens,\
          \ for example: `{alias}.{column} > {alias}.col_tax`. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnSqlConditionPassedPercentCheckSpec"
      daily_sql_aggregate_expression_on_column:
        description: "Verifies that a custom aggregated SQL expression (MIN, MAX,\
          \ etc.) is not outside the expected range. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnSqlAggregateExpressionCheckSpec"
      daily_import_custom_result_on_column:
        description: "Runs a custom query that retrieves a result of a data quality\
          \ check performed in the data engineering, whose result (the severity level)\
          \ is pulled from a separate table."
        $ref: "#/definitions/ColumnSqlImportCustomResultCheckSpec"
  ColumnCustomSqlDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_sql_condition_failed_on_column:
        description: "Verifies that a custom SQL expression is met for each row. Counts\
          \ the number of rows where the expression is not satisfied, and raises an\
          \ issue if too many failures were detected. This check is used also to compare\
          \ values between the current column and another column: `{alias}.{column}\
          \ > {alias}.col_tax`. Stores a separate data quality check result for each\
          \ daily partition."
        $ref: "#/definitions/ColumnSqlConditionFailedCheckSpec"
      daily_partition_sql_condition_passed_percent_on_column:
        description: "Verifies that a minimum percentage of rows passed a custom SQL\
          \ condition (expression). Reference the current column by using tokens,\
          \ for example: `{alias}.{column} > {alias}.col_tax`. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/ColumnSqlConditionPassedPercentCheckSpec"
      daily_partition_sql_aggregate_expression_on_column:
        description: "Verifies that a custom aggregated SQL expression (MIN, MAX,\
          \ etc.) is not outside the expected range. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnSqlAggregateExpressionCheckSpec"
      daily_partition_import_custom_result_on_column:
        description: "Runs a custom query that retrieves a result of a data quality\
          \ check performed in the data engineering, whose result (the severity level)\
          \ is pulled from a separate table."
        $ref: "#/definitions/ColumnSqlImportCustomResultCheckSpec"
  ColumnCustomSqlMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_sql_condition_failed_on_column:
        description: "Verifies that a custom SQL expression is met for each row. Counts\
          \ the number of rows where the expression is not satisfied, and raises an\
          \ issue if too many failures were detected. This check is used also to compare\
          \ values between the current column and another column: `{alias}.{column}\
          \ > {alias}.col_tax`. Stores the most recent captured count of failed rows\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnSqlConditionFailedCheckSpec"
      monthly_sql_condition_passed_percent_on_column:
        description: "Verifies that a minimum percentage of rows passed a custom SQL\
          \ condition (expression). Reference the current column by using tokens,\
          \ for example: `{alias}.{column} > {alias}.col_tax`.  Stores the most recent\
          \ check result for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnSqlConditionPassedPercentCheckSpec"
      monthly_sql_aggregate_expression_on_column:
        description: "Verifies that a custom aggregated SQL expression (MIN, MAX,\
          \ etc.) is not outside the expected range. Stores the most recent check\
          \ result for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnSqlAggregateExpressionCheckSpec"
      monthly_import_custom_result_on_column:
        description: "Runs a custom query that retrieves a result of a data quality\
          \ check performed in the data engineering, whose result (the severity level)\
          \ is pulled from a separate table."
        $ref: "#/definitions/ColumnSqlImportCustomResultCheckSpec"
  ColumnCustomSqlMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_sql_condition_failed_on_column:
        description: "Verifies that a custom SQL expression is met for each row. Counts\
          \ the number of rows where the expression is not satisfied, and raises an\
          \ issue if too many failures were detected. This check is used also to compare\
          \ values between the current column and another column: `{alias}.{column}\
          \ > {alias}.col_tax`. Stores a separate data quality check result for each\
          \ monthly partition."
        $ref: "#/definitions/ColumnSqlConditionFailedCheckSpec"
      monthly_partition_sql_condition_passed_percent_on_column:
        description: "Verifies that a minimum percentage of rows passed a custom SQL\
          \ condition (expression). Reference the current column by using tokens,\
          \ for example: `{alias}.{column} > {alias}.col_tax`. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/ColumnSqlConditionPassedPercentCheckSpec"
      monthly_partition_sql_aggregate_expression_on_column:
        description: "Verifies that a custom aggregated SQL expression (MIN, MAX,\
          \ etc.) is not outside the expected range. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnSqlAggregateExpressionCheckSpec"
      monthly_partition_import_custom_result_on_column:
        description: "Runs a custom query that retrieves a result of a data quality\
          \ check performed in the data engineering, whose result (the severity level)\
          \ is pulled from a separate table."
        $ref: "#/definitions/ColumnSqlImportCustomResultCheckSpec"
  ColumnCustomSqlProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_sql_condition_failed_on_column:
        description: "Verifies that a custom SQL expression is met for each row. Counts\
          \ the number of rows where the expression is not satisfied, and raises an\
          \ issue if too many failures were detected. This check is used also to compare\
          \ values between the current column and another column: `{alias}.{column}\
          \ > col_tax`."
        $ref: "#/definitions/ColumnSqlConditionFailedCheckSpec"
      profile_sql_condition_passed_percent_on_column:
        description: "Verifies that a minimum percentage of rows passed a custom SQL\
          \ condition (expression). Reference the current column by using tokens,\
          \ for example: `{alias}.{column} > {alias}.col_tax`."
        $ref: "#/definitions/ColumnSqlConditionPassedPercentCheckSpec"
      profile_sql_aggregate_expression_on_column:
        description: "Verifies that a custom aggregated SQL expression (MIN, MAX,\
          \ etc.) is not outside the expected range."
        $ref: "#/definitions/ColumnSqlAggregateExpressionCheckSpec"
      profile_import_custom_result_on_column:
        description: "Runs a custom query that retrieves a result of a data quality\
          \ check performed in the data engineering, whose result (the severity level)\
          \ is pulled from a separate table."
        $ref: "#/definitions/ColumnSqlImportCustomResultCheckSpec"
  ColumnDailyMonitoringCheckCategoriesSpec:
    type: "object"
    properties:
      custom:
        type: "object"
        description: "Dictionary of custom checks. The keys are check names within\
          \ this category."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      nulls:
        description: "Daily monitoring checks of nulls in the column"
        $ref: "#/definitions/ColumnNullsDailyMonitoringChecksSpec"
      uniqueness:
        description: "Daily monitoring checks of uniqueness in the column"
        $ref: "#/definitions/ColumnUniquenessDailyMonitoringChecksSpec"
      accepted_values:
        description: "Configuration of accepted values checks on a column level"
        $ref: "#/definitions/ColumnAcceptedValuesDailyMonitoringChecksSpec"
      text:
        description: "Daily monitoring checks of text values in the column"
        $ref: "#/definitions/ColumnTextDailyMonitoringChecksSpec"
      whitespace:
        description: "Configuration of column level checks that detect blank and whitespace\
          \ values"
        $ref: "#/definitions/ColumnWhitespaceDailyMonitoringChecksSpec"
      conversions:
        description: "Configuration of conversion testing checks on a column level."
        $ref: "#/definitions/ColumnConversionsDailyMonitoringChecksSpec"
      patterns:
        description: "Daily monitoring checks of pattern matching on a column level"
        $ref: "#/definitions/ColumnPatternsDailyMonitoringChecksSpec"
      pii:
        description: "Daily monitoring checks of Personal Identifiable Information\
          \ (PII) in the column"
        $ref: "#/definitions/ColumnPiiDailyMonitoringChecksSpec"
      numeric:
        description: "Daily monitoring checks of numeric values in the column"
        $ref: "#/definitions/ColumnNumericDailyMonitoringChecksSpec"
      anomaly:
        description: "Daily monitoring checks of anomalies in numeric columns"
        $ref: "#/definitions/ColumnAnomalyDailyMonitoringChecksSpec"
      datetime:
        description: "Daily monitoring checks of datetime in the column"
        $ref: "#/definitions/ColumnDatetimeDailyMonitoringChecksSpec"
      bool:
        description: "Daily monitoring checks of booleans in the column"
        $ref: "#/definitions/ColumnBoolDailyMonitoringChecksSpec"
      integrity:
        description: "Daily monitoring checks of integrity in the column"
        $ref: "#/definitions/ColumnIntegrityDailyMonitoringChecksSpec"
      accuracy:
        description: "Daily monitoring checks of accuracy in the column"
        $ref: "#/definitions/ColumnAccuracyDailyMonitoringChecksSpec"
      custom_sql:
        description: "Daily monitoring checks of custom SQL checks in the column"
        $ref: "#/definitions/ColumnCustomSqlDailyMonitoringChecksSpec"
      datatype:
        description: "Daily monitoring checks of datatype in the column"
        $ref: "#/definitions/ColumnDatatypeDailyMonitoringChecksSpec"
      schema:
        description: "Daily monitoring column schema checks"
        $ref: "#/definitions/ColumnSchemaDailyMonitoringChecksSpec"
      comparisons:
        type: "object"
        description: "Dictionary of configuration of checks for table comparisons\
          \ at a column level. The key that identifies each comparison must match\
          \ the name of a data comparison that is configured on the parent table."
        additionalProperties:
          $ref: "#/definitions/ColumnComparisonDailyMonitoringChecksSpec"
  ColumnDailyPartitionedCheckCategoriesSpec:
    type: "object"
    properties:
      custom:
        type: "object"
        description: "Dictionary of custom checks. The keys are check names within\
          \ this category."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      nulls:
        description: "Daily partitioned checks of nulls in the column"
        $ref: "#/definitions/ColumnNullsDailyPartitionedChecksSpec"
      uniqueness:
        description: "Daily partitioned checks of uniqueness in the column"
        $ref: "#/definitions/ColumnUniquenessDailyPartitionedChecksSpec"
      accepted_values:
        description: "Configuration of accepted values checks on a column level"
        $ref: "#/definitions/ColumnAcceptedValuesDailyPartitionedChecksSpec"
      text:
        description: "Daily partitioned checks of text values in the column"
        $ref: "#/definitions/ColumnTextDailyPartitionedChecksSpec"
      whitespace:
        description: "Configuration of column level checks that detect blank and whitespace\
          \ values"
        $ref: "#/definitions/ColumnWhitespaceDailyPartitionedChecksSpec"
      conversions:
        description: "Configuration of conversion testing checks on a column level."
        $ref: "#/definitions/ColumnConversionsDailyPartitionedChecksSpec"
      patterns:
        description: "Daily partitioned pattern match checks on a column level"
        $ref: "#/definitions/ColumnPatternsDailyPartitionedChecksSpec"
      pii:
        description: "Daily partitioned checks of Personal Identifiable Information\
          \ (PII) in the column"
        $ref: "#/definitions/ColumnPiiDailyPartitionedChecksSpec"
      numeric:
        description: "Daily partitioned checks of numeric values in the column"
        $ref: "#/definitions/ColumnNumericDailyPartitionedChecksSpec"
      anomaly:
        description: "Daily partitioned checks for anomalies in numeric columns"
        $ref: "#/definitions/ColumnAnomalyDailyPartitionedChecksSpec"
      datetime:
        description: "Daily partitioned checks of datetime in the column"
        $ref: "#/definitions/ColumnDatetimeDailyPartitionedChecksSpec"
      bool:
        description: "Daily partitioned checks for booleans in the column"
        $ref: "#/definitions/ColumnBoolDailyPartitionedChecksSpec"
      integrity:
        description: "Daily partitioned checks for integrity in the column"
        $ref: "#/definitions/ColumnIntegrityDailyPartitionedChecksSpec"
      custom_sql:
        description: "Daily partitioned checks using custom SQL expressions evaluated\
          \ on the column"
        $ref: "#/definitions/ColumnCustomSqlDailyPartitionedChecksSpec"
      datatype:
        description: "Daily partitioned checks for datatype in the column"
        $ref: "#/definitions/ColumnDatatypeDailyPartitionedChecksSpec"
      comparisons:
        type: "object"
        description: "Dictionary of configuration of checks for table comparisons\
          \ at a column level. The key that identifies each comparison must match\
          \ the name of a data comparison that is configured on the parent table."
        additionalProperties:
          $ref: "#/definitions/ColumnComparisonDailyPartitionedChecksSpec"
  ColumnDatatypeDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_detected_datatype_in_text:
        description: "Detects the data type of text values stored in the column. The\
          \ sensor returns the code of the detected type of column data: 1 - integers,\
          \ 2 - floats, 3 - dates, 4 - datetimes, 5 - timestamps, 6 - booleans, 7\
          \ - strings, 8 - mixed data types. Raises a data quality issue when the\
          \ detected data type does not match the expected data type. Stores the most\
          \ recent captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnDetectedDatatypeInTextCheckSpec"
      daily_detected_datatype_in_text_changed:
        description: "Detects that the data type of texts stored in a text column\
          \ has changed since the last verification. The sensor returns the detected\
          \ type of column data: 1 - integers, 2 - floats, 3 - dates, 4 - datetimes,\
          \ 5 - timestamps, 6 - booleans, 7 - strings, 8 - mixed data types. Stores\
          \ the most recent captured value for each day when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnDatatypeDetectedDatatypeInTextChangedCheckSpec"
  ColumnDatatypeDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_detected_datatype_in_text:
        description: "Detects the data type of text values stored in the column. The\
          \ sensor returns the code of the detected type of column data: 1 - integers,\
          \ 2 - floats, 3 - dates, 4 - datetimes, 5 - timestamps, 6 - booleans, 7\
          \ - strings, 8 - mixed data types. Raises a data quality issue when the\
          \ detected data type does not match the expected data type. Stores a separate\
          \ data quality check result for each daily partition."
        $ref: "#/definitions/ColumnDetectedDatatypeInTextCheckSpec"
      daily_partition_detected_datatype_in_text_changed:
        description: "Detects that the data type of texts stored in a text column\
          \ has changed when compared to an earlier not empty partition. The sensor\
          \ returns the detected type of column data: 1 - integers, 2 - floats, 3\
          \ - dates, 4 - datetimes, 5 - timestamps, 6 - booleans, 7 - strings, 8 -\
          \ mixed data types. Stores a separate data quality check result for each\
          \ daily partition."
        $ref: "#/definitions/ColumnDatatypeDetectedDatatypeInTextChangedCheckSpec"
  ColumnDatatypeDetectedDatatypeInTextChangedCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "The sensor parameters for a sensor that returns a value that\
          \ identifies the detected type of column data: 1 - integers, 2 - floats,\
          \ 3 - dates, 4 - datetimes, 5 - timestamps, 6 - booleans, 7 - strings, 8\
          \ - mixed data types."
        $ref: "#/definitions/ColumnDatatypeStringDatatypeDetectSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check, detects that the data type\
          \ of values stored in a column has changed since the last time it was evaluated\
          \ or the data type in the current daily/monthly partition differs from the\
          \ data type in the previous partition."
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      error:
        description: "Default alerting threshold that raises a data quality issue\
          \ at an error severity level, detects that the data type of values stored\
          \ in a column has changed since the last time it was evaluated or the data\
          \ type in the current daily/monthly partition differs from the data type\
          \ in the previous partition."
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem, detects that the data type of\
          \ values stored in a column has changed since the last time it was evaluated\
          \ or the data type in the current daily/monthly partition differs from the\
          \ data type in the previous partition."
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
  ColumnDatatypeMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_detected_datatype_in_text:
        description: "Detects the data type of text values stored in the column. The\
          \ sensor returns the code of the detected type of column data: 1 - integers,\
          \ 2 - floats, 3 - dates, 4 - datetimes, 5 - timestamps, 6 - booleans, 7\
          \ - strings, 8 - mixed data types. Raises a data quality issue when the\
          \ detected data type does not match the expected data type. Stores the most\
          \ recent check result for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnDetectedDatatypeInTextCheckSpec"
      monthly_detected_datatype_in_text_changed:
        description: "Detects that the data type of texts stored in a text column\
          \ has changed since the last verification. The sensor returns the detected\
          \ type of column data: 1 - integers, 2 - floats, 3 - dates, 4 - datetimes,\
          \ 5 - timestamps, 6 - booleans, 7 - strings, 8 - mixed data types. Stores\
          \ the most recent captured value for each day when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnDatatypeDetectedDatatypeInTextChangedCheckSpec"
  ColumnDatatypeMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_detected_datatype_in_text:
        description: "Detects the data type of text values stored in the column. The\
          \ sensor returns the code of the detected type of column data: 1 - integers,\
          \ 2 - floats, 3 - dates, 4 - datetimes, 5 - timestamps, 6 - booleans, 7\
          \ - strings, 8 - mixed data types. Raises a data quality issue when the\
          \ detected data type does not match the expected data type. Stores a separate\
          \ data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnDetectedDatatypeInTextCheckSpec"
      monthly_partition_detected_datatype_in_text_changed:
        description: "Detects that the data type of texts stored in a text column\
          \ has changed when compared to an earlier not empty partition. The sensor\
          \ returns the detected type of column data: 1 - integers, 2 - floats, 3\
          \ - dates, 4 - datetimes, 5 - timestamps, 6 - booleans, 7 - strings, 8 -\
          \ mixed data types. Stores a separate data quality check result for each\
          \ monthly partition."
        $ref: "#/definitions/ColumnDatatypeDetectedDatatypeInTextChangedCheckSpec"
  ColumnDatatypeProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_detected_datatype_in_text:
        description: "Detects the data type of text values stored in the column. The\
          \ sensor returns the code of the detected type of column data: 1 - integers,\
          \ 2 - floats, 3 - dates, 4 - datetimes, 5 - timestamps, 6 - booleans, 7\
          \ - strings, 8 - mixed data types. Raises a data quality issue when the\
          \ detected data type does not match the expected data type."
        $ref: "#/definitions/ColumnDetectedDatatypeInTextCheckSpec"
      profile_detected_datatype_in_text_changed:
        description: "Detects that the data type of texts stored in a text column\
          \ has changed since the last verification. The sensor returns the detected\
          \ data type of a column: 1 - integers, 2 - floats, 3 - dates, 4 - datetimes,\
          \ 5 - timestamps, 6 - booleans, 7 - strings, 8 - mixed data types."
        $ref: "#/definitions/ColumnDatatypeDetectedDatatypeInTextChangedCheckSpec"
  ColumnDatatypeStringDatatypeDetectSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnDateInRangePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnDateInRangePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set percentage of date values\
          \ in the range defined by the user in a column that raises a data quality\
          \ error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnDateInRangePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      min_date:
        type: "string"
        format: "date"
        description: "The earliest accepted date."
      max_date:
        type: "string"
        format: "date"
        description: "The latest accepted date."
  ColumnDateValuesInFuturePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnDatetimeDateValuesInFuturePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set percentage of date values\
          \ in future in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnDatetimeDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_date_values_in_future_percent:
        description: "Detects dates in the future in date, datetime and timestamp\
          \ columns. Measures a percentage of dates in the future. Raises a data quality\
          \ issue when too many future dates are found. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnDateValuesInFuturePercentCheckSpec"
      daily_date_in_range_percent:
        description: "Verifies that the dates in date, datetime, or timestamp columns\
          \ are within a reasonable range of dates. The default configuration detects\
          \ fake dates such as 1900-01-01 and 2099-12-31. Measures the percentage\
          \ of valid dates and raises a data quality issue when too many dates are\
          \ found. Stores the most recent captured value for each day when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnDateInRangePercentCheckSpec"
      daily_text_match_date_format_percent:
        description: "Verifies that the values in text columns match one of the predefined\
          \ date formats, such as an ISO 8601 date. Measures the percentage of valid\
          \ date strings and raises a data quality issue when too many invalid date\
          \ strings are found. Creates a separate data quality check (and an alert)\
          \ for each daily monitoring."
        $ref: "#/definitions/ColumnTextMatchDateFormatPercentCheckSpec"
  ColumnDatetimeDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_date_values_in_future_percent:
        description: "Detects dates in the future in date, datetime and timestamp\
          \ columns. Measures a percentage of dates in the future. Raises a data quality\
          \ issue when too many future dates are found. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnDateValuesInFuturePercentCheckSpec"
      daily_partition_date_in_range_percent:
        description: "Verifies that the dates in date, datetime, or timestamp columns\
          \ are within a reasonable range of dates. The default configuration detects\
          \ fake dates such as 1900-01-01 and 2099-12-31. Measures the percentage\
          \ of valid dates and raises a data quality issue when too many dates are\
          \ found. Stores a separate data quality check result for each daily partition."
        $ref: "#/definitions/ColumnDateInRangePercentCheckSpec"
      daily_partition_text_match_date_format_percent:
        description: "Verifies that the values in text columns match one of the predefined\
          \ date formats, such as an ISO 8601 date. Measures the percentage of valid\
          \ date strings and raises a data quality issue when too many invalid date\
          \ strings are found. Stores a separate data quality check result for each\
          \ daily partition."
        $ref: "#/definitions/ColumnTextMatchDateFormatPercentCheckSpec"
  ColumnDatetimeDateValuesInFuturePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnDatetimeMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_date_values_in_future_percent:
        description: "Detects dates in the future in date, datetime and timestamp\
          \ columns. Measures a percentage of dates in the future. Raises a data quality\
          \ issue when too many future dates are found. Stores the most recent check\
          \ result for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnDateValuesInFuturePercentCheckSpec"
      monthly_date_in_range_percent:
        description: "Verifies that the dates in date, datetime, or timestamp columns\
          \ are within a reasonable range of dates. The default configuration detects\
          \ fake dates such as 1900-01-01 and 2099-12-31. Measures the percentage\
          \ of valid dates and raises a data quality issue when too many dates are\
          \ found. Stores the most recent check result for each month when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnDateInRangePercentCheckSpec"
      monthly_text_match_date_format_percent:
        description: "Verifies that the values in text columns match one of the predefined\
          \ date formats, such as an ISO 8601 date. Measures the percentage of valid\
          \ date strings and raises a data quality issue when too many invalid date\
          \ strings are found. Creates a separate data quality check (and an alert)\
          \ for each monthly monitoring."
        $ref: "#/definitions/ColumnTextMatchDateFormatPercentCheckSpec"
  ColumnDatetimeMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_date_values_in_future_percent:
        description: "Detects dates in the future in date, datetime and timestamp\
          \ columns. Measures a percentage of dates in the future. Raises a data quality\
          \ issue when too many future dates are found. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnDateValuesInFuturePercentCheckSpec"
      monthly_partition_date_in_range_percent:
        description: "Verifies that the dates in date, datetime, or timestamp columns\
          \ are within a reasonable range of dates. The default configuration detects\
          \ fake dates such as 1900-01-01 and 2099-12-31. Measures the percentage\
          \ of valid dates and raises a data quality issue when too many dates are\
          \ found. Stores a separate data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnDateInRangePercentCheckSpec"
      monthly_partition_text_match_date_format_percent:
        description: "Verifies that the values in text columns match one of the predefined\
          \ date formats, such as an ISO 8601 date. Measures the percentage of valid\
          \ date strings and raises a data quality issue when too many invalid date\
          \ strings are found. Stores a separate data quality check result for each\
          \ monthly partition."
        $ref: "#/definitions/ColumnTextMatchDateFormatPercentCheckSpec"
  ColumnDatetimeProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_date_values_in_future_percent:
        description: "Detects dates in the future in date, datetime and timestamp\
          \ columns. Measures a percentage of dates in the future. Raises a data quality\
          \ issue when too many future dates are found."
        $ref: "#/definitions/ColumnDateValuesInFuturePercentCheckSpec"
      profile_date_in_range_percent:
        description: "Verifies that the dates in date, datetime, or timestamp columns\
          \ are within a reasonable range of dates. The default configuration detects\
          \ fake dates such as 1900-01-01 and 2099-12-31. Measures the percentage\
          \ of valid dates and raises a data quality issue when too many dates are\
          \ found."
        $ref: "#/definitions/ColumnDateInRangePercentCheckSpec"
      profile_text_match_date_format_percent:
        description: "Verifies that the values in text columns match one of the predefined\
          \ date formats, such as an ISO 8601 date. Measures the percentage of valid\
          \ date strings and raises a data quality issue when too many invalid date\
          \ strings are found."
        $ref: "#/definitions/ColumnTextMatchDateFormatPercentCheckSpec"
  ColumnDefaultChecksPatternSpec:
    type: "object"
    properties:
      priority:
        type: "integer"
        format: "int32"
        description: "The priority of the pattern. Patterns with lower values are\
          \ applied before patterns with higher priority values."
      disabled:
        type: "boolean"
        description: "Disables this data quality check configuration. The checks will\
          \ not be activated."
      description:
        type: "string"
        description: "The description (documentation) of this data quality check configuration."
      target:
        description: "The target column filter that are filtering the column, table\
          \ and connection on which the default checks are applied."
        $ref: "#/definitions/TargetColumnPatternSpec"
      profiling_checks:
        description: "Configuration of data quality profiling checks that are enabled.\
          \ Pick a check from a category, apply the parameters and rules to enable\
          \ it."
        $ref: "#/definitions/ColumnProfilingCheckCategoriesSpec"
      monitoring_checks:
        description: "Configuration of table level monitoring checks. Monitoring checks\
          \ are data quality checks that are evaluated for each period of time (daily,\
          \ weekly, monthly, etc.). A monitoring check stores only the most recent\
          \ data quality check result for each period of time."
        $ref: "#/definitions/ColumnMonitoringCheckCategoriesSpec"
      partitioned_checks:
        description: "Configuration of table level date/time partitioned checks. Partitioned\
          \ data quality checks are evaluated for each partition separately, raising\
          \ separate alerts at a partition level. The table does not need to be physically\
          \ partitioned by date, it is possible to run data quality checks for each\
          \ day or month of data separately."
        $ref: "#/definitions/ColumnPartitionedCheckCategoriesSpec"
  ColumnDetectedDatatypeInTextCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "The sensor parameters for a sensor that returns a value that\
          \ identifies the detected type of column data: 1 - integers, 2 - floats,\
          \ 3 - dates, 4 - datetimes, 5 - timestamps, 6 - booleans, 7 - strings, 8\
          \ - mixed data types."
        $ref: "#/definitions/ColumnDatatypeStringDatatypeDetectSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check, detects that the data type\
          \ of values stored in a column matches an expected data type code (1..8)."
        $ref: "#/definitions/DetectedDatatypeEqualsRuleParametersSpec"
      error:
        description: "Default alerting thresholdthat raises a data quality issue at\
          \ an error severity level, detects that the data type of values stored in\
          \ a column matches an expected data type code (1..8)."
        $ref: "#/definitions/DetectedDatatypeEqualsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem, detects that the data type of\
          \ values stored in a column matches an expected data type code (1..8)."
        $ref: "#/definitions/DetectedDatatypeEqualsRuleParametersSpec"
  ColumnDistinctCountAnomalyDifferencingCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnDistinctCountAnomalyStationaryPartitionCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnDistinctCountChange1DayCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent1DayRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent1DayRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent1DayRule50ParametersSpec"
  ColumnDistinctCountChange30DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent30DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent30DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent30DaysRule50ParametersSpec"
  ColumnDistinctCountChange7DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent7DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent7DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent7DaysRule50ParametersSpec"
  ColumnDistinctCountChangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercentRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercentRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercentRule50ParametersSpec"
  ColumnDistinctCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/CountBetweenRuleParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ nulls in a column that raises a data quality error (alert)."
        $ref: "#/definitions/CountBetweenRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/CountBetweenRuleParametersSpec"
  ColumnDistinctPercentAnomalyStationaryCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnDistinctPercentChange1DayCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent1DayRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent1DayRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent1DayRule50ParametersSpec"
  ColumnDistinctPercentChange30DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent30DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent30DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent30DaysRule50ParametersSpec"
  ColumnDistinctPercentChange7DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent7DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent7DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent7DaysRule50ParametersSpec"
  ColumnDistinctPercentChangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercentRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercentRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercentRule50ParametersSpec"
  ColumnDistinctPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum percentage of rows\
          \ with unique value in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnDuplicateCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDuplicateCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ nulls in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnDuplicatePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnUniquenessDuplicatePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ nulls in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnExpectedNumbersInUseCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters that specify a list of expected\
          \ numeric values that must be present in the column."
        $ref: "#/definitions/ColumnNumericExpectedNumbersInUseCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning when too\
          \ many expected values were not found in the column."
        $ref: "#/definitions/MaxMissingRule0WarningParametersSpec"
      error:
        description: "Alerting threshold that raises a data quality error when too\
          \ many expected values were not found in the column."
        $ref: "#/definitions/MaxMissingRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a data quality fatal issue when\
          \ too many expected values were not found in the column."
        $ref: "#/definitions/MaxMissingRule2ParametersSpec"
  ColumnExpectedTextValuesInUseCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters that specify a list of expected\
          \ text values that must be present in the column."
        $ref: "#/definitions/ColumnStringsExpectedTextValuesInUseCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning when too\
          \ many expected values were not found in the column."
        $ref: "#/definitions/MaxMissingRule0WarningParametersSpec"
      error:
        description: "Alerting threshold that raises a data quality error when too\
          \ many expected values were not found in the column."
        $ref: "#/definitions/MaxMissingRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a data quality fatal issue when\
          \ too many expected values were not found in the column."
        $ref: "#/definitions/MaxMissingRule2ParametersSpec"
  ColumnExpectedTextsInTopValuesCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters that specify a list of expected\
          \ most popular text values that should be found in the column. The second\
          \ parameter is 'top', which is the limit of the most popular column values\
          \ to find in the tested column."
        $ref: "#/definitions/ColumnStringsExpectedTextsInTopValuesCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning when too\
          \ many expected values were not found among the TOP most popular values\
          \ in the tested column."
        $ref: "#/definitions/MaxMissingRule0WarningParametersSpec"
      error:
        description: "Alerting threshold that raises a data quality error when too\
          \ many expected values were not found among the TOP most popular values\
          \ in the tested column."
        $ref: "#/definitions/MaxMissingRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a data quality fatal issue when\
          \ too many expected values were not found among the TOP most popular values\
          \ in the tested column."
        $ref: "#/definitions/MaxMissingRule2ParametersSpec"
  ColumnFalsePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnBoolFalsePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenPercentRuleParametersSpec"
      error:
        description: "Default alerting threshold for a set percentage of false value\
          \ in a column that raises a data quality error (alert)."
        $ref: "#/definitions/BetweenPercentRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenPercentRuleParametersSpec"
  ColumnIntegerInRangePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericIntegerInRangePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set number of values from range\
          \ in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnIntegrityDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_lookup_key_not_found:
        description: "Detects invalid values that are not present in a dictionary\
          \ table using an outer join query. Counts the number of invalid keys. Stores\
          \ the most recent captured value for each day when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnIntegrityLookupKeyNotFoundCountCheckSpec"
      daily_lookup_key_found_percent:
        description: "Measures the percentage of valid values that are present in\
          \ a dictionary table. Joins this table to a dictionary table using an outer\
          \ join. Stores the most recent captured value for each day when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnIntegrityForeignKeyMatchPercentCheckSpec"
  ColumnIntegrityDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_lookup_key_not_found:
        description: "Detects invalid values that are not present in a dictionary\
          \ table using an outer join query. Counts the number of invalid keys. Stores\
          \ a separate data quality check result for each daily partition."
        $ref: "#/definitions/ColumnIntegrityLookupKeyNotFoundCountCheckSpec"
      daily_partition_lookup_key_found_percent:
        description: "Measures the percentage of valid values that are present in\
          \ a dictionary table. Joins this table to a dictionary table using an outer\
          \ join. Stores a separate data quality check result for each daily partition."
        $ref: "#/definitions/ColumnIntegrityForeignKeyMatchPercentCheckSpec"
  ColumnIntegrityForeignKeyMatchPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters with the name of the foreign table\
          \ and the column where the lookup is performed by running an outer join\
          \ SQL query"
        $ref: "#/definitions/ColumnIntegrityForeignKeyMatchPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum percentage of rows\
          \ with values matching values in another table column that raises a data\
          \ quality error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnIntegrityForeignKeyMatchPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      foreign_table:
        type: "string"
        description: "This field can be used to define the name of the table to be\
          \ compared to. In order to define the name of the table, user should write\
          \ correct name as a String."
      foreign_column:
        type: "string"
        description: "This field can be used to define the name of the column to be\
          \ compared to. In order to define the name of the column, user should write\
          \ correct name as a String."
  ColumnIntegrityForeignKeyNotMatchCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      foreign_table:
        type: "string"
        description: "This field can be used to define the name of the table to be\
          \ compared to. In order to define the name of the table, user should write\
          \ correct name as a String."
      foreign_column:
        type: "string"
        description: "This field can be used to define the name of the column to be\
          \ compared to. In order to define the name of the column, user should write\
          \ correct name as a String."
  ColumnIntegrityLookupKeyNotFoundCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters with the name of the foreign table\
          \ and the column where the lookup is performed by running an outer join\
          \ SQL query"
        $ref: "#/definitions/ColumnIntegrityForeignKeyNotMatchCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ values not matching values in another table column that raises a data\
          \ quality error (alert)."
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnIntegrityMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_lookup_key_not_found:
        description: "Detects invalid values that are not present in a dictionary\
          \ table using an outer join query. Counts the number of invalid keys. Stores\
          \ the most recent check result for each month when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnIntegrityLookupKeyNotFoundCountCheckSpec"
      monthly_lookup_key_found_percent:
        description: "Measures the percentage of valid values that are present in\
          \ a dictionary table. Joins this table to a dictionary table using an outer\
          \ join. Stores the most recent check result for each month when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnIntegrityForeignKeyMatchPercentCheckSpec"
  ColumnIntegrityMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_lookup_key_not_found:
        description: "Detects invalid values that are not present in a dictionary\
          \ table using an outer join query. Counts the number of invalid keys. Stores\
          \ a separate data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnIntegrityLookupKeyNotFoundCountCheckSpec"
      monthly_partition_lookup_key_found_percent:
        description: "Measures the percentage of valid values that are present in\
          \ a dictionary table. Joins this table to a dictionary table using an outer\
          \ join. Stores a separate data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnIntegrityForeignKeyMatchPercentCheckSpec"
  ColumnIntegrityProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_lookup_key_not_found:
        description: "Detects invalid values that are not present in a dictionary\
          \ table using an outer join query. Counts the number of invalid keys."
        $ref: "#/definitions/ColumnIntegrityLookupKeyNotFoundCountCheckSpec"
      profile_lookup_key_found_percent:
        description: "Measures the percentage of valid values that are present in\
          \ a dictionary table. Joins this table to a dictionary table using an outer\
          \ join."
        $ref: "#/definitions/ColumnIntegrityForeignKeyMatchPercentCheckSpec"
  ColumnInvalidEmailFormatFoundCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPatternsInvalidEmailFormatCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ invalid emails in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnInvalidEmailFormatPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPatternsInvalidEmailFormatPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ empty strings in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnInvalidIp4AddressFormatFoundCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPatternsInvalidIp4AddressFormatCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ invalid IP4 address in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnInvalidIp6AddressFormatFoundCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPatternsInvalidIp6AddressFormatCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ invalid IP6 address in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnInvalidLatitudeCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericInvalidLatitudeCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with invalid\
          \ latitude value in a column that raises a data quality alert"
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnInvalidLongitudeCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericInvalidLongitudeCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with invalid\
          \ longitude value in a column that raises a data quality alert"
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnInvalidUuidFormatFoundCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPatternsInvalidUuidFormatCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ invalid uuid in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnListModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      table:
        description: "Physical table name including the schema and table names."
        $ref: "#/definitions/PhysicalTableName"
      column_name:
        type: "string"
        description: "Column names."
      labels:
        type: "array"
        description: "List of labels applied to the table."
        items:
          type: "string"
      sql_expression:
        type: "string"
        description: "SQL expression."
      column_hash:
        type: "integer"
        format: "int64"
        description: "Column hash that identifies the column using a unique hash code."
      disabled:
        type: "boolean"
        description: "Disables all data quality checks on the column. Data quality\
          \ checks will not be executed."
      has_any_configured_checks:
        type: "boolean"
        description: "True when the column has any checks configured."
      has_any_configured_profiling_checks:
        type: "boolean"
        description: "True when the column has any profiling checks configured."
      has_any_configured_monitoring_checks:
        type: "boolean"
        description: "True when the column has any monitoring checks configured."
      has_any_configured_partition_checks:
        type: "boolean"
        description: "True when the column has any partition checks configured."
      type_snapshot:
        description: "Column data type that was retrieved when the table metadata\
          \ was imported."
        $ref: "#/definitions/ColumnTypeSnapshotSpec"
      data_quality_status:
        description: "The current data quality status for the column, grouped by data\
          \ quality dimensions. DQOps may return a null value when the results were\
          \ not yet loaded into the cache. In that case, the client should wait a\
          \ few seconds and retry a call to get the most recent data quality status\
          \ of the column."
        $ref: "#/definitions/ColumnCurrentDataQualityStatusModel"
      run_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run all checks within this column."
        $ref: "#/definitions/CheckSearchFilters"
      run_profiling_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run profiling checks within this\
          \ column."
        $ref: "#/definitions/CheckSearchFilters"
      run_monitoring_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run monitoring checks within this\
          \ column."
        $ref: "#/definitions/CheckSearchFilters"
      run_partition_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run partition partitioned checks\
          \ within this column."
        $ref: "#/definitions/CheckSearchFilters"
      collect_statistics_job_template:
        description: "Configured parameters for the \"collect statistics\" job that\
          \ should be pushed to the job queue in order to run all statistics collector\
          \ within this column."
        $ref: "#/definitions/StatisticsCollectorSearchFilters"
      data_clean_job_template:
        description: "Configured parameters for the \"data clean\" job that after\
          \ being supplied with a time range should be pushed to the job queue in\
          \ order to remove stored results connected with this column."
        $ref: "#/definitions/DeleteStoredDataQueueJobParameters"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete the column."
      can_collect_statistics:
        type: "boolean"
        description: "Boolean flag that decides if the current user can collect statistics."
      can_run_checks:
        type: "boolean"
        description: "Boolean flag that decides if the current user can run checks."
      can_delete_data:
        type: "boolean"
        description: "Boolean flag that decides if the current user can delete data\
          \ (results)."
    description: "Column list model that returns the basic fields from a column specification,\
      \ excluding nested nodes like a list of activated checks."
  ColumnMaxAnomalyDifferencingCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMaxSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnMaxAnomalyStationaryCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMaxSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnMaxInRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMaxSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a maximum values in range in\
          \ a column that raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnMeanAnomalyStationaryCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMeanSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnMeanChange1DayCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMeanSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent1DayRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent1DayRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent1DayRule50ParametersSpec"
  ColumnMeanChange30DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMeanSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent30DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent30DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent30DaysRule50ParametersSpec"
  ColumnMeanChange7DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMeanSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent7DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent7DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent7DaysRule50ParametersSpec"
  ColumnMeanChangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMeanSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercentRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercentRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercentRule50ParametersSpec"
  ColumnMeanInRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMeanSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a mean in range in a column that\
          \ raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnMedianAnomalyStationaryCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMedianSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnMedianChange1DayCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMedianSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent1DayRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent1DayRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent1DayRule50ParametersSpec"
  ColumnMedianChange30DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMedianSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent30DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent30DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent30DaysRule50ParametersSpec"
  ColumnMedianChange7DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMedianSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent7DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent7DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent7DaysRule50ParametersSpec"
  ColumnMedianChangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMedianSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercentRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercentRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercentRule50ParametersSpec"
  ColumnMedianInRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMedianSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a median in a column that raises\
          \ a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnMinAnomalyDifferencingCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMinSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnMinAnomalyStationaryCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMinSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnMinInRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericMinSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a minimum values in range in\
          \ a column that raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      table:
        description: "Physical table name including the schema and table names."
        $ref: "#/definitions/PhysicalTableName"
      column_name:
        type: "string"
        description: "Column name."
      column_hash:
        type: "integer"
        format: "int64"
        description: "Column hash that identifies the column using a unique hash code."
      spec:
        description: "Full column specification."
        $ref: "#/definitions/ColumnSpec"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Full column model"
  ColumnMonitoringCheckCategoriesSpec:
    type: "object"
    properties:
      daily:
        description: "Configuration of daily monitoring evaluated at a column level."
        $ref: "#/definitions/ColumnDailyMonitoringCheckCategoriesSpec"
      monthly:
        description: "Configuration of monthly monitoring evaluated at a column level."
        $ref: "#/definitions/ColumnMonthlyMonitoringCheckCategoriesSpec"
  ColumnMonthlyMonitoringCheckCategoriesSpec:
    type: "object"
    properties:
      custom:
        type: "object"
        description: "Dictionary of custom checks. The keys are check names within\
          \ this category."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      nulls:
        description: "Monthly monitoring checks of nulls in the column"
        $ref: "#/definitions/ColumnNullsMonthlyMonitoringChecksSpec"
      uniqueness:
        description: "Monthly monitoring checks of uniqueness in the column"
        $ref: "#/definitions/ColumnUniquenessMonthlyMonitoringChecksSpec"
      accepted_values:
        description: "Configuration of accepted values checks on a column level"
        $ref: "#/definitions/ColumnAcceptedValuesMonthlyMonitoringChecksSpec"
      text:
        description: "Monthly monitoring checks of text values in the column"
        $ref: "#/definitions/ColumnTextMonthlyMonitoringChecksSpec"
      whitespace:
        description: "Configuration of column level checks that detect blank and whitespace\
          \ values"
        $ref: "#/definitions/ColumnWhitespaceMonthlyMonitoringChecksSpec"
      conversions:
        description: "Configuration of conversion testing checks on a column level."
        $ref: "#/definitions/ColumnConversionsMonthlyMonitoringChecksSpec"
      patterns:
        description: "Monthly monitoring checks of pattern matching on a column level"
        $ref: "#/definitions/ColumnPatternsMonthlyMonitoringChecksSpec"
      pii:
        description: "Monthly monitoring checks of Personal Identifiable Information\
          \ (PII) in the column"
        $ref: "#/definitions/ColumnPiiMonthlyMonitoringChecksSpec"
      numeric:
        description: "Monthly monitoring checks of numeric values in the column"
        $ref: "#/definitions/ColumnNumericMonthlyMonitoringChecksSpec"
      datetime:
        description: "Monthly monitoring checks of datetime in the column"
        $ref: "#/definitions/ColumnDatetimeMonthlyMonitoringChecksSpec"
      bool:
        description: "Monthly monitoring checks of booleans in the column"
        $ref: "#/definitions/ColumnBoolMonthlyMonitoringChecksSpec"
      integrity:
        description: "Monthly monitoring checks of integrity in the column"
        $ref: "#/definitions/ColumnIntegrityMonthlyMonitoringChecksSpec"
      accuracy:
        description: "Monthly monitoring checks of accuracy in the column"
        $ref: "#/definitions/ColumnAccuracyMonthlyMonitoringChecksSpec"
      custom_sql:
        description: "Monthly monitoring checks of custom SQL checks in the column"
        $ref: "#/definitions/ColumnCustomSqlMonthlyMonitoringChecksSpec"
      datatype:
        description: "Monthly monitoring checks of datatype in the column"
        $ref: "#/definitions/ColumnDatatypeMonthlyMonitoringChecksSpec"
      schema:
        description: "Monthly monitoring column schema checks"
        $ref: "#/definitions/ColumnSchemaMonthlyMonitoringChecksSpec"
      comparisons:
        type: "object"
        description: "Dictionary of configuration of checks for table comparisons\
          \ at a column level. The key that identifies each comparison must match\
          \ the name of a data comparison that is configured on the parent table."
        additionalProperties:
          $ref: "#/definitions/ColumnComparisonMonthlyMonitoringChecksSpec"
  ColumnMonthlyPartitionedCheckCategoriesSpec:
    type: "object"
    properties:
      custom:
        type: "object"
        description: "Dictionary of custom checks. The keys are check names within\
          \ this category."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      nulls:
        description: "Monthly partitioned checks of nulls in the column"
        $ref: "#/definitions/ColumnNullsMonthlyPartitionedChecksSpec"
      uniqueness:
        description: "Monthly partitioned checks of uniqueness in the column"
        $ref: "#/definitions/ColumnUniquenessMonthlyPartitionedChecksSpec"
      accepted_values:
        description: "Configuration of accepted values checks on a column level"
        $ref: "#/definitions/ColumnAcceptedValuesMonthlyPartitionedChecksSpec"
      text:
        description: "Monthly partitioned checks of text values in the column"
        $ref: "#/definitions/ColumnTextMonthlyPartitionedChecksSpec"
      whitespace:
        description: "Configuration of column level checks that detect blank and whitespace\
          \ values"
        $ref: "#/definitions/ColumnWhitespaceMonthlyPartitionedChecksSpec"
      conversions:
        description: "Configuration of conversion testing checks on a column level."
        $ref: "#/definitions/ColumnConversionsMonthlyPartitionedChecksSpec"
      patterns:
        description: "Monthly partitioned pattern match checks on a column level"
        $ref: "#/definitions/ColumnPatternsMonthlyPartitionedChecksSpec"
      pii:
        description: "Monthly partitioned checks of Personal Identifiable Information\
          \ (PII) in the column"
        $ref: "#/definitions/ColumnPiiMonthlyPartitionedChecksSpec"
      numeric:
        description: "Monthly partitioned checks of numeric values in the column"
        $ref: "#/definitions/ColumnNumericMonthlyPartitionedChecksSpec"
      datetime:
        description: "Monthly partitioned checks of datetime in the column"
        $ref: "#/definitions/ColumnDatetimeMonthlyPartitionedChecksSpec"
      bool:
        description: "Monthly partitioned checks for booleans in the column"
        $ref: "#/definitions/ColumnBoolMonthlyPartitionedChecksSpec"
      integrity:
        description: "Monthly partitioned checks for integrity in the column"
        $ref: "#/definitions/ColumnIntegrityMonthlyPartitionedChecksSpec"
      custom_sql:
        description: "Monthly partitioned checks using custom SQL expressions evaluated\
          \ on the column"
        $ref: "#/definitions/ColumnCustomSqlMonthlyPartitionedChecksSpec"
      datatype:
        description: "Monthly partitioned checks for datatype in the column"
        $ref: "#/definitions/ColumnDatatypeMonthlyPartitionedChecksSpec"
      comparisons:
        type: "object"
        description: "Dictionary of configuration of checks for table comparisons\
          \ at a column level. The key that identifies each comparison must match\
          \ the name of a data comparison that is configured on the parent table."
        additionalProperties:
          $ref: "#/definitions/ColumnComparisonMonthlyPartitionedChecksSpec"
  ColumnNegativeCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericNegativeCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnNegativePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericNegativePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set percentage of rows with\
          \ negative value in a column that raises a data quality alert"
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnNonNegativeCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericNonNegativeCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ non-negative values in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnNonNegativePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericNonNegativePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set percentage of rows with\
          \ non-negative value in a column that raises a data quality alert"
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnNotNullsCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNullsNotNullsCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinCountRule1ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with not\
          \ null values in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MinCountRule1ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinCountRule1ParametersSpec"
  ColumnNotNullsPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNullsNotNullsPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set percentage of rows with\
          \ null values in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnNullPercentAnomalyStationaryCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNullsNullsPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnNullPercentChange1DayCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNullsNullsPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent1DayRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent1DayRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent1DayRule50ParametersSpec"
  ColumnNullPercentChange30DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNullsNullsPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent30DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent30DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent30DaysRule50ParametersSpec"
  ColumnNullPercentChange7DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNullsNullsPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent7DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent7DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent7DaysRule50ParametersSpec"
  ColumnNullPercentChangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNullsNullsPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercentRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercentRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercentRule50ParametersSpec"
  ColumnNullsCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNullsNullsCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with null\
          \ values in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnNullsDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_nulls_count:
        description: "Detects incomplete columns that contain any null values. Counts\
          \ the number of rows having a null value. Raises a data quality issue when\
          \ the count of null values is above a max_count threshold. Stores the most\
          \ recent captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNullsCountCheckSpec"
      daily_nulls_percent:
        description: "Detects incomplete columns that contain any null values. Measures\
          \ the percentage of rows having a null value. Raises a data quality issue\
          \ when the percentage of null values is above a max_percent threshold. Stores\
          \ the most recent captured value for each day when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnNullsPercentCheckSpec"
      daily_nulls_percent_anomaly:
        description: "Detects day-to-day anomalies in the percentage of null values.\
          \ Raises a data quality issue when the rate of null values increases or\
          \ decreases too much during the last 90 days."
        $ref: "#/definitions/ColumnNullPercentAnomalyStationaryCheckSpec"
      daily_not_nulls_count:
        description: "Detects empty columns that contain only null values. Counts\
          \ the number of rows that have non-null values. Raises a data quality issue\
          \ when the count of non-null values is below min_count. Stores the most\
          \ recent captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNotNullsCountCheckSpec"
      daily_not_nulls_percent:
        description: "Detects incomplete columns that contain too few non-null values.\
          \ Measures the percentage of rows that have non-null values. Raises a data\
          \ quality issue when the percentage of non-null values is below min_percentage.\
          \ Stores the most recent captured value for each day when the data quality\
          \ check was evaluated."
        $ref: "#/definitions/ColumnNotNullsPercentCheckSpec"
      daily_nulls_percent_change:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since the last readout."
        $ref: "#/definitions/ColumnNullPercentChangeCheckSpec"
      daily_nulls_percent_change_1_day:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since the last readout from yesterday."
        $ref: "#/definitions/ColumnNullPercentChange1DayCheckSpec"
      daily_nulls_percent_change_7_days:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since the last readout from the last week."
        $ref: "#/definitions/ColumnNullPercentChange7DaysCheckSpec"
      daily_nulls_percent_change_30_days:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since the last readout from the last month."
        $ref: "#/definitions/ColumnNullPercentChange30DaysCheckSpec"
  ColumnNullsDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_nulls_count:
        description: "Detects incomplete columns that contain any null values. Counts\
          \ the number of rows having a null value. Raises a data quality issue when\
          \ the count of null values is above a max_count threshold. Stores a separate\
          \ data quality check result for each daily partition."
        $ref: "#/definitions/ColumnNullsCountCheckSpec"
      daily_partition_nulls_percent:
        description: "Detects incomplete columns that contain any null values. Measures\
          \ the percentage of rows having a null value. Raises a data quality issue\
          \ when the percentage of null values is above a max_percent threshold. Stores\
          \ a separate data quality check result for each daily partition."
        $ref: "#/definitions/ColumnNullsPercentCheckSpec"
      daily_partition_nulls_percent_anomaly:
        description: "Detects day-to-day anomalies in the percentage of null values.\
          \ Raises a data quality issue when the rate of null values increases or\
          \ decreases too much during the last 90 days."
        $ref: "#/definitions/ColumnNullPercentAnomalyStationaryCheckSpec"
      daily_partition_not_nulls_count:
        description: "Detects empty columns that contain only null values. Counts\
          \ the number of rows that have non-null values. Raises a data quality issue\
          \ when the count of non-null values is below min_count. Stores a separate\
          \ data quality check result for each daily partition."
        $ref: "#/definitions/ColumnNotNullsCountCheckSpec"
      daily_partition_not_nulls_percent:
        description: "Detects incomplete columns that contain too few non-null values.\
          \ Measures the percentage of rows that have non-null values. Raises a data\
          \ quality issue when the percentage of non-null values is below min_percentage.\
          \ Stores a separate data quality check result for each daily partition."
        $ref: "#/definitions/ColumnNotNullsPercentCheckSpec"
      daily_partition_nulls_percent_change:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since last readout."
        $ref: "#/definitions/ColumnNullPercentChangeCheckSpec"
      daily_partition_nulls_percent_change_1_day:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since the last readout from yesterday."
        $ref: "#/definitions/ColumnNullPercentChange1DayCheckSpec"
      daily_partition_nulls_percent_change_7_days:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since the last readout from the last week."
        $ref: "#/definitions/ColumnNullPercentChange7DaysCheckSpec"
      daily_partition_nulls_percent_change_30_days:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since the last readout from the last month."
        $ref: "#/definitions/ColumnNullPercentChange30DaysCheckSpec"
  ColumnNullsMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_nulls_count:
        description: "Detects incomplete columns that contain any null values. Counts\
          \ the number of rows having a null value. Raises a data quality issue when\
          \ the count of null values is above a max_count threshold.. Stores the most\
          \ recent count check result for each month when the data quality check was\
          \ evaluated."
        $ref: "#/definitions/ColumnNullsCountCheckSpec"
      monthly_nulls_percent:
        description: "Detects incomplete columns that contain any null values. Measures\
          \ the percentage of rows having a null value. Raises a data quality issue\
          \ when the percentage of null values is above a max_percent threshold. Stores\
          \ the most recent check result for each month when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnNullsPercentCheckSpec"
      monthly_not_nulls_count:
        description: "Detects empty columns that contain only null values. Counts\
          \ the number of rows that have non-null values. Raises a data quality issue\
          \ when the count of non-null values is below min_count. Stores the most\
          \ recent check result for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNotNullsCountCheckSpec"
      monthly_not_nulls_percent:
        description: "Detects incomplete columns that contain too few non-null values.\
          \ Measures the percentage of rows that have non-null values. Raises a data\
          \ quality issue when the percentage of non-null values is below min_percentage.\
          \ Stores the most recent check result for each month when the data quality\
          \ check was evaluated."
        $ref: "#/definitions/ColumnNotNullsPercentCheckSpec"
  ColumnNullsMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_nulls_count:
        description: "Detects incomplete columns that contain any null values. Counts\
          \ the number of rows having a null value. Raises a data quality issue when\
          \ the count of null values is above a max_count threshold. Stores a separate\
          \ data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNullsCountCheckSpec"
      monthly_partition_nulls_percent:
        description: "Detects incomplete columns that contain any null values. Measures\
          \ the percentage of rows having a null value. Raises a data quality issue\
          \ when the percentage of null values is above a max_percent threshold. Stores\
          \ a separate data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNullsPercentCheckSpec"
      monthly_partition_not_nulls_count:
        description: "Detects empty columns that contain only null values. Counts\
          \ the number of rows that have non-null values. Raises a data quality issue\
          \ when the count of non-null values is below min_count. Stores a separate\
          \ data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNotNullsCountCheckSpec"
      monthly_partition_not_nulls_percent:
        description: "Detects incomplete columns that contain too few non-null values.\
          \ Measures the percentage of rows that have non-null values. Raises a data\
          \ quality issue when the percentage of non-null values is below min_percentage.\
          \ Stores a separate data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNotNullsPercentCheckSpec"
  ColumnNullsNotNullsCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNullsNotNullsCountStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnNullsNotNullsCountSensorParametersSpec"
  ColumnNullsNotNullsPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNullsNotNullsPercentStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnNullsNotNullsPercentSensorParametersSpec"
  ColumnNullsNullsCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNullsNullsCountStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnNullsNullsCountSensorParametersSpec"
  ColumnNullsNullsPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNullsNullsPercentStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnNullsNullsPercentSensorParametersSpec"
  ColumnNullsPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNullsNullsPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set percentage of rows with\
          \ null values in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnNullsProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_nulls_count:
        description: "Detects incomplete columns that contain any null values. Counts\
          \ the number of rows having a null value. Raises a data quality issue when\
          \ the count of null values is above a max_count threshold."
        $ref: "#/definitions/ColumnNullsCountCheckSpec"
      profile_nulls_percent:
        description: "Detects incomplete columns that contain any null values. Measures\
          \ the percentage of rows having a null value. Raises a data quality issue\
          \ when the percentage of null values is above a max_percent threshold."
        $ref: "#/definitions/ColumnNullsPercentCheckSpec"
      profile_nulls_percent_anomaly:
        description: "Detects day-to-day anomalies in the percentage of null values.\
          \ Raises a data quality issue when the rate of null values increases or\
          \ decreases too much during the last 90 days."
        $ref: "#/definitions/ColumnNullPercentAnomalyStationaryCheckSpec"
      profile_not_nulls_count:
        description: "Detects empty columns that contain only null values. Counts\
          \ the number of rows that have non-null values. Raises a data quality issue\
          \ when the count of non-null values is below min_count."
        $ref: "#/definitions/ColumnNotNullsCountCheckSpec"
      profile_not_nulls_percent:
        description: "Detects incomplete columns that contain too few non-null values.\
          \ Measures the percentage of rows that have non-null values. Raises a data\
          \ quality issue when the percentage of non-null values is below min_percentage."
        $ref: "#/definitions/ColumnNotNullsPercentCheckSpec"
      profile_nulls_percent_change:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since last readout."
        $ref: "#/definitions/ColumnNullPercentChangeCheckSpec"
      profile_nulls_percent_change_1_day:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since last readout from yesterday."
        $ref: "#/definitions/ColumnNullPercentChange1DayCheckSpec"
      profile_nulls_percent_change_7_days:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since last readout from last week."
        $ref: "#/definitions/ColumnNullPercentChange7DaysCheckSpec"
      profile_nulls_percent_change_30_days:
        description: "Verifies that the null percent value in a column changed in\
          \ a fixed rate since last readout from last month."
        $ref: "#/definitions/ColumnNullPercentChange30DaysCheckSpec"
  ColumnNullsStatisticsCollectorsSpec:
    type: "object"
    properties:
      nulls_count:
        description: "Configuration of the profiler that counts null column values."
        $ref: "#/definitions/ColumnNullsNullsCountStatisticsCollectorSpec"
      nulls_percent:
        description: "Configuration of the profiler that measures the percentage of\
          \ null values."
        $ref: "#/definitions/ColumnNullsNullsPercentStatisticsCollectorSpec"
      not_nulls_count:
        description: "Configuration of the profiler that counts not null column values."
        $ref: "#/definitions/ColumnNullsNotNullsCountStatisticsCollectorSpec"
      not_nulls_percent:
        description: "Configuration of the profiler that measures the percentage of\
          \ not null values."
        $ref: "#/definitions/ColumnNullsNotNullsPercentStatisticsCollectorSpec"
  ColumnNumberAboveMaxValueCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericNumberAboveMaxValueCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ values with a value above the indicated by the user value in a column\
          \ that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnNumberAboveMaxValuePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericNumberAboveMaxValuePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ values with a value above the indicated by the user value in a column\
          \ that raises a data quality error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnNumberBelowMinValueCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericNumberBelowMinValueCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ values with a value below the indicated by the user value in a column\
          \ that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnNumberBelowMinValuePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericNumberBelowMinValuePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ values with a value below the indicated by the user value in a column\
          \ that raises a data quality error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnNumberFoundInSetPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters that specify a list of expected\
          \ values that are compared to the values in the tested numeric column."
        $ref: "#/definitions/ColumnNumericNumberFoundInSetPercentSensorParametersSpec"
      warning:
        description: "Default alerting threshold for a percentage of rows with valid\
          \ values in a column (from a set of expected values). Raises a data quality\
          \ issue with at a warning severity level when the percentage of valid rows\
          \ is below the minimum percentage threshold."
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a percentage of rows with valid\
          \ values in a column (from a set of expected values). Raises a data quality\
          \ issue with at an error severity level when the percentage of valid rows\
          \ is below the minimum percentage threshold"
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Default alerting threshold for a percentage of rows with valid\
          \ values in a column (from a set of expected values). Raises a data quality\
          \ issue with at a fatal severity level when the percentage of valid rows\
          \ is below the minimum percentage threshold"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnNumberInRangePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericNumberInRangePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for set percentage of values from\
          \ the range in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnNumericDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_number_below_min_value:
        description: "The check counts the number of values in the column that are\
          \ below the value defined by the user as a parameter. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberBelowMinValueCheckSpec"
      daily_number_above_max_value:
        description: "The check counts the number of values in the column that are\
          \ above the value defined by the user as a parameter. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberAboveMaxValueCheckSpec"
      daily_negative_values:
        description: "Verifies that the number of negative values in a column does\
          \ not exceed the maximum accepted count. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNegativeCountCheckSpec"
      daily_negative_values_percent:
        description: "Verifies that the percentage of negative values in a column\
          \ does not exceed the maximum accepted percentage. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNegativePercentCheckSpec"
      daily_number_below_min_value_percent:
        description: "The check counts the percentage of values in the column that\
          \ are below the value defined by the user as a parameter. Stores the most\
          \ recent captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberBelowMinValuePercentCheckSpec"
      daily_number_above_max_value_percent:
        description: "The check counts the percentage of values in the column that\
          \ are above the value defined by the user as a parameter. Stores the most\
          \ recent captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberAboveMaxValuePercentCheckSpec"
      daily_number_in_range_percent:
        description: "Verifies that the percentage of values from range in a column\
          \ does not exceed the minimum accepted percentage. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberInRangePercentCheckSpec"
      daily_integer_in_range_percent:
        description: "Verifies that the percentage of values from range in a column\
          \ does not exceed the minimum accepted percentage. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnIntegerInRangePercentCheckSpec"
      daily_min_in_range:
        description: "Verifies that the minimum value in a column is not outside the\
          \ expected range. Stores the most recent captured value for each day when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnMinInRangeCheckSpec"
      daily_max_in_range:
        description: "Verifies that the maximum value in a column is not outside the\
          \ expected range. Stores the most recent captured value for each day when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnMaxInRangeCheckSpec"
      daily_sum_in_range:
        description: "Verifies that the sum of all values in a column is not outside\
          \ the expected range. Stores the most recent captured value for each day\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnSumInRangeCheckSpec"
      daily_mean_in_range:
        description: "Verifies that the average (mean) of all values in a column is\
          \ not outside the expected range. Stores the most recent captured value\
          \ for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnMeanInRangeCheckSpec"
      daily_median_in_range:
        description: "Verifies that the median of all values in a column is not outside\
          \ the expected range. Stores the most recent value for each month when the\
          \ data quality check was evaluated."
        $ref: "#/definitions/ColumnMedianInRangeCheckSpec"
      daily_percentile_in_range:
        description: "Verifies that the percentile of all values in a column is not\
          \ outside the expected range. Stores the most recent captured value for\
          \ each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPercentileInRangeCheckSpec"
      daily_percentile_10_in_range:
        description: "Verifies that the percentile 10 of all values in a column is\
          \ not outside the expected range. Stores the most recent captured value\
          \ for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPercentile10InRangeCheckSpec"
      daily_percentile_25_in_range:
        description: "Verifies that the percentile 25 of all values in a column is\
          \ not outside the expected range. Stores the most recent captured value\
          \ for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPercentile25InRangeCheckSpec"
      daily_percentile_75_in_range:
        description: "Verifies that the percentile 75 of all values in a column is\
          \ not outside the expected range. Stores the most recent captured value\
          \ for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPercentile75InRangeCheckSpec"
      daily_percentile_90_in_range:
        description: "Verifies that the percentile 90 of all values in a column is\
          \ not outside the expected range. Stores the most recent captured value\
          \ for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPercentile90InRangeCheckSpec"
      daily_sample_stddev_in_range:
        description: "Verifies that the sample standard deviation of all values in\
          \ a column is not outside the expected range. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnSampleStddevInRangeCheckSpec"
      daily_population_stddev_in_range:
        description: "Verifies that the population standard deviation of all values\
          \ in a column is not outside the expected range. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPopulationStddevInRangeCheckSpec"
      daily_sample_variance_in_range:
        description: "Verifies that the sample variance of all values in a column\
          \ is not outside the expected range. Stores the most recent captured value\
          \ for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnSampleVarianceInRangeCheckSpec"
      daily_population_variance_in_range:
        description: "Verifies that the population variance of all values in a column\
          \ is not outside the expected range. Stores the most recent captured value\
          \ for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPopulationVarianceInRangeCheckSpec"
      daily_invalid_latitude:
        description: "Verifies that the number of invalid latitude values in a column\
          \ does not exceed the maximum accepted count. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnInvalidLatitudeCountCheckSpec"
      daily_valid_latitude_percent:
        description: "Verifies that the percentage of valid latitude values in a column\
          \ does not fall below the minimum accepted percentage. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnValidLatitudePercentCheckSpec"
      daily_invalid_longitude:
        description: "Verifies that the number of invalid longitude values in a column\
          \ does not exceed the maximum accepted count. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnInvalidLongitudeCountCheckSpec"
      daily_valid_longitude_percent:
        description: "Verifies that the percentage of valid longitude values in a\
          \ column does not fall below the minimum accepted percentage. Stores the\
          \ most recent captured value for each day when the data quality check was\
          \ evaluated."
        $ref: "#/definitions/ColumnValidLongitudePercentCheckSpec"
      daily_non_negative_values:
        description: "Verifies that the number of non-negative values in a column\
          \ does not exceed the maximum accepted count. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNonNegativeCountCheckSpec"
      daily_non_negative_values_percent:
        description: "Verifies that the percentage of non-negative values in a column\
          \ does not exceed the maximum accepted percentage. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNonNegativePercentCheckSpec"
  ColumnNumericDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_number_below_min_value:
        description: "The check counts the number of values in the column that are\
          \ below the value defined by the user as a parameter. Stores a separate\
          \ data quality check result for each daily partition."
        $ref: "#/definitions/ColumnNumberBelowMinValueCheckSpec"
      daily_partition_number_above_max_value:
        description: "The check counts the number of values in the column that are\
          \ above the value defined by the user as a parameter. Stores a separate\
          \ data quality check result for each daily partition."
        $ref: "#/definitions/ColumnNumberAboveMaxValueCheckSpec"
      daily_partition_negative_values:
        description: "Verifies that the number of negative values in a column does\
          \ not exceed the maximum accepted count. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnNegativeCountCheckSpec"
      daily_partition_negative_values_percent:
        description: "Verifies that the percentage of negative values in a column\
          \ does not exceed the maximum accepted percentage. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/ColumnNegativePercentCheckSpec"
      daily_partition_number_below_min_value_percent:
        description: "The check counts the percentage of values in the column that\
          \ are below the value defined by the user as a parameter. Stores a separate\
          \ data quality check result for each daily partition."
        $ref: "#/definitions/ColumnNumberBelowMinValuePercentCheckSpec"
      daily_partition_number_above_max_value_percent:
        description: "The check counts the percentage of values in the column that\
          \ are above the value defined by the user as a parameter. Stores a separate\
          \ data quality check result for each daily partition."
        $ref: "#/definitions/ColumnNumberAboveMaxValuePercentCheckSpec"
      daily_partition_number_in_range_percent:
        description: "Verifies that the percentage of values from range in a column\
          \ does not exceed the minimum accepted percentage. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/ColumnNumberInRangePercentCheckSpec"
      daily_partition_integer_in_range_percent:
        description: "Verifies that the percentage of values from range in a column\
          \ does not exceed the minimum accepted percentage. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/ColumnIntegerInRangePercentCheckSpec"
      daily_partition_min_in_range:
        description: "Verifies that the minimum value in a column is not outside the\
          \ expected range. Stores a separate data quality check result for each daily\
          \ partition."
        $ref: "#/definitions/ColumnMinInRangeCheckSpec"
      daily_partition_max_in_range:
        description: "Verifies that the maximum value in a column is not outside the\
          \ expected range. Stores a separate data quality check result for each daily\
          \ partition."
        $ref: "#/definitions/ColumnMaxInRangeCheckSpec"
      daily_partition_sum_in_range:
        description: "Verifies that the sum of all values in a column is not outside\
          \ the expected range. Stores a separate data quality check result for each\
          \ daily partition."
        $ref: "#/definitions/ColumnSumInRangeCheckSpec"
      daily_partition_mean_in_range:
        description: "Verifies that the average (mean) of all values in a column is\
          \ not outside the expected range. Stores a separate data quality check result\
          \ for each daily partition."
        $ref: "#/definitions/ColumnMeanInRangeCheckSpec"
      daily_partition_median_in_range:
        description: "Verifies that the median of all values in a column is not outside\
          \ the expected range. Stores a separate data quality check result for each\
          \ daily partition."
        $ref: "#/definitions/ColumnMedianInRangeCheckSpec"
      daily_partition_percentile_in_range:
        description: "Verifies that the percentile of all values in a column is not\
          \ outside the expected range. Stores a separate data quality check result\
          \ for each daily partition."
        $ref: "#/definitions/ColumnPercentileInRangeCheckSpec"
      daily_partition_percentile_10_in_range:
        description: "Verifies that the percentile 10 of all values in a column is\
          \ not outside the expected range. Stores a separate data quality check result\
          \ for each daily partition."
        $ref: "#/definitions/ColumnPercentile10InRangeCheckSpec"
      daily_partition_percentile_25_in_range:
        description: "Verifies that the percentile 25 of all values in a column is\
          \ not outside the expected range. Stores a separate data quality check result\
          \ for each daily partition."
        $ref: "#/definitions/ColumnPercentile25InRangeCheckSpec"
      daily_partition_percentile_75_in_range:
        description: "Verifies that the percentile 75 of all values in a column is\
          \ not outside the expected range. Stores a separate data quality check result\
          \ for each daily partition."
        $ref: "#/definitions/ColumnPercentile75InRangeCheckSpec"
      daily_partition_percentile_90_in_range:
        description: "Verifies that the percentile 90 of all values in a column is\
          \ not outside the expected range. Stores a separate data quality check result\
          \ for each daily partition."
        $ref: "#/definitions/ColumnPercentile90InRangeCheckSpec"
      daily_partition_sample_stddev_in_range:
        description: "Verifies that the sample standard deviation of all values in\
          \ a column is not outside the expected range. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnSampleStddevInRangeCheckSpec"
      daily_partition_population_stddev_in_range:
        description: "Verifies that the population standard deviation of all values\
          \ in a column is not outside the expected range. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/ColumnPopulationStddevInRangeCheckSpec"
      daily_partition_sample_variance_in_range:
        description: "Verifies that the sample variance of all values in a column\
          \ is not outside the expected range. Stores a separate data quality check\
          \ result for each daily partition."
        $ref: "#/definitions/ColumnSampleVarianceInRangeCheckSpec"
      daily_partition_population_variance_in_range:
        description: "Verifies that the population variance of all values in a column\
          \ is not outside the expected range. Stores a separate data quality check\
          \ result for each daily partition."
        $ref: "#/definitions/ColumnPopulationVarianceInRangeCheckSpec"
      daily_partition_invalid_latitude:
        description: "Verifies that the number of invalid latitude values in a column\
          \ does not exceed the maximum accepted count. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnInvalidLatitudeCountCheckSpec"
      daily_partition_valid_latitude_percent:
        description: "Verifies that the percentage of valid latitude values in a column\
          \ does not fall below the minimum accepted percentage. Stores a separate\
          \ data quality check result for each daily partition."
        $ref: "#/definitions/ColumnValidLatitudePercentCheckSpec"
      daily_partition_invalid_longitude:
        description: "Verifies that the number of invalid longitude values in a column\
          \ does not exceed the maximum accepted count. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnInvalidLongitudeCountCheckSpec"
      daily_partition_valid_longitude_percent:
        description: "Verifies that the percentage of valid longitude values in a\
          \ column does not fall below the minimum accepted percentage. Stores a separate\
          \ data quality check result for each daily partition."
        $ref: "#/definitions/ColumnValidLongitudePercentCheckSpec"
      daily_partition_non_negative_values:
        description: "Verifies that the number of non-negative values in a column\
          \ does not exceed the maximum accepted count. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnNonNegativeCountCheckSpec"
      daily_partition_non_negative_values_percent:
        description: "Verifies that the percentage of non-negative values in a column\
          \ does not exceed the maximum accepted percentage. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/ColumnNonNegativePercentCheckSpec"
  ColumnNumericExpectedNumbersInUseCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      expected_values:
        type: "array"
        description: "List of expected numeric values that should be found in the\
          \ tested column."
        items:
          type: "integer"
          format: "int64"
  ColumnNumericIntegerInRangePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      min_value:
        type: "integer"
        format: "int64"
        description: "Minimum value range variable."
      max_value:
        type: "integer"
        format: "int64"
        description: "Maximum value range variable."
  ColumnNumericInvalidLatitudeCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericInvalidLongitudeCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericMaxSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericMeanSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericMedianSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      percentile_value:
        type: "number"
        format: "double"
        description: "Median (50th percentile), must equal 0.5"
  ColumnNumericMinSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_number_below_min_value:
        description: "The check counts the number of values in the column that are\
          \ below the value defined by the user as a parameter. Stores the most recent\
          \ value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberBelowMinValueCheckSpec"
      monthly_number_above_max_value:
        description: "The check counts the number of values in the column that are\
          \ above the value defined by the user as a parameter. Stores the most recent\
          \ value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberAboveMaxValueCheckSpec"
      monthly_negative_values:
        description: "Verifies that the number of negative values in a column does\
          \ not exceed the maximum accepted count. Stores the most recent value for\
          \ each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNegativeCountCheckSpec"
      monthly_negative_values_percent:
        description: "Verifies that the percentage of negative values in a column\
          \ does not exceed the maximum accepted percentage. Stores the most recent\
          \ value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNegativePercentCheckSpec"
      monthly_number_below_min_value_percent:
        description: "The check counts the percentage of values in the column that\
          \ are below the value defined by the user as a parameter. Stores the most\
          \ recent value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberBelowMinValuePercentCheckSpec"
      monthly_number_above_max_value_percent:
        description: "The check counts the percentage of values in the column that\
          \ are above the value defined by the user as a parameter. Stores the most\
          \ recent value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberAboveMaxValuePercentCheckSpec"
      monthly_number_in_range_percent:
        description: "Verifies that the percentage of values from range in a column\
          \ does not exceed the minimum accepted percentage. Stores the most recent\
          \ value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNumberInRangePercentCheckSpec"
      monthly_integer_in_range_percent:
        description: "Verifies that the percentage of values from range in a column\
          \ does not exceed the minimum accepted percentage. Stores the most recent\
          \ value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnIntegerInRangePercentCheckSpec"
      monthly_min_in_range:
        description: "Verifies that the minimum value in a column does not exceed\
          \ the expected range. Stores the most recent value for each month when the\
          \ data quality check was evaluated."
        $ref: "#/definitions/ColumnMinInRangeCheckSpec"
      monthly_max_in_range:
        description: "Verifies that the maximum value in a column does not exceed\
          \ the expected range. Stores the most recent value for each month when the\
          \ data quality check was evaluated."
        $ref: "#/definitions/ColumnMaxInRangeCheckSpec"
      monthly_sum_in_range:
        description: "Verifies that the sum of all values in a column does not exceed\
          \ the expected range. Stores the most recent value for each month when the\
          \ data quality check was evaluated."
        $ref: "#/definitions/ColumnSumInRangeCheckSpec"
      monthly_mean_in_range:
        description: "Verifies that the average (mean) of all values in a column does\
          \ not exceed the expected range. Stores the most recent value for each month\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnMeanInRangeCheckSpec"
      monthly_median_in_range:
        description: "Verifies that the median of all values in a column is not outside\
          \ the expected range. Stores the most recent value for each month when the\
          \ data quality check was evaluated."
        $ref: "#/definitions/ColumnMedianInRangeCheckSpec"
      monthly_percentile_in_range:
        description: "Verifies that the percentile of all values in a column is not\
          \ outside the expected range. Stores the most recent value for each month\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPercentileInRangeCheckSpec"
      monthly_percentile_10_in_range:
        description: "Verifies that the percentile 10 of all values in a column is\
          \ not outside the expected range. Stores the most recent value for each\
          \ month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPercentile10InRangeCheckSpec"
      monthly_percentile_25_in_range:
        description: "Verifies that the percentile 25 of all values in a column is\
          \ not outside the expected range. Stores the most recent value for each\
          \ month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPercentile25InRangeCheckSpec"
      monthly_percentile_75_in_range:
        description: "Verifies that the percentile 75 of all values in a column is\
          \ not outside the expected range. Stores the most recent value for each\
          \ month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPercentile75InRangeCheckSpec"
      monthly_percentile_90_in_range:
        description: "Verifies that the percentile 90 of all values in a column is\
          \ not outside the expected range. Stores the most recent value for each\
          \ month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPercentile90InRangeCheckSpec"
      monthly_sample_stddev_in_range:
        description: "Verifies that the sample standard deviation of all values in\
          \ a column is not outside the expected range. Stores the most recent value\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnSampleStddevInRangeCheckSpec"
      monthly_population_stddev_in_range:
        description: "Verifies that the population standard deviation of all values\
          \ in a column is not outside the expected range. Stores the most recent\
          \ value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPopulationStddevInRangeCheckSpec"
      monthly_sample_variance_in_range:
        description: "Verifies that the sample variance of all values in a column\
          \ is not outside the expected range. Stores the most recent value for each\
          \ month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnSampleVarianceInRangeCheckSpec"
      monthly_population_variance_in_range:
        description: "Verifies that the population variance of all values in a column\
          \ is not outside the expected range. Stores the most recent value for each\
          \ month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPopulationVarianceInRangeCheckSpec"
      monthly_invalid_latitude:
        description: "Verifies that the number of invalid latitude values in a column\
          \ does not exceed the maximum accepted count. Stores the most recent value\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnInvalidLatitudeCountCheckSpec"
      monthly_valid_latitude_percent:
        description: "Verifies that the percentage of valid latitude values in a column\
          \ does not fall below the minimum accepted percentage. Stores the most recent\
          \ value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnValidLatitudePercentCheckSpec"
      monthly_invalid_longitude:
        description: "Verifies that the number of invalid longitude values in a column\
          \ does not exceed the maximum accepted count. Stores the most recent value\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnInvalidLongitudeCountCheckSpec"
      monthly_valid_longitude_percent:
        description: "Verifies that the percentage of valid longitude values in a\
          \ column does not fall below the minimum accepted percentage. Stores the\
          \ most recent value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnValidLongitudePercentCheckSpec"
      monthly_non_negative_values:
        description: "Verifies that the number of non-negative values in a column\
          \ does not exceed the maximum accepted count. Stores the most recent value\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNonNegativeCountCheckSpec"
      monthly_non_negative_values_percent:
        description: "Verifies that the percentage of non-negative values in a column\
          \ does not exceed the maximum accepted percentage. Stores the most recent\
          \ value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnNonNegativePercentCheckSpec"
  ColumnNumericMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_number_below_min_value:
        description: "The check counts the number of values in the column that are\
          \ below the value defined by the user as a parameter. Stores a separate\
          \ data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNumberBelowMinValueCheckSpec"
      monthly_partition_number_above_max_value:
        description: "The check counts the number of values in the column that are\
          \ above the value defined by the user as a parameter. Stores a separate\
          \ data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNumberAboveMaxValueCheckSpec"
      monthly_partition_negative_values:
        description: "Verifies that the number of negative values in a column does\
          \ not exceed the maximum accepted count. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnNegativeCountCheckSpec"
      monthly_partition_negative_values_percent:
        description: "Verifies that the percentage of negative values in a column\
          \ does not exceed the maximum accepted percentage. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNegativePercentCheckSpec"
      monthly_partition_number_below_min_value_percent:
        description: "The check counts the percentage of values in the column that\
          \ are below the value defined by the user as a parameter. Stores a separate\
          \ data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNumberBelowMinValuePercentCheckSpec"
      monthly_partition_number_above_max_value_percent:
        description: "The check counts the percentage of values in the column that\
          \ are above the value defined by the user as a parameter. Stores a separate\
          \ data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNumberAboveMaxValuePercentCheckSpec"
      monthly_partition_number_in_range_percent:
        description: "Verifies that the percentage of values from range in a column\
          \ does not exceed the minimum accepted percentage. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNumberInRangePercentCheckSpec"
      monthly_partition_integer_in_range_percent:
        description: "Verifies that the percentage of values from range in a column\
          \ does not exceed the minimum accepted percentage. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/ColumnIntegerInRangePercentCheckSpec"
      monthly_partition_min_in_range:
        description: "Verifies that the minimum value in a column is not outside the\
          \ expected range. Stores a separate data quality check result for each monthly\
          \ partition."
        $ref: "#/definitions/ColumnMinInRangeCheckSpec"
      monthly_partition_max_in_range:
        description: "Verifies that the maximum value in a column is not outside the\
          \ expected range. Stores a separate data quality check result for each monthly\
          \ partition."
        $ref: "#/definitions/ColumnMaxInRangeCheckSpec"
      monthly_partition_sum_in_range:
        description: "Verifies that the sum of all values in a column is not outside\
          \ the expected range. Stores a separate data quality check result for each\
          \ monthly partition."
        $ref: "#/definitions/ColumnSumInRangeCheckSpec"
      monthly_partition_mean_in_range:
        description: "Verifies that the average (mean) of all values in a column is\
          \ not outside the expected range. Stores a separate data quality check result\
          \ for each monthly partition."
        $ref: "#/definitions/ColumnMeanInRangeCheckSpec"
      monthly_partition_median_in_range:
        description: "Verifies that the median of all values in a column is not outside\
          \ the expected range. Stores a separate data quality check result for each\
          \ monthly partition."
        $ref: "#/definitions/ColumnMedianInRangeCheckSpec"
      monthly_partition_percentile_in_range:
        description: "Verifies that the percentile of all values in a column is not\
          \ outside the expected range. Stores a separate data quality check result\
          \ for each monthly partition."
        $ref: "#/definitions/ColumnPercentileInRangeCheckSpec"
      monthly_partition_percentile_10_in_range:
        description: "Verifies that the percentile 10 of all values in a column is\
          \ not outside the expected range. Stores a separate data quality check result\
          \ for each monthly partition."
        $ref: "#/definitions/ColumnPercentile10InRangeCheckSpec"
      monthly_partition_percentile_25_in_range:
        description: "Verifies that the percentile 25 of all values in a column is\
          \ not outside the expected range. Stores a separate data quality check result\
          \ for each monthly partition."
        $ref: "#/definitions/ColumnPercentile25InRangeCheckSpec"
      monthly_partition_percentile_75_in_range:
        description: "Verifies that the percentile 75 of all values in a column is\
          \ not outside the expected range. Stores a separate data quality check result\
          \ for each monthly partition."
        $ref: "#/definitions/ColumnPercentile75InRangeCheckSpec"
      monthly_partition_percentile_90_in_range:
        description: "Verifies that the percentile 90 of all values in a column is\
          \ not outside the expected range. Stores a separate data quality check result\
          \ for each monthly partition."
        $ref: "#/definitions/ColumnPercentile90InRangeCheckSpec"
      monthly_partition_sample_stddev_in_range:
        description: "Verifies that the sample standard deviation of all values in\
          \ a column is not outside the expected range. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnSampleStddevInRangeCheckSpec"
      monthly_partition_population_stddev_in_range:
        description: "Verifies that the population standard deviation of all values\
          \ in a column is not outside the expected range. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/ColumnPopulationStddevInRangeCheckSpec"
      monthly_partition_sample_variance_in_range:
        description: "Verifies that the sample variance of all values in a column\
          \ is not outside the expected range. Stores a separate data quality check\
          \ result for each monthly partition."
        $ref: "#/definitions/ColumnSampleVarianceInRangeCheckSpec"
      monthly_partition_population_variance_in_range:
        description: "Verifies that the population variance of all values in a column\
          \ is not outside the expected range. Stores a separate data quality check\
          \ result for each monthly partition."
        $ref: "#/definitions/ColumnPopulationVarianceInRangeCheckSpec"
      monthly_partition_invalid_latitude:
        description: "Verifies that the number of invalid latitude values in a column\
          \ does not exceed the maximum accepted count. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnInvalidLatitudeCountCheckSpec"
      monthly_partition_valid_latitude_percent:
        description: "Verifies that the percentage of valid latitude values in a column\
          \ does not fall below the minimum accepted percentage. Stores a separate\
          \ data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnValidLatitudePercentCheckSpec"
      monthly_partition_invalid_longitude:
        description: "Verifies that the number of invalid longitude values in a column\
          \ does not exceed the maximum accepted count. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnInvalidLongitudeCountCheckSpec"
      monthly_partition_valid_longitude_percent:
        description: "Verifies that the percentage of valid longitude values in a\
          \ column does not fall below the minimum accepted percentage. Stores a separate\
          \ data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnValidLongitudePercentCheckSpec"
      monthly_partition_non_negative_values:
        description: "Verifies that the number of non-negative values in a column\
          \ does not exceed the maximum accepted count. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnNonNegativeCountCheckSpec"
      monthly_partition_non_negative_values_percent:
        description: "Verifies that the percentage of non-negative values in a column\
          \ does not exceed the maximum accepted percentage. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/ColumnNonNegativePercentCheckSpec"
  ColumnNumericNegativeCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericNegativePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericNonNegativeCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericNonNegativePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericNumberAboveMaxValueCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      max_value:
        type: "integer"
        format: "int32"
        description: "This field can be used to define custom value. In order to define\
          \ custom value, user should write correct value as an integer. If value\
          \ is not defined by user then default value is 0"
  ColumnNumericNumberAboveMaxValuePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      max_value:
        type: "integer"
        format: "int32"
        description: "This field can be used to define custom value. In order to define\
          \ custom value, user should write correct value as an integer. If value\
          \ is not defined by user then default value is 0"
  ColumnNumericNumberBelowMinValueCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      min_value:
        type: "integer"
        format: "int32"
        description: "This field can be used to define custom value. In order to define\
          \ custom value, user should write correct value as an integer. If value\
          \ is not defined by user then default value is 0"
  ColumnNumericNumberBelowMinValuePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      min_value:
        type: "integer"
        format: "int32"
        description: "This field can be used to define custom value. In order to define\
          \ custom value, user should write correct value as an integer. If value\
          \ is not defined by user then default value is 0"
  ColumnNumericNumberFoundInSetPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      expected_values:
        type: "array"
        description: "A list of expected values that must be present in a numeric\
          \ column, only values from this list are accepted and rows having these\
          \ values in the tested column are counted as valid rows."
        items:
          type: "integer"
          format: "int64"
  ColumnNumericNumberInRangePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      min_value:
        type: "number"
        format: "double"
        description: "Minimum value for the range."
      max_value:
        type: "number"
        format: "double"
        description: "Maximum value for the range."
  ColumnNumericPercentile10SensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      percentile_value:
        type: "number"
        format: "double"
        description: "10th percentile, must equal 0.1"
  ColumnNumericPercentile25SensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      percentile_value:
        type: "number"
        format: "double"
        description: "25th percentile, must equal 0.25"
  ColumnNumericPercentile75SensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      percentile_value:
        type: "number"
        format: "double"
        description: "75th percentile, must equal 0.75"
  ColumnNumericPercentile90SensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      percentile_value:
        type: "number"
        format: "double"
        description: "90th percentile, must equal 0.9"
  ColumnNumericPercentileSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      percentile_value:
        type: "number"
        format: "double"
        description: "Must be a literal in the range [0, 1]."
  ColumnNumericPopulationStddevSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericPopulationVarianceSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_number_below_min_value:
        description: "The check counts the number of values in the column that are\
          \ below the value defined by the user as a parameter."
        $ref: "#/definitions/ColumnNumberBelowMinValueCheckSpec"
      profile_number_above_max_value:
        description: "The check counts the number of values in the column that are\
          \ above the value defined by the user as a parameter."
        $ref: "#/definitions/ColumnNumberAboveMaxValueCheckSpec"
      profile_negative_values:
        description: "Verifies that the number of negative values in a column does\
          \ not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnNegativeCountCheckSpec"
      profile_negative_values_percent:
        description: "Verifies that the percentage of negative values in a column\
          \ does not exceed the maximum accepted percentage."
        $ref: "#/definitions/ColumnNegativePercentCheckSpec"
      profile_number_below_min_value_percent:
        description: "The check counts the percentage of values in the column that\
          \ are below the value defined by the user as a parameter."
        $ref: "#/definitions/ColumnNumberBelowMinValuePercentCheckSpec"
      profile_number_above_max_value_percent:
        description: "The check counts the percentage of values in the column that\
          \ are above the value defined by the user as a parameter."
        $ref: "#/definitions/ColumnNumberAboveMaxValuePercentCheckSpec"
      profile_number_in_range_percent:
        description: "Verifies that the percentage of values from range in a column\
          \ does not exceed the minimum accepted percentage."
        $ref: "#/definitions/ColumnNumberInRangePercentCheckSpec"
      profile_integer_in_range_percent:
        description: "Verifies that the percentage of values from range in a column\
          \ does not exceed the minimum accepted percentage."
        $ref: "#/definitions/ColumnIntegerInRangePercentCheckSpec"
      profile_min_in_range:
        description: "Verifies that the minimum value in a column is not outside the\
          \ expected range."
        $ref: "#/definitions/ColumnMinInRangeCheckSpec"
      profile_max_in_range:
        description: "Verifies that the maximum value in a column is not outside the\
          \ expected range."
        $ref: "#/definitions/ColumnMaxInRangeCheckSpec"
      profile_sum_in_range:
        description: "Verifies that the sum of all values in a column is not outside\
          \ the expected range."
        $ref: "#/definitions/ColumnSumInRangeCheckSpec"
      profile_mean_in_range:
        description: "Verifies that the average (mean) of all values in a column is\
          \ not outside the expected range."
        $ref: "#/definitions/ColumnMeanInRangeCheckSpec"
      profile_median_in_range:
        description: "Verifies that the median of all values in a column is not outside\
          \ the expected range."
        $ref: "#/definitions/ColumnMedianInRangeCheckSpec"
      profile_percentile_in_range:
        description: "Verifies that the percentile of all values in a column is not\
          \ outside the expected range."
        $ref: "#/definitions/ColumnPercentileInRangeCheckSpec"
      profile_percentile_10_in_range:
        description: "Verifies that the percentile 10 of all values in a column is\
          \ not outside the expected range."
        $ref: "#/definitions/ColumnPercentile10InRangeCheckSpec"
      profile_percentile_25_in_range:
        description: "Verifies that the percentile 25 of all values in a column is\
          \ not outside the expected range."
        $ref: "#/definitions/ColumnPercentile25InRangeCheckSpec"
      profile_percentile_75_in_range:
        description: "Verifies that the percentile 75 of all values in a column is\
          \ not outside the expected range."
        $ref: "#/definitions/ColumnPercentile75InRangeCheckSpec"
      profile_percentile_90_in_range:
        description: "Verifies that the percentile 90 of all values in a column is\
          \ not outside the expected range."
        $ref: "#/definitions/ColumnPercentile90InRangeCheckSpec"
      profile_sample_stddev_in_range:
        description: "Verifies that the sample standard deviation of all values in\
          \ a column is not outside the expected range."
        $ref: "#/definitions/ColumnSampleStddevInRangeCheckSpec"
      profile_population_stddev_in_range:
        description: "Verifies that the population standard deviation of all values\
          \ in a column is not outside the expected range."
        $ref: "#/definitions/ColumnPopulationStddevInRangeCheckSpec"
      profile_sample_variance_in_range:
        description: "Verifies that the sample variance of all values in a column\
          \ is not outside the expected range."
        $ref: "#/definitions/ColumnSampleVarianceInRangeCheckSpec"
      profile_population_variance_in_range:
        description: "Verifies that the population variance of all values in a column\
          \ is not outside the expected range."
        $ref: "#/definitions/ColumnPopulationVarianceInRangeCheckSpec"
      profile_invalid_latitude:
        description: "Verifies that the number of invalid latitude values in a column\
          \ does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidLatitudeCountCheckSpec"
      profile_valid_latitude_percent:
        description: "Verifies that the percentage of valid latitude values in a column\
          \ does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnValidLatitudePercentCheckSpec"
      profile_invalid_longitude:
        description: "Verifies that the number of invalid longitude values in a column\
          \ does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidLongitudeCountCheckSpec"
      profile_valid_longitude_percent:
        description: "Verifies that the percentage of valid longitude values in a\
          \ column does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnValidLongitudePercentCheckSpec"
      profile_non_negative_values:
        description: "Verifies that the number of non-negative values in a column\
          \ does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnNonNegativeCountCheckSpec"
      profile_non_negative_values_percent:
        description: "Verifies that the percentage of non-negative values in a column\
          \ does not exceed the maximum accepted percentage."
        $ref: "#/definitions/ColumnNonNegativePercentCheckSpec"
  ColumnNumericSampleStddevSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericSampleVarianceSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericSumSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericValidLatitudePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnNumericValidLongitudePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPartitionedCheckCategoriesSpec:
    type: "object"
    properties:
      daily:
        description: "Configuration of day partitioned data quality checks evaluated\
          \ at a column level."
        $ref: "#/definitions/ColumnDailyPartitionedCheckCategoriesSpec"
      monthly:
        description: "Configuration of monthly partitioned data quality checks evaluated\
          \ at a column level."
        $ref: "#/definitions/ColumnMonthlyPartitionedCheckCategoriesSpec"
  ColumnPatternsDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_text_not_matching_regex_found:
        description: "Verifies that the number of text values not matching the custom\
          \ regular expression pattern does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnTextNotMatchingRegexFoundCheckSpec"
      daily_texts_matching_regex_percent:
        description: "Verifies that the percentage of strings matching the custom\
          \ regular expression pattern does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnTextsMatchingRegexPercentCheckSpec"
      daily_invalid_email_format_found:
        description: "Verifies that the number of invalid emails in a text column\
          \ does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidEmailFormatFoundCheckSpec"
      daily_invalid_email_format_percent:
        description: "Verifies that the percentage of invalid emails in a text column\
          \ does not exceed the maximum accepted percentage."
        $ref: "#/definitions/ColumnInvalidEmailFormatPercentCheckSpec"
      daily_text_not_matching_date_pattern_found:
        description: "Verifies that the number of texts not matching the date format\
          \ regular expression does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnTextNotMatchingDatePatternFoundCheckSpec"
      daily_text_matching_date_pattern_percent:
        description: "Verifies that the percentage of texts matching the date format\
          \ regular expression in a column does not fall below the minimum accepted\
          \ percentage."
        $ref: "#/definitions/ColumnTextMatchingDatePatternPercentCheckSpec"
      daily_text_matching_name_pattern_percent:
        description: "Verifies that the percentage of texts matching the name regular\
          \ expression does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnTextMatchingNamePatternPercentCheckSpec"
      daily_invalid_uuid_format_found:
        description: "Verifies that the number of invalid UUIDs in a text column does\
          \ not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidUuidFormatFoundCheckSpec"
      daily_valid_uuid_format_percent:
        description: "Verifies that the percentage of valid UUID in a text column\
          \ does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnValidUuidFormatPercentCheckSpec"
      daily_invalid_ip4_address_format_found:
        description: "Verifies that the number of invalid IP4 addresses in a text\
          \ column does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidIp4AddressFormatFoundCheckSpec"
      daily_invalid_ip6_address_format_found:
        description: "Verifies that the number of invalid IP6 addresses in a text\
          \ column does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidIp6AddressFormatFoundCheckSpec"
  ColumnPatternsDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_text_not_matching_regex_found:
        description: "Verifies that the number of text values not matching the custom\
          \ regular expression pattern does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnTextNotMatchingRegexFoundCheckSpec"
      daily_partition_texts_matching_regex_percent:
        description: "Verifies that the percentage of strings matching the custom\
          \ regular expression pattern does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnTextsMatchingRegexPercentCheckSpec"
      daily_partition_invalid_email_format_found:
        description: "Verifies that the number of invalid emails in a text column\
          \ does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidEmailFormatFoundCheckSpec"
      daily_partition_invalid_email_format_percent:
        description: "Verifies that the percentage of invalid emails in a text column\
          \ does not exceed the maximum accepted percentage."
        $ref: "#/definitions/ColumnInvalidEmailFormatPercentCheckSpec"
      daily_partition_text_not_matching_date_pattern_found:
        description: "Verifies that the number of texts not matching the date format\
          \ regular expression does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnTextNotMatchingDatePatternFoundCheckSpec"
      daily_partition_text_matching_date_pattern_percent:
        description: "Verifies that the percentage of texts matching the date format\
          \ regular expression in a column does not fall below the minimum accepted\
          \ percentage."
        $ref: "#/definitions/ColumnTextMatchingDatePatternPercentCheckSpec"
      daily_partition_text_matching_name_pattern_percent:
        description: "Verifies that the percentage of texts matching the name regular\
          \ expression does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnTextMatchingNamePatternPercentCheckSpec"
      daily_partition_invalid_uuid_format_found:
        description: "Verifies that the number of invalid UUIDs in a text column does\
          \ not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidUuidFormatFoundCheckSpec"
      daily_partition_valid_uuid_format_percent:
        description: "Verifies that the percentage of valid UUID in a text column\
          \ does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnValidUuidFormatPercentCheckSpec"
      daily_partition_invalid_ip4_address_format_found:
        description: "Verifies that the number of invalid IP4 addresses in a text\
          \ column does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidIp4AddressFormatFoundCheckSpec"
      daily_partition_invalid_ip6_address_format_found:
        description: "Verifies that the number of invalid IP6 addresses in a text\
          \ column does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidIp6AddressFormatFoundCheckSpec"
  ColumnPatternsInvalidEmailFormatCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPatternsInvalidEmailFormatPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPatternsInvalidIp4AddressFormatCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPatternsInvalidIp6AddressFormatCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPatternsInvalidUuidFormatCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPatternsMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_text_not_matching_regex_found:
        description: "Verifies that the number of text values not matching the custom\
          \ regular expression pattern does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnTextNotMatchingRegexFoundCheckSpec"
      monthly_texts_matching_regex_percent:
        description: "Verifies that the percentage of strings matching the custom\
          \ regular expression pattern does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnTextsMatchingRegexPercentCheckSpec"
      monthly_invalid_email_format_found:
        description: "Verifies that the number of invalid emails in a text column\
          \ does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidEmailFormatFoundCheckSpec"
      monthly_invalid_email_format_percent:
        description: "Verifies that the percentage of invalid emails in a text column\
          \ does not exceed the maximum accepted percentage."
        $ref: "#/definitions/ColumnInvalidEmailFormatPercentCheckSpec"
      monthly_text_not_matching_date_pattern_found:
        description: "Verifies that the number of texts not matching the date format\
          \ regular expression does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnTextNotMatchingDatePatternFoundCheckSpec"
      monthly_text_matching_date_pattern_percent:
        description: "Verifies that the percentage of texts matching the date format\
          \ regular expression in a column does not fall below the minimum accepted\
          \ percentage."
        $ref: "#/definitions/ColumnTextMatchingDatePatternPercentCheckSpec"
      monthly_text_matching_name_pattern_percent:
        description: "Verifies that the percentage of texts matching the name regular\
          \ expression does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnTextMatchingNamePatternPercentCheckSpec"
      monthly_invalid_uuid_format_found:
        description: "Verifies that the number of invalid UUIDs in a text column does\
          \ not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidUuidFormatFoundCheckSpec"
      monthly_valid_uuid_format_percent:
        description: "Verifies that the percentage of valid UUID in a text column\
          \ does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnValidUuidFormatPercentCheckSpec"
      monthly_invalid_ip4_address_format_found:
        description: "Verifies that the number of invalid IP4 addresses in a text\
          \ column does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidIp4AddressFormatFoundCheckSpec"
      monthly_invalid_ip6_address_format_found:
        description: "Verifies that the number of invalid IP6 addresses in a text\
          \ column does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidIp6AddressFormatFoundCheckSpec"
  ColumnPatternsMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_text_not_matching_regex_found:
        description: "Verifies that the number of text values not matching the custom\
          \ regular expression pattern does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnTextNotMatchingRegexFoundCheckSpec"
      monthly_partition_texts_matching_regex_percent:
        description: "Verifies that the percentage of strings matching the custom\
          \ regular expression pattern does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnTextsMatchingRegexPercentCheckSpec"
      monthly_partition_invalid_email_format_found:
        description: "Verifies that the number of invalid emails in a text column\
          \ does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidEmailFormatFoundCheckSpec"
      monthly_partition_invalid_email_format_percent:
        description: "Verifies that the percentage of invalid emails in a text column\
          \ does not exceed the maximum accepted percentage."
        $ref: "#/definitions/ColumnInvalidEmailFormatPercentCheckSpec"
      monthly_partition_text_not_matching_date_pattern_found:
        description: "Verifies that the number of texts not matching the date format\
          \ regular expression does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnTextNotMatchingDatePatternFoundCheckSpec"
      monthly_partition_text_matching_date_pattern_percent:
        description: "Verifies that the percentage of texts matching the date format\
          \ regular expression in a column does not fall below the minimum accepted\
          \ percentage."
        $ref: "#/definitions/ColumnTextMatchingDatePatternPercentCheckSpec"
      monthly_partition_text_matching_name_pattern_percent:
        description: "Verifies that the percentage of texts matching the name regular\
          \ expression does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnTextMatchingNamePatternPercentCheckSpec"
      monthly_partition_invalid_uuid_format_found:
        description: "Verifies that the number of invalid UUIDs in a text column does\
          \ not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidUuidFormatFoundCheckSpec"
      monthly_partition_valid_uuid_format_percent:
        description: "Verifies that the percentage of valid UUID in a text column\
          \ does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnValidUuidFormatPercentCheckSpec"
      monthly_partition_invalid_ip4_address_format_found:
        description: "Verifies that the number of invalid IP4 addresses in a text\
          \ column does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidIp4AddressFormatFoundCheckSpec"
      monthly_partition_invalid_ip6_address_format_found:
        description: "Verifies that the number of invalid IP6 addresses in a text\
          \ column does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidIp6AddressFormatFoundCheckSpec"
  ColumnPatternsProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_text_not_matching_regex_found:
        description: "Verifies that the number of text values not matching the custom\
          \ regular expression pattern does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnTextNotMatchingRegexFoundCheckSpec"
      profile_texts_matching_regex_percent:
        description: "Verifies that the percentage of strings matching the custom\
          \ regular expression pattern does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnTextsMatchingRegexPercentCheckSpec"
      profile_invalid_email_format_found:
        description: "Verifies that the number of invalid emails in a text column\
          \ does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidEmailFormatFoundCheckSpec"
      profile_invalid_email_format_percent:
        description: "Verifies that the percentage of invalid emails in a text column\
          \ does not exceed the maximum accepted percentage."
        $ref: "#/definitions/ColumnInvalidEmailFormatPercentCheckSpec"
      profile_text_not_matching_date_pattern_found:
        description: "Verifies that the number of texts not matching the date format\
          \ regular expression does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnTextNotMatchingDatePatternFoundCheckSpec"
      profile_text_matching_date_pattern_percent:
        description: "Verifies that the percentage of texts matching the date format\
          \ regular expression in a column does not fall below the minimum accepted\
          \ percentage."
        $ref: "#/definitions/ColumnTextMatchingDatePatternPercentCheckSpec"
      profile_text_matching_name_pattern_percent:
        description: "Verifies that the percentage of texts matching the name regular\
          \ expression does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnTextMatchingNamePatternPercentCheckSpec"
      profile_invalid_uuid_format_found:
        description: "Verifies that the number of invalid UUIDs in a text column does\
          \ not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidUuidFormatFoundCheckSpec"
      profile_valid_uuid_format_percent:
        description: "Verifies that the percentage of valid UUID in a text column\
          \ does not fall below the minimum accepted percentage."
        $ref: "#/definitions/ColumnValidUuidFormatPercentCheckSpec"
      profile_invalid_ip4_address_format_found:
        description: "Verifies that the number of invalid IP4 addresses in a text\
          \ column does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidIp4AddressFormatFoundCheckSpec"
      profile_invalid_ip6_address_format_found:
        description: "Verifies that the number of invalid IP6 addresses in a text\
          \ column does not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnInvalidIp6AddressFormatFoundCheckSpec"
  ColumnPatternsTextMatchingDatePatternPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      date_format:
        type: "string"
        description: "Desired date format. Sensor will try to parse the column records\
          \ and cast the data using this format."
        enum:
        - "YYYY-MM-DD"
        - "MM/DD/YYYY"
        - "DD/MM/YYYY"
        - "YYYY/MM/DD"
        - "Month D, YYYY"
  ColumnPatternsTextMatchingNamePatternPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPatternsTextNotMatchingDatePatternCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      date_format:
        type: "string"
        description: "Desired date format. Sensor will try to parse the column records\
          \ and cast the data using this format."
        enum:
        - "YYYY-MM-DD"
        - "MM/DD/YYYY"
        - "DD/MM/YYYY"
        - "YYYY/MM/DD"
        - "Month D, YYYY"
  ColumnPatternsTextNotMatchingRegexCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      regex:
        type: "string"
        description: "This field can be used to define custom regex. In order to define\
          \ custom regex, user should write correct regex as a string. If regex is\
          \ not defined by user then default regex is null"
  ColumnPatternsTextsMatchingRegexPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      regex:
        type: "string"
        description: "This field can be used to define custom regex. In order to define\
          \ custom regex, user should write correct regex as a string. If regex is\
          \ not defined by user then default regex is null"
  ColumnPatternsValidUuidFormatPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPercentile10InRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericPercentile10SensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a percentile 10 in a column that\
          \ raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnPercentile25InRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericPercentile25SensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a percentile 25 in a column that\
          \ raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnPercentile75InRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericPercentile75SensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a percentile 75 in a column that\
          \ raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnPercentile90InRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericPercentile90SensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a percentile 90 in a column that\
          \ raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnPercentileInRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericPercentileSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a percentile in a column that\
          \ raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnPiiContainsEmailPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPiiContainsEmailPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum percentage of rows\
          \ that contains email values in a column that raises a data quality error\
          \ (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnPiiContainsEmailPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPiiContainsIp4PercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPiiContainsIp4PercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum percentage of rows\
          \ that contains IP4 values in a column that raises a data quality error\
          \ (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnPiiContainsIp4PercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPiiContainsIp6PercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPiiContainsIp6PercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum percentage of rows\
          \ that contains IP6 values in a column that raises a data quality error\
          \ (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnPiiContainsIp6PercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPiiContainsUsaPhonePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Numerical value in range percent sensor parameters"
        $ref: "#/definitions/ColumnPiiContainsUsaPhonePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for the minimum percentage of rows\
          \ that contains a USA phone number in a column that raises a data quality\
          \ error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnPiiContainsUsaPhonePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPiiContainsUsaZipcodePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Numerical value in range percent sensor parameters"
        $ref: "#/definitions/ColumnPiiContainsUsaZipcodePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for the minimum percentage of rows\
          \ that contains a USA zip code number in a column that raises a data quality\
          \ error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnPiiContainsUsaZipcodePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnPiiDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_contains_usa_phone_percent:
        description: "Detects USA phone numbers in text columns. Verifies that the\
          \ percentage of rows that contains a USA phone number in a column does not\
          \ exceed the maximum accepted percentage. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPiiContainsUsaPhonePercentCheckSpec"
      daily_contains_email_percent:
        description: "Detects emails in text columns. Verifies that the percentage\
          \ of rows that contains emails in a column does not exceed the minimum accepted\
          \ percentage. Stores the most recent captured value for each day when the\
          \ data quality check was evaluated."
        $ref: "#/definitions/ColumnPiiContainsEmailPercentCheckSpec"
      daily_contains_usa_zipcode_percent:
        description: "Detects USA zip codes in text columns. Verifies that the percentage\
          \ of rows that contains a USA zip code in a column does not exceed the maximum\
          \ accepted percentage. Stores the most recent captured value for each day\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPiiContainsUsaZipcodePercentCheckSpec"
      daily_contains_ip4_percent:
        description: "Detects IP4 addresses in text columns. Verifies that the percentage\
          \ of rows that contains IP4 address values in a column does not fall below\
          \ the minimum accepted percentage. Stores the most recent captured value\
          \ for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPiiContainsIp4PercentCheckSpec"
      daily_contains_ip6_percent:
        description: "Detects IP6 addresses in text columns. Verifies that the percentage\
          \ of rows that contains valid IP6 address values in a column does not fall\
          \ below the minimum accepted percentage. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPiiContainsIp6PercentCheckSpec"
  ColumnPiiDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_contains_usa_phone_percent:
        description: "Detects USA phone numbers in text columns. Verifies that the\
          \ percentage of rows that contains USA phone number in a column does not\
          \ exceed the maximum accepted percentage. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnPiiContainsUsaPhonePercentCheckSpec"
      daily_partition_contains_email_percent:
        description: "Detects emails in text columns. Verifies that the percentage\
          \ of rows that contains emails in a column does not exceed the minimum accepted\
          \ percentage. Stores a separate data quality check result for each daily\
          \ partition."
        $ref: "#/definitions/ColumnPiiContainsEmailPercentCheckSpec"
      daily_partition_contains_usa_zipcode_percent:
        description: "Detects USA zip codes in text columns. Verifies that the percentage\
          \ of rows that contains USA zip code in a column does not exceed the maximum\
          \ accepted percentage. Stores a separate data quality check result for each\
          \ daily partition."
        $ref: "#/definitions/ColumnPiiContainsUsaZipcodePercentCheckSpec"
      daily_partition_contains_ip4_percent:
        description: "Detects IP4 addresses in text columns. Verifies that the percentage\
          \ of rows that contains IP4 address values in a column does not fall below\
          \ the minimum accepted percentage. Stores a separate data quality check\
          \ result for each daily partition."
        $ref: "#/definitions/ColumnPiiContainsIp4PercentCheckSpec"
      daily_partition_contains_ip6_percent:
        description: "Detects IP6 addresses in text columns. Verifies that the percentage\
          \ of rows that contains valid IP6 address values in a column does not fall\
          \ below the minimum accepted percentage. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnPiiContainsIp6PercentCheckSpec"
  ColumnPiiMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_contains_usa_phone_percent:
        description: "Detects USA phone numbers in text columns. Verifies that the\
          \ percentage of rows that contains a USA phone number in a column does not\
          \ exceed the maximum accepted percentage. Stores the most recent check result\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPiiContainsUsaPhonePercentCheckSpec"
      monthly_contains_email_percent:
        description: "Detects emails in text columns. Verifies that the percentage\
          \ of rows that contains emails in a column does not exceed the minimum accepted\
          \ percentage. Stores the most recent check result for each month when the\
          \ data quality check was evaluated."
        $ref: "#/definitions/ColumnPiiContainsEmailPercentCheckSpec"
      monthly_contains_usa_zipcode_percent:
        description: "Detects USA zip codes in text columns. Verifies that the percentage\
          \ of rows that contains a USA zip code in a column does not exceed the maximum\
          \ accepted percentage. Stores the most recent check result for each month\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPiiContainsUsaZipcodePercentCheckSpec"
      monthly_contains_ip4_percent:
        description: "Detects IP4 addresses in text columns. Verifies that the percentage\
          \ of rows that contains IP4 address values in a column does not fall below\
          \ the minimum accepted percentage. Stores the most recent check result for\
          \ each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPiiContainsIp4PercentCheckSpec"
      monthly_contains_ip6_percent:
        description: "Detects IP6 addresses in text columns. Verifies that the percentage\
          \ of rows that contains valid IP6 address values in a column does not fall\
          \ below the minimum accepted percentage. Stores the most recent check result\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnPiiContainsIp6PercentCheckSpec"
  ColumnPiiMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_contains_usa_phone_percent:
        description: "Detects USA phone numbers in text columns. Verifies that the\
          \ percentage of rows that contains USA phone number in a column does not\
          \ exceed the maximum accepted percentage. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnPiiContainsUsaPhonePercentCheckSpec"
      monthly_partition_contains_email_percent:
        description: "Detects emails in text columns. Verifies that the percentage\
          \ of rows that contains emails in a column does not exceed the minimum accepted\
          \ percentage. Stores a separate data quality check result for each monthly\
          \ partition."
        $ref: "#/definitions/ColumnPiiContainsEmailPercentCheckSpec"
      monthly_partition_contains_usa_zipcode_percent:
        description: "Detects USA zip codes in text columns. Verifies that the percentage\
          \ of rows that contains USA zip code in a column does not exceed the maximum\
          \ accepted percentage. Stores a separate data quality check result for each\
          \ monthly partition."
        $ref: "#/definitions/ColumnPiiContainsUsaZipcodePercentCheckSpec"
      monthly_partition_contains_ip4_percent:
        description: "Detects IP4 addresses in text columns. Verifies that the percentage\
          \ of rows that contains IP4 address values in a column does not fall below\
          \ the minimum accepted percentage. Stores a separate data quality check\
          \ result for each monthly partition."
        $ref: "#/definitions/ColumnPiiContainsIp4PercentCheckSpec"
      monthly_partition_contains_ip6_percent:
        description: "Detects IP6 addresses in text columns. Verifies that the percentage\
          \ of rows that contains valid IP6 address values in a column does not fall\
          \ below the minimum accepted percentage. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnPiiContainsIp6PercentCheckSpec"
  ColumnPiiProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_contains_usa_phone_percent:
        description: "Detects USA phone numbers in text columns. Verifies that the\
          \ percentage of rows that contains USA phone number in a column does not\
          \ exceed the maximum accepted percentage."
        $ref: "#/definitions/ColumnPiiContainsUsaPhonePercentCheckSpec"
      profile_contains_email_percent:
        description: "Detects emails in text columns. Verifies that the percentage\
          \ of rows that contains valid emails in a column does not exceed the minimum\
          \ accepted percentage."
        $ref: "#/definitions/ColumnPiiContainsEmailPercentCheckSpec"
      profile_contains_usa_zipcode_percent:
        description: "Detects USA zip codes in text columns. Verifies that the percentage\
          \ of rows that contains USA zip code in a column does not exceed the maximum\
          \ accepted percentage."
        $ref: "#/definitions/ColumnPiiContainsUsaZipcodePercentCheckSpec"
      profile_contains_ip4_percent:
        description: "Detects IP4 addresses in text columns. Verifies that the percentage\
          \ of rows that contains valid IP4 address values in a column does not fall\
          \ below the minimum accepted percentage."
        $ref: "#/definitions/ColumnPiiContainsIp4PercentCheckSpec"
      profile_contains_ip6_percent:
        description: "Detects IP6 addresses in text columns. Verifies that the percentage\
          \ of rows that contains valid IP6 address values in a column does not fall\
          \ below the minimum accepted percentage."
        $ref: "#/definitions/ColumnPiiContainsIp6PercentCheckSpec"
  ColumnPopulationStddevInRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericPopulationStddevSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a population (biased) standard\
          \ deviation in range in a column that raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnPopulationVarianceInRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericPopulationVarianceSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a population (biased) standard\
          \ deviation in range in a column that raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnProfilingCheckCategoriesSpec:
    type: "object"
    properties:
      custom:
        type: "object"
        description: "Dictionary of custom checks. The keys are check names within\
          \ this category."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      nulls:
        description: "Configuration of column level checks that detect null values."
        $ref: "#/definitions/ColumnNullsProfilingChecksSpec"
      uniqueness:
        description: "Configuration of uniqueness checks on a column level."
        $ref: "#/definitions/ColumnUniquenessProfilingChecksSpec"
      accepted_values:
        description: "Configuration of accepted values checks on a column level."
        $ref: "#/definitions/ColumnAcceptedValuesProfilingChecksSpec"
      text:
        description: "Configuration of column level checks that verify text values."
        $ref: "#/definitions/ColumnTextProfilingChecksSpec"
      whitespace:
        description: "Configuration of column level checks that detect blank and whitespace\
          \ values."
        $ref: "#/definitions/ColumnWhitespaceProfilingChecksSpec"
      conversions:
        description: "Configuration of conversion testing checks on a column level."
        $ref: "#/definitions/ColumnConversionsProfilingChecksSpec"
      patterns:
        description: "Configuration of pattern match checks on a column level."
        $ref: "#/definitions/ColumnPatternsProfilingChecksSpec"
      pii:
        description: "Configuration of Personal Identifiable Information (PII) checks\
          \ on a column level."
        $ref: "#/definitions/ColumnPiiProfilingChecksSpec"
      numeric:
        description: "Configuration of column level checks that verify numeric values."
        $ref: "#/definitions/ColumnNumericProfilingChecksSpec"
      anomaly:
        description: "Configuration of anomaly checks on a column level that detect\
          \ anomalies in numeric columns."
        $ref: "#/definitions/ColumnAnomalyProfilingChecksSpec"
      datetime:
        description: "Configuration of datetime checks on a column level."
        $ref: "#/definitions/ColumnDatetimeProfilingChecksSpec"
      bool:
        description: "Configuration of booleans checks on a column level."
        $ref: "#/definitions/ColumnBoolProfilingChecksSpec"
      integrity:
        description: "Configuration of integrity checks on a column level."
        $ref: "#/definitions/ColumnIntegrityProfilingChecksSpec"
      accuracy:
        description: "Configuration of accuracy checks on a column level."
        $ref: "#/definitions/ColumnAccuracyProfilingChecksSpec"
      custom_sql:
        description: "Configuration of SQL checks that use custom SQL aggregated expressions\
          \ and SQL conditions in data quality checks."
        $ref: "#/definitions/ColumnCustomSqlProfilingChecksSpec"
      datatype:
        description: "Configuration of datatype checks on a column level."
        $ref: "#/definitions/ColumnDatatypeProfilingChecksSpec"
      schema:
        description: "Configuration of schema checks on a column level."
        $ref: "#/definitions/ColumnSchemaProfilingChecksSpec"
      comparisons:
        type: "object"
        description: "Dictionary of configuration of checks for table comparisons\
          \ at a column level. The key that identifies each comparison must match\
          \ the name of a data comparison that is configured on the parent table."
        additionalProperties:
          $ref: "#/definitions/ColumnComparisonProfilingChecksSpec"
  ColumnRangeMaxValueSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnRangeMaxValueStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnRangeMaxValueSensorParametersSpec"
  ColumnRangeMedianValueStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnNumericMedianSensorParametersSpec"
  ColumnRangeMinValueSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnRangeMinValueStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnRangeMinValueSensorParametersSpec"
  ColumnRangeStatisticsCollectorsSpec:
    type: "object"
    properties:
      min_value:
        description: "Configuration of the profiler that finds the minimum value in\
          \ the column."
        $ref: "#/definitions/ColumnRangeMinValueStatisticsCollectorSpec"
      median_value:
        description: "Configuration of the profiler that finds the median value in\
          \ the column."
        $ref: "#/definitions/ColumnRangeMedianValueStatisticsCollectorSpec"
      max_value:
        description: "Configuration of the profiler that finds the maximum value in\
          \ the column."
        $ref: "#/definitions/ColumnRangeMaxValueStatisticsCollectorSpec"
      sum_value:
        description: "Configuration of the profiler that finds the sum value in the\
          \ column."
        $ref: "#/definitions/ColumnRangeSumValueStatisticsCollectorSpec"
  ColumnRangeSumValueStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnNumericSumSensorParametersSpec"
  ColumnSampleStddevInRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericSampleStddevSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a sample (unbiased) maximum values\
          \ in range in a column that raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnSampleVarianceInRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericSampleVarianceSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a sample (unbiased) maximum values\
          \ in range in a column that raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnSamplingColumnSamplesSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      limit:
        type: "integer"
        format: "int32"
        description: "The limit of results that are returned. The default value is\
          \ 10 sample values with the highest count (the most popular)."
  ColumnSamplingColumnSamplesStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnSamplingColumnSamplesSensorParametersSpec"
  ColumnSamplingStatisticsCollectorsSpec:
    type: "object"
    properties:
      column_samples:
        description: "Configuration of the profiler that finds the maximum string\
          \ length."
        $ref: "#/definitions/ColumnSamplingColumnSamplesStatisticsCollectorSpec"
  ColumnSchemaColumnExistsCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters for a column exists sensor"
        $ref: "#/definitions/ColumnColumnExistsSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning when the\
          \ column was not found."
        $ref: "#/definitions/Equals1RuleParametersSpec"
      error:
        description: "Alerting threshold that raises a data quality error when the\
          \ column was not found."
        $ref: "#/definitions/Equals1RuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a data quality fatal issue when\
          \ the column was not found."
        $ref: "#/definitions/Equals1RuleParametersSpec"
  ColumnSchemaDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_column_exists:
        description: "Checks the metadata of the monitored table and verifies if the\
          \ column exists. Stores the most recent value for each day when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnSchemaColumnExistsCheckSpec"
      daily_column_type_changed:
        description: "Checks the metadata of the monitored column and detects if the\
          \ data type (including the length, precision, scale, nullability) has changed\
          \ since the last day. Stores the most recent hash for each day when the\
          \ data quality check was evaluated."
        $ref: "#/definitions/ColumnSchemaTypeChangedCheckSpec"
  ColumnSchemaMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_column_exists:
        description: "Checks the metadata of the monitored table and verifies if the\
          \ column exists. Stores the most recent value for each month when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnSchemaColumnExistsCheckSpec"
      monthly_column_type_changed:
        description: "Checks the metadata of the monitored column and detects if the\
          \ data type (including the length, precision, scale, nullability) has changed\
          \ since the last month. Stores the most recent hash for each month when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnSchemaTypeChangedCheckSpec"
  ColumnSchemaProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_column_exists:
        description: "Checks the metadata of the monitored table and verifies if the\
          \ column exists."
        $ref: "#/definitions/ColumnSchemaColumnExistsCheckSpec"
      profile_column_type_changed:
        description: "Checks the metadata of the monitored column and detects if the\
          \ data type (including the length, precision, scale, nullability) has changed."
        $ref: "#/definitions/ColumnSchemaTypeChangedCheckSpec"
  ColumnSchemaTypeChangedCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Column data type hash sensor parameters"
        $ref: "#/definitions/ColumnColumnTypeHashSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      error:
        description: "Default alerting thresholdthat raises a data quality issue at\
          \ an error severity level"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
  ColumnSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables all data quality checks on the column. Data quality\
          \ checks will not be executed."
      sql_expression:
        type: "string"
        description: "SQL expression used for calculated fields or when additional\
          \ column value transformation is required before the column can be used\
          \ for analysis with data quality checks (data type conversion, transformation).\
          \ It should be an SQL expression that uses the SQL language of the analyzed\
          \ database type. Use the replacement tokens {table} to replace the content\
          \ with the full table name, {alias} to replace the content with the table\
          \ alias of the table under analysis, or {column} to replace the content\
          \ with the analyzed column name. An example of extracting a value from a\
          \ string column storing JSON in PostgreSQL: \"{column}::json->'address'->'zip'\"\
          ."
      type_snapshot:
        description: "Column data type that was retrieved when the table metadata\
          \ was imported."
        $ref: "#/definitions/ColumnTypeSnapshotSpec"
      profiling_checks:
        description: "Configuration of data quality profiling checks that are enabled.\
          \ Pick a check from a category, apply the parameters and rules to enable\
          \ it."
        $ref: "#/definitions/ColumnProfilingCheckCategoriesSpec"
      monitoring_checks:
        description: "Configuration of column level monitoring checks. Monitoring\
          \ are data quality checks that are evaluated for each period of time (daily,\
          \ weekly, monthly, etc.). A monitoring stores only the most recent data\
          \ quality check result for each period of time."
        $ref: "#/definitions/ColumnMonitoringCheckCategoriesSpec"
      partitioned_checks:
        description: "Configuration of column level date/time partitioned checks.\
          \ Partitioned data quality checks are evaluated for each partition separately,\
          \ raising separate alerts at a partition level. The table does not need\
          \ to be physically partitioned by date, it is possible to run data quality\
          \ checks for each day or month of data separately."
        $ref: "#/definitions/ColumnPartitionedCheckCategoriesSpec"
      statistics:
        description: "Custom configuration of a column level statistics collector\
          \ (a basic profiler). Enables customization of the statistics collector\
          \ settings when the collector is analysing this column."
        $ref: "#/definitions/ColumnStatisticsCollectorsRootCategoriesSpec"
      labels:
        type: "array"
        description: "Custom labels that were assigned to the column. Labels are used\
          \ for searching for columns when filtered data quality checks are executed."
        items:
          type: "string"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
  ColumnSqlAggregateExpressionCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sensor parameters with the custom SQL aggregate expression that\
          \ is evaluated on a column"
        $ref: "#/definitions/ColumnSqlAggregatedExpressionSensorParametersSpec"
      warning:
        description: "Default alerting threshold for warnings raised when the aggregated\
          \ value is above the maximum accepted value."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for errors raised when the aggregated\
          \ value is above the maximum accepted value."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Default alerting threshold for fatal data quality issues raised\
          \ when the aggregated value is above the maximum accepted value."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnSqlAggregatedExpressionSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      sql_expression:
        type: "string"
        description: "SQL aggregate expression that returns a numeric value calculated\
          \ from rows. The expression is evaluated on a whole table or within a GROUP\
          \ BY clause for daily partitions and/or data groups. The expression can\
          \ use {table} and {column} placeholder that are replaced with a full table\
          \ name and the analyzed column name."
  ColumnSqlConditionFailedCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sensor parameters with the custom SQL condition (an expression\
          \ that returns true/false) which is evaluated on a each row, using a {column}\
          \ placeholder to reference the current column."
        $ref: "#/definitions/ColumnSqlConditionFailedCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning when a\
          \ given number of rows failed the custom SQL condition (expression). The\
          \ warning is considered as a passed data quality check."
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows failing\
          \ the custom SQL condition (expression) that raises a data quality error\
          \ (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue when\
          \ a given number of rows failed the custom SQL condition (expression). A\
          \ fatal issue indicates a serious data quality problem that should result\
          \ in stopping the data pipelines."
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnSqlConditionFailedCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      sql_condition:
        type: "string"
        description: "SQL condition (expression) that returns true or false. The condition\
          \ is evaluated for each row. The expression can use {table} and {column}\
          \ placeholder that are replaced with a full table name and the analyzed\
          \ column name."
  ColumnSqlConditionPassedPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sensor parameters with the custom SQL condition (an expression\
          \ that returns true/false) which is evaluated on a each row for the given\
          \ column, using a {column} placeholder to reference the current column."
        $ref: "#/definitions/ColumnSqlConditionPassedPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning when a\
          \ minimum acceptable percentage of rows did not pass the custom SQL condition\
          \ (expression). The warning is considered as a passed data quality check."
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum acceptable percentage\
          \ of rows passing the custom SQL condition (expression) that raises a data\
          \ quality error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue when\
          \ a minimum acceptable percentage of rows did not pass the custom SQL condition\
          \ (expression). A fatal issue indicates a serious data quality problem that\
          \ should result in stopping the data pipelines."
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnSqlConditionPassedPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      sql_condition:
        type: "string"
        description: "SQL condition (expression) that returns true or false. The condition\
          \ is evaluated for each row. The expression can use {table} and {column}\
          \ placeholder that are replaced with a full table name and the analyzed\
          \ column name."
  ColumnSqlImportCustomResultCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sensor parameters with the custom SQL SELECT statement that\
          \ queries a log table to get a result of a custom query that retrieves results\
          \ from other data quality libraries."
        $ref: "#/definitions/ColumnSqlImportCustomResultSensorParametersSpec"
      warning:
        description: "Warning severity import rule. Activate the rule with no parameters\
          \ to import custom data quality results when the custom query returns a\
          \ value **1** in the *severity* result column."
        $ref: "#/definitions/ImportSeverityRuleParametersSpec"
      error:
        description: "Error severity import rule. Activate the rule with no parameters\
          \ to import custom data quality results when the custom query returns a\
          \ value **2** in the *severity* result column."
        $ref: "#/definitions/ImportSeverityRuleParametersSpec"
      fatal:
        description: "Fatal severity import rule. Activate the rule with no parameters\
          \ to import custom data quality results when the custom query returns a\
          \ value **3** in the *severity* result column."
        $ref: "#/definitions/ImportSeverityRuleParametersSpec"
  ColumnSqlImportCustomResultSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      sql_query:
        type: "string"
        description: "A custom SELECT statement that queries a logging table with\
          \ custom results of data quality checks executed by the data pipeline. The\
          \ query must return a result column named *severity*. The values of the\
          \ *severity* column must be: 0 - data quality check passed, 1 - warning\
          \ issue, 2 - error severity issue, 3 - fatal severity issue. The query can\
          \ return *actual_value* and *expected_value* results that are imported into\
          \ DQOps data lake. The query can use a {table_name} placeholder that is\
          \ replaced with a table name for which the results are imported, and a {column_name}\
          \ placeholder replaced with the column name."
  ColumnStatisticsCollectorsRootCategoriesSpec:
    type: "object"
    properties:
      nulls:
        description: "Configuration of null values profilers on a column level."
        $ref: "#/definitions/ColumnNullsStatisticsCollectorsSpec"
      text:
        description: "Configuration of text column profilers on a column level."
        $ref: "#/definitions/ColumnTextStatisticsCollectorsSpec"
      uniqueness:
        description: "Configuration of profilers that analyse uniqueness of values\
          \ (distinct count)."
        $ref: "#/definitions/ColumnUniquenessStatisticsCollectorsSpec"
      range:
        description: "Configuration of profilers that analyse the range of values\
          \ (min, max)."
        $ref: "#/definitions/ColumnRangeStatisticsCollectorsSpec"
      sampling:
        description: "Configuration of profilers that collect the column samples."
        $ref: "#/definitions/ColumnSamplingStatisticsCollectorsSpec"
      strings:
        $ref: "#/definitions/ColumnTextStatisticsCollectorsSpec"
  ColumnStatisticsModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      table:
        description: "Physical table name including the schema and table names."
        $ref: "#/definitions/PhysicalTableName"
      column_name:
        type: "string"
        description: "Column name."
      column_hash:
        type: "integer"
        format: "int64"
        description: "Column hash that identifies the column using a unique hash code."
      disabled:
        type: "boolean"
        description: "Disables all data quality checks on the column. Data quality\
          \ checks will not be executed."
      has_any_configured_checks:
        type: "boolean"
        description: "True when the column has any checks configured."
      type_snapshot:
        description: "Column data type that was retrieved when the table metadata\
          \ was imported."
        $ref: "#/definitions/ColumnTypeSnapshotSpec"
      statistics:
        type: "array"
        description: "List of collected column statistics."
        items:
          $ref: "#/definitions/StatisticsMetricModel"
      collect_column_statistics_job_template:
        description: "Configured parameters for the \"collect statistics\" job that\
          \ should be pushed to the job queue in order to run all statistics collectors\
          \ for this column"
        $ref: "#/definitions/StatisticsCollectorSearchFilters"
      can_collect_statistics:
        type: "boolean"
        description: "Boolean flag that decides if the current user can collect statistics."
    description: "Column model that returns the basic fields from a column specification\
      \ with the additional data statistics."
  ColumnStringsExpectedTextValuesInUseCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      expected_values:
        type: "array"
        description: "List of expected string values that should be found in the tested\
          \ column."
        items:
          type: "string"
  ColumnStringsExpectedTextsInTopValuesCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      expected_values:
        type: "array"
        description: "List of expected string values that should be found in the tested\
          \ column among the TOP most popular (highest distinct count) column values."
        items:
          type: "string"
      top:
        type: "integer"
        format: "int64"
        description: "The number of the most popular values (with the highest distinct\
          \ count) that are analyzed to find the expected values."
  ColumnSumAnomalyDifferencingCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericSumSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnSumAnomalyStationaryPartitionCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericSumSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleFatal01PctParametersSpec"
  ColumnSumChange1DayCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericSumSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent1DayRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent1DayRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent1DayRule50ParametersSpec"
  ColumnSumChange30DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericSumSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent30DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent30DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent30DaysRule50ParametersSpec"
  ColumnSumChange7DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericSumSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent7DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent7DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent7DaysRule50ParametersSpec"
  ColumnSumChangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericSumSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercentRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercentRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercentRule50ParametersSpec"
  ColumnSumInRangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericSumSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a sum in range in a column that\
          \ raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnTextDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_text_min_length:
        description: "This check finds the length of the shortest text in a column.\
          \ Then, it verifies that the minimum length is within an accepted range.\
          \ It detects that the shortest text is too short. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextMinLengthCheckSpec"
      daily_text_max_length:
        description: "This check finds the length of the longest text in a column.\
          \ Then, it verifies that the maximum length is within an accepted range.\
          \ It detects that the texts are too long or not long enough. Stores the\
          \ most recent captured value for each day when the data quality check was\
          \ evaluated."
        $ref: "#/definitions/ColumnTextMaxLengthCheckSpec"
      daily_text_mean_length:
        description: "Verifies that the mean (average) length of texts in a column\
          \ is within an accepted range. Stores the most recent captured value for\
          \ each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextMeanLengthCheckSpec"
      daily_text_length_below_min_length:
        description: "The check counts the number of text values in the column that\
          \ is below the length defined by the user as a parameter. Stores the most\
          \ recent captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextLengthBelowMinLengthCheckSpec"
      daily_text_length_below_min_length_percent:
        description: "The check measures the percentage of text values in the column\
          \ that is below the length defined by the user as a parameter. Stores the\
          \ most recent captured value for each day when the data quality check was\
          \ evaluated."
        $ref: "#/definitions/ColumnTextLengthBelowMinLengthPercentCheckSpec"
      daily_text_length_above_max_length:
        description: "The check counts the number of text values in the column that\
          \ is above the length defined by the user as a parameter. Stores the most\
          \ recent captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextLengthAboveMaxLengthCheckSpec"
      daily_text_length_above_max_length_percent:
        description: "The check measures the percentage of text values in the column\
          \ that is above the length defined by the user as a parameter. Stores the\
          \ most recent captured value for each day when the data quality check was\
          \ evaluated."
        $ref: "#/definitions/ColumnTextLengthAboveMaxLengthPercentCheckSpec"
      daily_text_length_in_range_percent:
        description: "The check measures the percentage of those text values with\
          \ length in the range provided by the user in the column. Stores the most\
          \ recent captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextLengthInRangePercentCheckSpec"
  ColumnTextDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_text_min_length:
        description: "This check finds the length of the shortest text in a column.\
          \ Then, it verifies that the minimum length is within an accepted range.\
          \ It detects that the shortest text is too short. Analyzes every daily partition\
          \ and creates a separate data quality check result with the time period\
          \ value that identifies the daily partition."
        $ref: "#/definitions/ColumnTextMinLengthCheckSpec"
      daily_partition_text_max_length:
        description: "This check finds the length of the longest text in a column.\
          \ Then, it verifies that the maximum length is within an accepted range.\
          \ It detects that the texts are too long or not long enough. Analyzes every\
          \ daily partition and creates a separate data quality check result with\
          \ the time period value that identifies the daily partition."
        $ref: "#/definitions/ColumnTextMaxLengthCheckSpec"
      daily_partition_text_mean_length:
        description: "Verifies that the mean (average) length of texts in a column\
          \ is within an accepted range. Analyzes every daily partition and creates\
          \ a separate data quality check result with the time period value that identifies\
          \ the daily partition."
        $ref: "#/definitions/ColumnTextMeanLengthCheckSpec"
      daily_partition_text_length_below_min_length:
        description: "The check counts the number of text values in the column that\
          \ is below the length defined by the user as a parameter. Analyzes every\
          \ daily partition and creates a separate data quality check result with\
          \ the time period value that identifies the daily partition."
        $ref: "#/definitions/ColumnTextLengthBelowMinLengthCheckSpec"
      daily_partition_text_length_below_min_length_percent:
        description: "The check measures the percentage of text values in the column\
          \ that is below the length defined by the user as a parameter. Analyzes\
          \ every daily partition and creates a separate data quality check result\
          \ with the time period value that identifies the daily partition."
        $ref: "#/definitions/ColumnTextLengthBelowMinLengthPercentCheckSpec"
      daily_partition_text_length_above_max_length:
        description: "The check counts the number of text values in the column that\
          \ is above the length defined by the user as a parameter. Analyzes every\
          \ daily partition and creates a separate data quality check result with\
          \ the time period value that identifies the daily partition."
        $ref: "#/definitions/ColumnTextLengthAboveMaxLengthCheckSpec"
      daily_partition_text_length_above_max_length_percent:
        description: "The check measures the percentage of text values in the column\
          \ that is above the length defined by the user as a parameter. Analyzes\
          \ every daily partition and creates a separate data quality check result\
          \ with the time period value that identifies the daily partition."
        $ref: "#/definitions/ColumnTextLengthAboveMaxLengthPercentCheckSpec"
      daily_partition_text_length_in_range_percent:
        description: "The check measures the percentage of those text values with\
          \ length in the range provided by the user in the column. Analyzes every\
          \ daily partition and creates a separate data quality check result with\
          \ the time period value that identifies the daily partition."
        $ref: "#/definitions/ColumnTextLengthInRangePercentCheckSpec"
  ColumnTextFoundInSetPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters that specify a list of expected\
          \ values that are compared to the values in the tested text column."
        $ref: "#/definitions/ColumnAcceptedValuesTextFoundInSetPercentSensorParametersSpec"
      warning:
        description: "Default alerting threshold for a percentage of rows with valid\
          \ values in a column (from a set of expected values). Raises a data quality\
          \ issue with at a warning severity level when the percentage of valid rows\
          \ is below the minimum percentage threshold."
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a percentage of rows with valid\
          \ values in a column (from a set of expected values). Raises a data quality\
          \ issue with at an error severity level when the percentage of valid rows\
          \ is below the minimum percentage threshold."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Default alerting threshold for a percentage of rows with valid\
          \ values in a column (from a set of expected values). Raises a data quality\
          \ issue with at a fatal severity level when the percentage of valid rows\
          \ is below the minimum percentage threshold."
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTextLengthAboveMaxLengthCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextLengthAboveMaxLengthCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ strings with a length above the indicated by the user length in a column\
          \ that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnTextLengthAboveMaxLengthPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextLengthAboveMaxLengthPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of rows\
          \ with strings with a length above the indicated by the user length in a\
          \ column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnTextLengthBelowMinLengthCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextLengthBelowMinLengthCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ strings with a length below the indicated by the user length in a column\
          \ that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnTextLengthBelowMinLengthPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextLengthBelowMinLengthPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of rows\
          \ with strings with a length below the indicated by the user length in a\
          \ column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnTextLengthInRangePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextLengthInRangePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of rows\
          \ with strings with a length in the range indicated by the user in a column\
          \ that raises a data quality error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTextMatchDateFormatPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextMatchDateFormatPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of rows\
          \ with matching date format in a column that raises a data quality error\
          \ (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTextMatchDateFormatPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      date_format:
        type: "string"
        description: "Desired date format. Sensor will try to parse the column records\
          \ and cast the data using this format."
        enum:
        - "DD/MM/YYYY"
        - "DD-MM-YYYY"
        - "DD.MM.YYYY"
        - "YYYY-MM-DD"
  ColumnTextMatchingDatePatternPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPatternsTextMatchingDatePatternPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of rows\
          \ with matching date regex in a column that raises a data quality error\
          \ (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTextMatchingNamePatternPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPatternsTextMatchingNamePatternPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of rows\
          \ with matching name regex in a column that raises a data quality error\
          \ (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTextMaxLengthCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextMaxLengthSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenIntsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ nulls in a column that raises a data quality error (alert)."
        $ref: "#/definitions/BetweenIntsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenIntsRuleParametersSpec"
  ColumnTextMeanLengthCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextMeanLengthSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ nulls in a column that raises a data quality error (alert)."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  ColumnTextMinLengthCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextMinLengthSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenIntsRuleParametersSpec"
      error:
        description: "Default alerting threshold for a minimum length of string in\
          \ a column that raises a data quality error (alert)."
        $ref: "#/definitions/BetweenIntsRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenIntsRuleParametersSpec"
  ColumnTextMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_text_min_length:
        description: "This check finds the length of the shortest text in a column.\
          \ Then, it verifies that the minimum length is within an accepted range.\
          \ It detects that the shortest text is too short. Stores the most recent\
          \ captured value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextMinLengthCheckSpec"
      monthly_text_max_length:
        description: "This check finds the length of the longest text in a column.\
          \ Then, it verifies that the maximum length is within an accepted range.\
          \ It detects that the texts are too long or not long enough. Stores the\
          \ most recent captured value for each month when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnTextMaxLengthCheckSpec"
      monthly_text_mean_length:
        description: "Verifies that the mean (average) length of texts in a column\
          \ is within an accepted range. Stores the most recent captured value for\
          \ each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextMeanLengthCheckSpec"
      monthly_text_length_below_min_length:
        description: "The check counts the number of text values in the column that\
          \ is below the length defined by the user as a parameter. Stores the most\
          \ recent captured value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextLengthBelowMinLengthCheckSpec"
      monthly_text_length_below_min_length_percent:
        description: "The check measures the percentage of text values in the column\
          \ that is below the length defined by the user as a parameter. Stores the\
          \ most recent captured value for each month when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnTextLengthBelowMinLengthPercentCheckSpec"
      monthly_text_length_above_max_length:
        description: "The check counts the number of text values in the column that\
          \ is above the length defined by the user as a parameter. Stores the most\
          \ recent captured value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextLengthAboveMaxLengthCheckSpec"
      monthly_text_length_above_max_length_percent:
        description: "The check measures the percentage of text values in the column\
          \ that is above the length defined by the user as a parameter. Stores the\
          \ most recent captured value for each month when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnTextLengthAboveMaxLengthPercentCheckSpec"
      monthly_text_length_in_range_percent:
        description: "The check measures the percentage of those text values with\
          \ length in the range provided by the user in the column. Stores the most\
          \ recent captured value for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnTextLengthInRangePercentCheckSpec"
  ColumnTextMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_text_min_length:
        description: "This check finds the length of the shortest text in a column.\
          \ Then, it verifies that the minimum length is within an accepted range.\
          \ It detects that the shortest text is too short. Analyzes every monthly\
          \ partition and creates a separate data quality check result with the time\
          \ period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnTextMinLengthCheckSpec"
      monthly_partition_text_max_length:
        description: "This check finds the length of the longest text in a column.\
          \ Then, it verifies that the maximum length is within an accepted range.\
          \ It detects that the texts are too long or not long enough. Analyzes every\
          \ monthly partition and creates a separate data quality check result with\
          \ the time period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnTextMaxLengthCheckSpec"
      monthly_partition_text_mean_length:
        description: "Verifies that the mean (average) length of texts in a column\
          \ is within an accepted range. Analyzes every monthly partition and creates\
          \ a separate data quality check result with the time period value that identifies\
          \ the monthly partition."
        $ref: "#/definitions/ColumnTextMeanLengthCheckSpec"
      monthly_partition_text_length_below_min_length:
        description: "The check counts the number of text values in the column that\
          \ is below the length defined by the user as a parameter. Analyzes every\
          \ monthly partition and creates a separate data quality check result with\
          \ the time period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnTextLengthBelowMinLengthCheckSpec"
      monthly_partition_text_length_below_min_length_percent:
        description: "The check measures the percentage of text values in the column\
          \ that is below the length defined by the user as a parameter. Analyzes\
          \ every monthly partition and creates a separate data quality check result\
          \ with the time period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnTextLengthBelowMinLengthPercentCheckSpec"
      monthly_partition_text_length_above_max_length:
        description: "The check counts the number of text values in the column that\
          \ is above the length defined by the user as a parameter. Analyzes every\
          \ monthly partition and creates a separate data quality check result with\
          \ the time period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnTextLengthAboveMaxLengthCheckSpec"
      monthly_partition_text_length_above_max_length_percent:
        description: "The check measures the percentage of text values in the column\
          \ that is above the length defined by the user as a parameter. Analyzes\
          \ every monthly partition and creates a separate data quality check result\
          \ with the time period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnTextLengthAboveMaxLengthPercentCheckSpec"
      monthly_partition_text_length_in_range_percent:
        description: "The check measures the percentage of those text values with\
          \ length in the range provided by the user in the column. Analyzes every\
          \ monthly partition and creates a separate data quality check result with\
          \ the time period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnTextLengthInRangePercentCheckSpec"
  ColumnTextNotMatchingDatePatternFoundCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPatternsTextNotMatchingDatePatternCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ not matching date regex in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnTextNotMatchingRegexFoundCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPatternsTextNotMatchingRegexCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ not matching regex in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnTextParsableToBooleanPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextParsableToBooleanPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum percentage of rows\
          \ with a boolean placeholder strings in a column that raises a data quality\
          \ error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTextParsableToDatePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextParsableToDatePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ nulls in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTextParsableToFloatPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextParsableToFloatPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum percentage of rows\
          \ with a parsable to float strings in a column that raises a data quality\
          \ error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTextParsableToIntegerPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextParsableToIntegerPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum percentage of rows\
          \ with a parsable to integer strings in a column that raises a data quality\
          \ error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTextProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_text_min_length:
        description: "This check finds the length of the shortest text in a column.\
          \ Then, it verifies that the minimum length is within an accepted range.\
          \ It detects that the shortest text is too short."
        $ref: "#/definitions/ColumnTextMinLengthCheckSpec"
      profile_text_max_length:
        description: "This check finds the length of the longest text in a column.\
          \ Then, it verifies that the maximum length is within an accepted range.\
          \ It detects that the texts are too long or not long enough."
        $ref: "#/definitions/ColumnTextMaxLengthCheckSpec"
      profile_text_mean_length:
        description: "Verifies that the mean (average) length of texts in a column\
          \ is within an accepted range."
        $ref: "#/definitions/ColumnTextMeanLengthCheckSpec"
      profile_text_length_below_min_length:
        description: "The check counts the number of text values in the column that\
          \ is below the length defined by the user as a parameter."
        $ref: "#/definitions/ColumnTextLengthBelowMinLengthCheckSpec"
      profile_text_length_below_min_length_percent:
        description: "The check measures the percentage of text values in the column\
          \ that is below the length defined by the user as a parameter."
        $ref: "#/definitions/ColumnTextLengthBelowMinLengthPercentCheckSpec"
      profile_text_length_above_max_length:
        description: "The check counts the number of text values in the column that\
          \ is above the length defined by the user as a parameter."
        $ref: "#/definitions/ColumnTextLengthAboveMaxLengthCheckSpec"
      profile_text_length_above_max_length_percent:
        description: "The check measures the percentage of text values in the column\
          \ that is above the length defined by the user as a parameter."
        $ref: "#/definitions/ColumnTextLengthAboveMaxLengthPercentCheckSpec"
      profile_text_length_in_range_percent:
        description: "The check measures the percentage of those text values with\
          \ length in the range provided by the user in the column."
        $ref: "#/definitions/ColumnTextLengthInRangePercentCheckSpec"
  ColumnTextStatisticsCollectorsSpec:
    type: "object"
    properties:
      text_max_length:
        description: "Configuration of the profiler that finds the maximum text length."
        $ref: "#/definitions/ColumnTextTextMaxLengthStatisticsCollectorSpec"
      text_mean_length:
        description: "Configuration of the profiler that finds the mean text length."
        $ref: "#/definitions/ColumnTextTextMeanLengthStatisticsCollectorSpec"
      text_min_length:
        description: "Configuration of the profiler that finds the min text length."
        $ref: "#/definitions/ColumnTextTextMinLengthStatisticsCollectorSpec"
      text_datatype_detect:
        description: "Configuration of the profiler that detects datatype."
        $ref: "#/definitions/ColumnTextTextDatatypeDetectStatisticsCollectorSpec"
  ColumnTextTextDatatypeDetectStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnDatatypeStringDatatypeDetectSensorParametersSpec"
  ColumnTextTextLengthAboveMaxLengthCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      max_length:
        type: "integer"
        format: "int32"
        description: "This field can be used to define custom length. In order to\
          \ define custom length, user should write correct length as a integer. If\
          \ length is not defined by user then default length is 0"
  ColumnTextTextLengthAboveMaxLengthPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      max_length:
        type: "integer"
        format: "int32"
        description: "This field can be used to define custom length. In order to\
          \ define custom length, user should write correct length as a integer. If\
          \ length is not defined by user then default length is 0"
  ColumnTextTextLengthBelowMinLengthCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      min_length:
        type: "integer"
        format: "int32"
        description: "This field can be used to define custom length. In order to\
          \ define custom length, user should write correct length as a integer. If\
          \ length is not defined by user then default length is 0"
  ColumnTextTextLengthBelowMinLengthPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      min_length:
        type: "integer"
        format: "int32"
        description: "This field can be used to define custom length. In order to\
          \ define custom length, user should write correct length as a integer. If\
          \ length is not defined by user then default length is 0"
  ColumnTextTextLengthInRangePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      min_length:
        type: "integer"
        format: "int32"
        description: "Sets a minimum text length"
      max_length:
        type: "integer"
        format: "int32"
        description: "Sets a maximum text length"
  ColumnTextTextMaxLengthSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnTextTextMaxLengthStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnTextTextMaxLengthSensorParametersSpec"
  ColumnTextTextMeanLengthSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnTextTextMeanLengthStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnTextTextMeanLengthSensorParametersSpec"
  ColumnTextTextMinLengthSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnTextTextMinLengthStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnTextTextMinLengthSensorParametersSpec"
  ColumnTextTextParsableToBooleanPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnTextTextParsableToDatePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnTextTextParsableToFloatPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnTextTextParsableToIntegerPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnTextTextValidCountryCodePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnTextTextValidCurrencyCodePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnTextValidCountryCodePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextValidCountryCodePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of rows\
          \ with a valid country code strings in a column that raises a data quality\
          \ error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTextValidCurrencyCodePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnTextTextValidCurrencyCodePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of rows\
          \ with a valid currency code strings in a column that raises a data quality\
          \ error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTextsMatchingRegexPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPatternsTextsMatchingRegexPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum percentage of rows\
          \ with matching regex in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnTruePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnBoolTruePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/BetweenPercentRuleParametersSpec"
      error:
        description: "Default alerting threshold for a set percentage of true value\
          \ in a column that raises a data quality error (alert)."
        $ref: "#/definitions/BetweenPercentRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/BetweenPercentRuleParametersSpec"
  ColumnTypeSnapshotSpec:
    type: "object"
    properties:
      column_type:
        type: "string"
        description: "Column data type using the monitored database type names."
      nullable:
        type: "boolean"
        description: "Column is nullable."
      length:
        type: "integer"
        format: "int32"
        description: "Maximum length of text and binary columns."
      precision:
        type: "integer"
        format: "int32"
        description: "Precision of a numeric (decimal) data type."
      scale:
        type: "integer"
        format: "int32"
        description: "Scale of a numeric (decimal) data type."
      nested:
        type: "boolean"
        description: "This field is a nested field inside another STRUCT. It is used\
          \ to identify nested fields in JSON files."
  ColumnUniquenessDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_distinct_count:
        description: "Verifies that the number of distinct values stays within an\
          \ accepted range. Stores the most recent captured value for each day when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnDistinctCountCheckSpec"
      daily_distinct_percent:
        description: "Verifies that the percentage of distinct values in a column\
          \ does not fall below the minimum accepted percent. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnDistinctPercentCheckSpec"
      daily_duplicate_count:
        description: "Verifies that the number of duplicate values in a column does\
          \ not exceed the maximum accepted count. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnDuplicateCountCheckSpec"
      daily_duplicate_percent:
        description: "Verifies that the percentage of duplicate values in a column\
          \ does not exceed the maximum accepted percentage. Stores the most recent\
          \ captured value for each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnDuplicatePercentCheckSpec"
      daily_distinct_count_anomaly:
        description: "Verifies that the distinct count in a monitored column is within\
          \ a two-tailed percentile from measurements made during the last 90 days."
        $ref: "#/definitions/ColumnDistinctCountAnomalyDifferencingCheckSpec"
      daily_distinct_percent_anomaly:
        description: "Verifies that the distinct percent in a monitored column is\
          \ within a two-tailed percentile from measurements made during the last\
          \ 90 days."
        $ref: "#/definitions/ColumnDistinctPercentAnomalyStationaryCheckSpec"
      daily_distinct_count_change:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout."
        $ref: "#/definitions/ColumnDistinctCountChangeCheckSpec"
      daily_distinct_percent_change:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout."
        $ref: "#/definitions/ColumnDistinctPercentChangeCheckSpec"
      daily_distinct_count_change_1_day:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout from yesterday."
        $ref: "#/definitions/ColumnDistinctCountChange1DayCheckSpec"
      daily_distinct_count_change_7_days:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout from last week."
        $ref: "#/definitions/ColumnDistinctCountChange7DaysCheckSpec"
      daily_distinct_count_change_30_days:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout from last month."
        $ref: "#/definitions/ColumnDistinctCountChange30DaysCheckSpec"
      daily_distinct_percent_change_1_day:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout from yesterday."
        $ref: "#/definitions/ColumnDistinctPercentChange1DayCheckSpec"
      daily_distinct_percent_change_7_days:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout from last week."
        $ref: "#/definitions/ColumnDistinctPercentChange7DaysCheckSpec"
      daily_distinct_percent_change_30_days:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout from last month."
        $ref: "#/definitions/ColumnDistinctPercentChange30DaysCheckSpec"
  ColumnUniquenessDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_distinct_count:
        description: "Verifies  that the number of distinct values stays within an\
          \ accepted range. Stores a separate data quality check result for each daily\
          \ partition."
        $ref: "#/definitions/ColumnDistinctCountCheckSpec"
      daily_partition_distinct_percent:
        description: "Verifies that the percentage of distinct values in a column\
          \ does not fall below the minimum accepted percent. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/ColumnDistinctPercentCheckSpec"
      daily_partition_duplicate_count:
        description: "Verifies that the number of duplicate values in a column does\
          \ not exceed the maximum accepted count. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnDuplicateCountCheckSpec"
      daily_partition_duplicate_percent:
        description: "Verifies that the percent of duplicate values in a column does\
          \ not exceed the maximum accepted percent. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/ColumnDuplicatePercentCheckSpec"
      daily_partition_distinct_count_anomaly:
        description: "Verifies that the distinct count in a monitored column is within\
          \ a two-tailed percentile from measurements made during the last 90 days."
        $ref: "#/definitions/ColumnDistinctCountAnomalyStationaryPartitionCheckSpec"
      daily_partition_distinct_percent_anomaly:
        description: "Verifies that the distinct percent in a monitored column is\
          \ within a two-tailed percentile from measurements made during the last\
          \ 90 days."
        $ref: "#/definitions/ColumnDistinctPercentAnomalyStationaryCheckSpec"
      daily_partition_distinct_count_change:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout."
        $ref: "#/definitions/ColumnDistinctCountChangeCheckSpec"
      daily_partition_distinct_percent_change:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout."
        $ref: "#/definitions/ColumnDistinctPercentChangeCheckSpec"
      daily_partition_distinct_count_change_1_day:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout from yesterday."
        $ref: "#/definitions/ColumnDistinctCountChange1DayCheckSpec"
      daily_partition_distinct_count_change_7_days:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout from the last week."
        $ref: "#/definitions/ColumnDistinctCountChange7DaysCheckSpec"
      daily_partition_distinct_count_change_30_days:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout from the last month."
        $ref: "#/definitions/ColumnDistinctCountChange30DaysCheckSpec"
      daily_partition_distinct_percent_change_1_day:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout from yesterday."
        $ref: "#/definitions/ColumnDistinctPercentChange1DayCheckSpec"
      daily_partition_distinct_percent_change_7_days:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout from the last week."
        $ref: "#/definitions/ColumnDistinctPercentChange7DaysCheckSpec"
      daily_partition_distinct_percent_change_30_days:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout from the last month."
        $ref: "#/definitions/ColumnDistinctPercentChange30DaysCheckSpec"
  ColumnUniquenessDistinctCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnUniquenessDistinctCountStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctCountSensorParametersSpec"
  ColumnUniquenessDistinctPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnUniquenessDistinctPercentStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnUniquenessDistinctPercentSensorParametersSpec"
  ColumnUniquenessDuplicateCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnUniquenessDuplicateCountStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnUniquenessDuplicateCountSensorParametersSpec"
  ColumnUniquenessDuplicatePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnUniquenessDuplicatePercentStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/ColumnUniquenessDuplicatePercentSensorParametersSpec"
  ColumnUniquenessMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_distinct_count:
        description: "Verifies  that the number of distinct values stays within an\
          \ accepted range. Stores the most recent check result for each month when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnDistinctCountCheckSpec"
      monthly_distinct_percent:
        description: "Verifies that the percentage of distinct values in a column\
          \ does not fall below the minimum accepted percent. Stores the most recent\
          \ check result for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnDistinctPercentCheckSpec"
      monthly_duplicate_count:
        description: "Verifies that the number of duplicate values in a column does\
          \ not exceed the maximum accepted count. Stores the most recent check result\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnDuplicateCountCheckSpec"
      monthly_duplicate_percent:
        description: "Verifies that the percentage of duplicate values in a column\
          \ does not exceed the maximum accepted percentage. Stores the most recent\
          \ check result for each month when the data quality check was evaluated."
        $ref: "#/definitions/ColumnDuplicatePercentCheckSpec"
      monthly_distinct_count_change:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout."
        $ref: "#/definitions/ColumnDistinctCountChangeCheckSpec"
      monthly_distinct_percent_change:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout."
        $ref: "#/definitions/ColumnDistinctPercentChangeCheckSpec"
  ColumnUniquenessMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_distinct_count:
        description: "Verifies  that the number of distinct values stays within an\
          \ accepted range. Stores a separate data quality check result for each monthly\
          \ partition."
        $ref: "#/definitions/ColumnDistinctCountCheckSpec"
      monthly_partition_distinct_percent:
        description: "Verifies that the percentage of distinct values in a column\
          \ does not fall below the minimum accepted percent. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/ColumnDistinctPercentCheckSpec"
      monthly_partition_duplicate_count:
        description: "Verifies that the number of duplicate values in a column does\
          \ not exceed the maximum accepted count. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnDuplicateCountCheckSpec"
      monthly_partition_duplicate_percent:
        description: "Verifies that the percent of duplicate values in a column does\
          \ not exceed the maximum accepted percent. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/ColumnDuplicatePercentCheckSpec"
      monthly_partition_distinct_count_change:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout."
        $ref: "#/definitions/ColumnDistinctCountChangeCheckSpec"
      monthly_partition_distinct_percent_change:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout."
        $ref: "#/definitions/ColumnDistinctPercentChangeCheckSpec"
  ColumnUniquenessProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_distinct_count:
        description: "Verifies that the number of distinct values stays within an\
          \ accepted range."
        $ref: "#/definitions/ColumnDistinctCountCheckSpec"
      profile_distinct_percent:
        description: "Verifies that the percentage of distinct values in a column\
          \ does not fall below the minimum accepted percent."
        $ref: "#/definitions/ColumnDistinctPercentCheckSpec"
      profile_duplicate_count:
        description: "Verifies that the number of duplicate values in a column does\
          \ not exceed the maximum accepted count."
        $ref: "#/definitions/ColumnDuplicateCountCheckSpec"
      profile_duplicate_percent:
        description: "Verifies that the percentage of duplicate values in a column\
          \ does not exceed the maximum accepted percentage."
        $ref: "#/definitions/ColumnDuplicatePercentCheckSpec"
      profile_distinct_count_anomaly:
        description: "Verifies that the distinct count in a monitored column is within\
          \ a two-tailed percentile from measurements made during the last 90 days."
        $ref: "#/definitions/ColumnDistinctCountAnomalyDifferencingCheckSpec"
      profile_distinct_percent_anomaly:
        description: "Verifies that the distinct percent in a monitored column is\
          \ within a two-tailed percentile from measurements made during the last\
          \ 90 days."
        $ref: "#/definitions/ColumnDistinctPercentAnomalyStationaryCheckSpec"
      profile_distinct_count_change:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout."
        $ref: "#/definitions/ColumnDistinctCountChangeCheckSpec"
      profile_distinct_percent_change:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout."
        $ref: "#/definitions/ColumnDistinctPercentChangeCheckSpec"
      profile_distinct_count_change_1_day:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout from yesterday."
        $ref: "#/definitions/ColumnDistinctCountChange1DayCheckSpec"
      profile_distinct_count_change_7_days:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout from last week."
        $ref: "#/definitions/ColumnDistinctCountChange7DaysCheckSpec"
      profile_distinct_count_change_30_days:
        description: "Verifies that the distinct count in a monitored column has changed\
          \ by a fixed rate since the last readout from last month."
        $ref: "#/definitions/ColumnDistinctCountChange30DaysCheckSpec"
      profile_distinct_percent_change_1_day:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout from yesterday."
        $ref: "#/definitions/ColumnDistinctPercentChange1DayCheckSpec"
      profile_distinct_percent_change_7_days:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout from last week."
        $ref: "#/definitions/ColumnDistinctPercentChange7DaysCheckSpec"
      profile_distinct_percent_change_30_days:
        description: "Verifies that the distinct percent in a monitored column has\
          \ changed by a fixed rate since the last readout from last month."
        $ref: "#/definitions/ColumnDistinctPercentChange30DaysCheckSpec"
  ColumnUniquenessStatisticsCollectorsSpec:
    type: "object"
    properties:
      distinct_count:
        description: "Configuration of the profiler that counts distinct column values."
        $ref: "#/definitions/ColumnUniquenessDistinctCountStatisticsCollectorSpec"
      distinct_percent:
        description: "Configuration of the profiler that measure the percentage of\
          \ distinct column values."
        $ref: "#/definitions/ColumnUniquenessDistinctPercentStatisticsCollectorSpec"
      duplicate_count:
        description: "Configuration of the profiler that counts duplicate column values."
        $ref: "#/definitions/ColumnUniquenessDuplicateCountStatisticsCollectorSpec"
      duplicate_percent:
        description: "Configuration of the profiler that measure the percentage of\
          \ duplicate column values."
        $ref: "#/definitions/ColumnUniquenessDuplicatePercentStatisticsCollectorSpec"
  ColumnValidLatitudePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericValidLatitudePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set percentage of rows with\
          \ valid latitude value in a column that raises a data quality alert"
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnValidLongitudePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnNumericValidLongitudePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a set percentage of rows with\
          \ valid longitude value in a column that raises a data quality alert"
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnValidUuidFormatPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnPatternsValidUuidFormatPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum percentage of rows\
          \ with a valid UUID in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  ColumnWhitespaceBlankNullPlaceholderTextCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnWhitespaceBlankNullPlaceholderTextPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnWhitespaceDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_empty_text_found:
        description: "Detects empty texts (not null, zero-length texts). This check\
          \ counts empty and raises a data quality issue when their count exceeds\
          \ a *max_count* parameter value. Stores the most recent captured value for\
          \ each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceEmptyTextFoundCheckSpec"
      daily_whitespace_text_found:
        description: "Detects texts that contain only spaces and other whitespace\
          \ characters. It raises a data quality issue when their count exceeds a\
          \ *max_count* parameter value. Stores the most recent captured value for\
          \ each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextFoundCheckSpec"
      daily_null_placeholder_text_found:
        description: "Detects texts that are well-known placeholders of null values,\
          \ such as *None*, *null*, *n/a*. It counts null placeholders and raises\
          \ a data quality issue when their count exceeds a *max_count* parameter\
          \ value. Stores the most recent captured value for each day when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceNullPlaceholderTextFoundCheckSpec"
      daily_empty_text_percent:
        description: "Detects empty texts (not null, zero-length texts) and measures\
          \ their percentage in the column. This check verifies that the rate of empty\
          \ strings in a column does not exceed the maximum accepted percentage. Stores\
          \ the most recent captured value for each day when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnWhitespaceEmptyTextPercentCheckSpec"
      daily_whitespace_text_percent:
        description: "Detects texts that contain only spaces and other whitespace\
          \ characters and measures their percentage in the column. It raises a data\
          \ quality issue when their rate exceeds a *max_percent* parameter value.\
          \ Stores the most recent captured value for each day when the data quality\
          \ check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextPercentCheckSpec"
      daily_null_placeholder_text_percent:
        description: "Detects texts that are well-known placeholders of null values,\
          \ such as *None*, *null*, *n/a*, and measures their percentage in the column.\
          \ It raises a data quality issue when their rate exceeds a *max_percent*\
          \ parameter value. Stores the most recent captured value for each day when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceNullPlaceholderTextPercentCheckSpec"
      daily_text_surrounded_by_whitespace_found:
        description: "Detects text values that are surrounded by whitespace characters\
          \ on any side. This check counts whitespace-surrounded texts and raises\
          \ a data quality issue when their count exceeds the *max_count* parameter\
          \ value. Stores the most recent captured value for each day when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespaceFoundCheckSpec"
      daily_text_surrounded_by_whitespace_percent:
        description: "This check detects text values that are surrounded by whitespace\
          \ characters on any side and measures their percentage. This check raises\
          \ a data quality issue when their percentage exceeds the *max_percent* parameter\
          \ value. Stores the most recent captured value for each day when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespacePercentCheckSpec"
  ColumnWhitespaceDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_empty_text_found:
        description: "Detects empty texts (not null, zero-length texts). This check\
          \ counts empty and raises a data quality issue when their count exceeds\
          \ a *max_count* parameter value. Stores a separate data quality check result\
          \ for each daily partition."
        $ref: "#/definitions/ColumnWhitespaceEmptyTextFoundCheckSpec"
      daily_partition_whitespace_text_found:
        description: "Detects texts that contain only spaces and other whitespace\
          \ characters. It raises a data quality issue when their count exceeds a\
          \ *max_count* parameter value. Stores a separate data quality check result\
          \ for each daily partition."
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextFoundCheckSpec"
      daily_partition_null_placeholder_text_found:
        description: "Detects texts that are well-known placeholders of null values,\
          \ such as *None*, *null*, *n/a*. It counts null placeholders and raises\
          \ a data quality issue when their count exceeds a *max_count* parameter\
          \ value. Stores a separate data quality check result for each daily partition."
        $ref: "#/definitions/ColumnWhitespaceNullPlaceholderTextFoundCheckSpec"
      daily_partition_empty_text_percent:
        description: "Detects empty texts (not null, zero-length texts) and measures\
          \ their percentage in the column. This check verifies that the rate of empty\
          \ strings in a column does not exceed the maximum accepted percentage. Stores\
          \ a separate data quality check result for each daily partition."
        $ref: "#/definitions/ColumnWhitespaceEmptyTextPercentCheckSpec"
      daily_partition_whitespace_text_percent:
        description: "Detects texts that contain only spaces and other whitespace\
          \ characters and measures their percentage in the column. It raises a data\
          \ quality issue when their rate exceeds a *max_percent* parameter value.\
          \ Stores a separate data quality check result for each daily partition."
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextPercentCheckSpec"
      daily_partition_null_placeholder_text_percent:
        description: "Detects texts that are well-known placeholders of null values,\
          \ such as *None*, *null*, *n/a*, and measures their percentage in the column.\
          \ It raises a data quality issue when their rate exceeds a *max_percent*\
          \ parameter value. Stores a separate data quality check result for each\
          \ daily partition."
        $ref: "#/definitions/ColumnWhitespaceNullPlaceholderTextPercentCheckSpec"
      daily_partition_text_surrounded_by_whitespace_found:
        description: "Detects text values that are surrounded by whitespace characters\
          \ on any side. This check counts whitespace-surrounded texts and raises\
          \ a data quality issue when their count exceeds the *max_count* parameter\
          \ value. Analyzes every daily partition and creates a separate data quality\
          \ check result with the time period value that identifies the daily partition."
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespaceFoundCheckSpec"
      daily_partition_text_surrounded_by_whitespace_percent:
        description: "This check detects text values that are surrounded by whitespace\
          \ characters on any side and measures their percentage. This check raises\
          \ a data quality issue when their percentage exceeds the *max_percent* parameter\
          \ value. Analyzes every daily partition and creates a separate data quality\
          \ check result with the time period value that identifies the daily partition."
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespacePercentCheckSpec"
  ColumnWhitespaceEmptyTextCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnWhitespaceEmptyTextFoundCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnWhitespaceEmptyTextCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ empty strings in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnWhitespaceEmptyTextPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnWhitespaceEmptyTextPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ empty strings in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnWhitespaceEmptyTextPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnWhitespaceMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_empty_text_found:
        description: "Detects empty texts (not null, zero-length texts). This check\
          \ counts empty and raises a data quality issue when their count exceeds\
          \ a *max_count* parameter value. Stores the most recent captured value for\
          \ each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceEmptyTextFoundCheckSpec"
      monthly_whitespace_text_found:
        description: "Detects texts that contain only spaces and other whitespace\
          \ characters. It raises a data quality issue when their count exceeds a\
          \ *max_count* parameter value. Stores the most recent captured value for\
          \ each day when the data quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextFoundCheckSpec"
      monthly_null_placeholder_text_found:
        description: "Detects texts that are well-known placeholders of null values,\
          \ such as *None*, *null*, *n/a*. It counts null placeholders and raises\
          \ a data quality issue when their count exceeds a *max_count* parameter\
          \ value. Stores the most recent captured value for each day when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceNullPlaceholderTextFoundCheckSpec"
      monthly_empty_text_percent:
        description: "Detects empty texts (not null, zero-length texts) and measures\
          \ their percentage in the column. This check verifies that the rate of empty\
          \ strings in a column does not exceed the maximum accepted percentage. Stores\
          \ the most recent captured value for each day when the data quality check\
          \ was evaluated."
        $ref: "#/definitions/ColumnWhitespaceEmptyTextPercentCheckSpec"
      monthly_whitespace_text_percent:
        description: "Detects texts that contain only spaces and other whitespace\
          \ characters and measures their percentage in the column. It raises a data\
          \ quality issue when their rate exceeds a *max_percent* parameter value.\
          \ Stores the most recent captured value for each day when the data quality\
          \ check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextPercentCheckSpec"
      monthly_null_placeholder_text_percent:
        description: "Detects texts that are well-known placeholders of null values,\
          \ such as *None*, *null*, *n/a*, and measures their percentage in the column.\
          \ It raises a data quality issue when their rate exceeds a *max_percent*\
          \ parameter value. Stores the most recent captured value for each day when\
          \ the data quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceNullPlaceholderTextPercentCheckSpec"
      monthly_text_surrounded_by_whitespace_found:
        description: "Detects text values that are surrounded by whitespace characters\
          \ on any side. This check counts whitespace-surrounded texts and raises\
          \ a data quality issue when their count exceeds the *max_count* parameter\
          \ value. Stores the most recent captured value for each month when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespaceFoundCheckSpec"
      monthly_text_surrounded_by_whitespace_percent:
        description: "This check detects text values that are surrounded by whitespace\
          \ characters on any side and measures their percentage. This check raises\
          \ a data quality issue when their percentage exceeds the *max_percent* parameter\
          \ value. Stores the most recent captured value for each month when the data\
          \ quality check was evaluated."
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespacePercentCheckSpec"
  ColumnWhitespaceMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_empty_text_found:
        description: "Detects empty texts (not null, zero-length texts). This check\
          \ counts empty and raises a data quality issue when their count exceeds\
          \ a *max_count* parameter value. Stores a separate data quality check result\
          \ for each monthly partition."
        $ref: "#/definitions/ColumnWhitespaceEmptyTextFoundCheckSpec"
      monthly_partition_whitespace_text_found:
        description: "Detects texts that contain only spaces and other whitespace\
          \ characters. It raises a data quality issue when their count exceeds a\
          \ *max_count* parameter value. Stores a separate data quality check result\
          \ for each monthly partition."
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextFoundCheckSpec"
      monthly_partition_null_placeholder_text_found:
        description: "Detects texts that are well-known placeholders of null values,\
          \ such as *None*, *null*, *n/a*. It counts null placeholders and raises\
          \ a data quality issue when their count exceeds a *max_count* parameter\
          \ value. Stores a separate data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnWhitespaceNullPlaceholderTextFoundCheckSpec"
      monthly_partition_empty_text_percent:
        description: "Detects empty texts (not null, zero-length texts) and measures\
          \ their percentage in the column. This check verifies that the rate of empty\
          \ strings in a column does not exceed the maximum accepted percentage. Stores\
          \ a separate data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnWhitespaceEmptyTextPercentCheckSpec"
      monthly_partition_whitespace_text_percent:
        description: "Detects texts that contain only spaces and other whitespace\
          \ characters and measures their percentage in the column. It raises a data\
          \ quality issue when their rate exceeds a *max_percent* parameter value.\
          \ Stores a separate data quality check result for each monthly partition."
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextPercentCheckSpec"
      monthly_partition_null_placeholder_text_percent:
        description: "Detects texts that are well-known placeholders of null values,\
          \ such as *None*, *null*, *n/a*, and measures their percentage in the column.\
          \ It raises a data quality issue when their rate exceeds a *max_percent*\
          \ parameter value. Stores a separate data quality check result for each\
          \ monthly partition."
        $ref: "#/definitions/ColumnWhitespaceNullPlaceholderTextPercentCheckSpec"
      monthly_partition_text_surrounded_by_whitespace_found:
        description: "Detects text values that are surrounded by whitespace characters\
          \ on any side. This check counts whitespace-surrounded texts and raises\
          \ a data quality issue when their count exceeds the *max_count* parameter\
          \ value. Analyzes every monthly partition and creates a separate data quality\
          \ check result with the time period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespaceFoundCheckSpec"
      monthly_partition_text_surrounded_by_whitespace_percent:
        description: "This check detects text values that are surrounded by whitespace\
          \ characters on any side and measures their percentage. This check raises\
          \ a data quality issue when their percentage exceeds the *max_percent* parameter\
          \ value. Analyzes every monthly partition and creates a separate data quality\
          \ check result with the time period value that identifies the monthly partition."
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespacePercentCheckSpec"
  ColumnWhitespaceNullPlaceholderTextFoundCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnWhitespaceBlankNullPlaceholderTextCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ a null placeholder strings in a column that raises a data quality error\
          \ (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnWhitespaceNullPlaceholderTextPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnWhitespaceBlankNullPlaceholderTextPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of rows\
          \ with a null placeholder strings in a column that raises a data quality\
          \ error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnWhitespaceProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_empty_text_found:
        description: "Detects empty texts (not null, zero-length texts). This check\
          \ counts empty and raises a data quality issue when their count exceeds\
          \ a *max_count* parameter value."
        $ref: "#/definitions/ColumnWhitespaceEmptyTextFoundCheckSpec"
      profile_whitespace_text_found:
        description: "Detects texts that contain only spaces and other whitespace\
          \ characters. It raises a data quality issue when their count exceeds a\
          \ *max_count* parameter value."
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextFoundCheckSpec"
      profile_null_placeholder_text_found:
        description: "Detects texts that are well-known placeholders of null values,\
          \ such as *None*, *null*, *n/a*. It counts null placeholders and raises\
          \ a data quality issue when their count exceeds a *max_count* parameter\
          \ value."
        $ref: "#/definitions/ColumnWhitespaceNullPlaceholderTextFoundCheckSpec"
      profile_empty_text_percent:
        description: "Detects empty texts (not null, zero-length texts) and measures\
          \ their percentage in the column. This check verifies that the rate of empty\
          \ strings in a column does not exceed the maximum accepted percentage. This\
          \ check verifies that the rate of empty strings in a column does not exceed\
          \ the maximum accepted percentage."
        $ref: "#/definitions/ColumnWhitespaceEmptyTextPercentCheckSpec"
      profile_whitespace_text_percent:
        description: "Detects texts that contain only spaces and other whitespace\
          \ characters and measures their percentage in the column. It raises a data\
          \ quality issue when their rate exceeds a *max_percent* parameter value."
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextPercentCheckSpec"
      profile_null_placeholder_text_percent:
        description: "Detects texts that are well-known placeholders of null values,\
          \ such as *None*, *null*, *n/a*, and measures their percentage in the column.\
          \ It raises a data quality issue when their rate exceeds a *max_percent*\
          \ parameter value."
        $ref: "#/definitions/ColumnWhitespaceNullPlaceholderTextPercentCheckSpec"
      profile_text_surrounded_by_whitespace_found:
        description: "Detects text values that are surrounded by whitespace characters\
          \ on any side. This check counts whitespace-surrounded texts and raises\
          \ a data quality issue when their count exceeds the *max_count* parameter\
          \ value."
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespaceFoundCheckSpec"
      profile_text_surrounded_by_whitespace_percent:
        description: "This check detects text values that are surrounded by whitespace\
          \ characters on any side and measures their percentage. This check raises\
          \ a data quality issue when their percentage exceeds the *max_percent* parameter\
          \ value."
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespacePercentCheckSpec"
  ColumnWhitespaceTextSurroundedByWhitespaceCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnWhitespaceTextSurroundedByWhitespaceFoundCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespaceCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ surrounded by whitespace strings in a column that raises a data quality\
          \ error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnWhitespaceTextSurroundedByWhitespacePercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnWhitespaceTextSurroundedByWhitespacePercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ surrounded by whitespace strings in a column that raises a data quality\
          \ error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnWhitespaceTextSurroundedByWhitespacePercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnWhitespaceWhitespaceTextCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  ColumnWhitespaceWhitespaceTextFoundCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ whitespace strings in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  ColumnWhitespaceWhitespaceTextPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/ColumnWhitespaceWhitespaceTextPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxPercentRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows with\
          \ whitespace strings in a column that raises a data quality error (alert)."
        $ref: "#/definitions/MaxPercentRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxPercentRule5ParametersSpec"
  ColumnWhitespaceWhitespaceTextPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  CommentSpec:
    type: "object"
    properties:
      date:
        type: "string"
        format: "date-time"
        description: "Comment date and time"
      comment_by:
        type: "string"
        description: "Commented by"
      comment:
        type: "string"
        description: "Comment text"
  CommonColumnModel:
    type: "object"
    properties:
      column_name:
        type: "string"
        description: "Column name."
      tables_count:
        type: "integer"
        format: "int32"
        description: "Count of tables that are have a column with this name."
    description: "Common column model that describes a column name that is frequently\
      \ used in tables within a connection"
  CompareThresholdsModel:
    type: "object"
    properties:
      warning_difference_percent:
        type: "number"
        format: "double"
        description: "The percentage difference between the measure value on the compared\
          \ table and the reference table that raises a warning severity data quality\
          \ issue when the difference is bigger."
      error_difference_percent:
        type: "number"
        format: "double"
        description: "The percentage difference between the measure value on the compared\
          \ table and the reference table that raises an error severity data quality\
          \ issue when the difference is bigger."
      fatal_difference_percent:
        type: "number"
        format: "double"
        description: "The percentage difference between the measure value on the compared\
          \ table and the reference table that raises a fatal severity data quality\
          \ issue when the difference is bigger."
    description: "Model with the compare threshold levels for raising data quality\
      \ issues at different severity levels when the difference between the compared\
      \ (tested) table and the reference table (the source of truth) exceed given\
      \ thresholds as a percentage of difference between the actual value and the\
      \ expected value from the reference table."
  ComparisonCheckResultModel:
    type: "object"
    properties:
      check_name:
        type: "string"
        description: "DQOps data quality check name."
      executed_at:
        type: "integer"
        format: "int64"
        description: "The timestamp when the check was executed."
      valid_results:
        type: "integer"
        format: "int32"
        description: "The number of data groups that were compared and the values\
          \ matched within the accepted error margin for all check severity levels."
      warnings:
        type: "integer"
        format: "int32"
        description: "The number of data groups that were compared and the values\
          \ did not match, raising a warning severity level data quality issue."
      errors:
        type: "integer"
        format: "int32"
        description: "The number of data groups that were compared and the values\
          \ did not match, raising an error severity level data quality issue."
      fatals:
        type: "integer"
        format: "int32"
        description: "The number of data groups that were compared and the values\
          \ did not match, raising a fatal severity level data quality issue."
      execution_errors:
        type: "integer"
        format: "int32"
        description: "The number of execution errors in the check or rule that prevented\
          \ comparing the tables."
      not_matching_data_groups:
        type: "array"
        description: "A list of not matching data grouping names."
        items:
          type: "string"
    description: "The table comparison check result model for the most recent data\
      \ comparison run. Identifies the check name and the number of data groupings\
      \ that passed or failed the comparison."
  ConnectionIncidentGroupingSpec:
    type: "object"
    properties:
      grouping_level:
        type: "string"
        description: "Grouping level of failed data quality checks for creating higher\
          \ level data quality incidents. The default grouping level is by a table,\
          \ a data quality dimension and a check category (i.e. a datatype data quality\
          \ incident detected on a table X in the numeric checks category)."
        enum:
        - "table"
        - "table_dimension"
        - "table_dimension_category"
        - "table_dimension_category_type"
        - "table_dimension_category_name"
      minimum_severity:
        type: "string"
        description: "Minimum severity level of data quality issues that are grouped\
          \ into incidents. The default minimum severity level is 'warning'. Other\
          \ supported severity levels are 'error' and 'fatal'."
        enum:
        - "warning"
        - "error"
        - "fatal"
      divide_by_data_groups:
        type: "boolean"
        description: "Create separate data quality incidents for each data group,\
          \ creating different incidents for different groups of rows. By default,\
          \ data groups are ignored for grouping data quality issues into data quality\
          \ incidents."
      max_incident_length_days:
        type: "integer"
        format: "int32"
        description: "The maximum length of a data quality incident in days. When\
          \ a new data quality issue is detected after max_incident_length_days days\
          \ since a similar data quality was first seen, a new data quality incident\
          \ is created that will capture all following data quality issues for the\
          \ next max_incident_length_days days. The default value is 60 days."
      mute_for_days:
        type: "integer"
        format: "int32"
        description: "The number of days that all similar data quality issues are\
          \ muted when a a data quality incident is closed in the 'mute' status."
      disabled:
        type: "boolean"
        description: "Disables data quality incident creation for failed data quality\
          \ checks on the data source."
      webhooks:
        description: "Configuration of Webhook URLs for new or updated incident notifications."
        $ref: "#/definitions/IncidentWebhookNotificationsSpec"
  ConnectionModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      connection_hash:
        type: "integer"
        format: "int64"
        description: "Connection hash that identifies the connection using a unique\
          \ hash code."
      parallel_jobs_limit:
        type: "integer"
        format: "int32"
        description: "The concurrency limit for the maximum number of parallel SQL\
          \ queries executed on this connection."
      provider_type:
        type: "string"
        description: "Database provider type (required). Accepts: bigquery, snowflake,\
          \ etc."
        enum:
        - "bigquery"
        - "databricks"
        - "mysql"
        - "oracle"
        - "postgresql"
        - "duckdb"
        - "presto"
        - "redshift"
        - "snowflake"
        - "spark"
        - "sqlserver"
        - "trino"
      bigquery:
        description: "BigQuery connection parameters. Specify parameters in the bigquery\
          \ section."
        $ref: "#/definitions/BigQueryParametersSpec"
      snowflake:
        description: "Snowflake connection parameters."
        $ref: "#/definitions/SnowflakeParametersSpec"
      postgresql:
        description: "PostgreSQL connection parameters."
        $ref: "#/definitions/PostgresqlParametersSpec"
      duckdb:
        description: "DuckDB connection parameters."
        $ref: "#/definitions/DuckdbParametersSpec"
      redshift:
        description: "Redshift connection parameters."
        $ref: "#/definitions/RedshiftParametersSpec"
      sqlserver:
        description: "SqlServer connection parameters."
        $ref: "#/definitions/SqlServerParametersSpec"
      presto:
        description: "Presto connection parameters."
        $ref: "#/definitions/PrestoParametersSpec"
      trino:
        description: "Trino connection parameters."
        $ref: "#/definitions/TrinoParametersSpec"
      mysql:
        description: "MySQL connection parameters."
        $ref: "#/definitions/MysqlParametersSpec"
      oracle:
        description: "Oracle connection parameters."
        $ref: "#/definitions/OracleParametersSpec"
      spark:
        description: "Spark connection parameters."
        $ref: "#/definitions/SparkParametersSpec"
      databricks:
        description: "Databricks connection parameters."
        $ref: "#/definitions/DatabricksParametersSpec"
      run_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run all checks within this connection."
        $ref: "#/definitions/CheckSearchFilters"
      run_profiling_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run profiling checks within this\
          \ connection."
        $ref: "#/definitions/CheckSearchFilters"
      run_monitoring_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run monitoring checks within this\
          \ connection."
        $ref: "#/definitions/CheckSearchFilters"
      run_partition_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run partition partitioned checks\
          \ within this connection."
        $ref: "#/definitions/CheckSearchFilters"
      collect_statistics_job_template:
        description: "Configured parameters for the \"collect statistics\" job that\
          \ should be pushed to the job queue in order to run all statistics collectors\
          \ within this connection."
        $ref: "#/definitions/StatisticsCollectorSearchFilters"
      data_clean_job_template:
        description: "Configured parameters for the \"data clean\" job that after\
          \ being supplied with a time range should be pushed to the job queue in\
          \ order to remove stored results connected with this connection."
        $ref: "#/definitions/DeleteStoredDataQueueJobParameters"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete the connection to the data source."
      can_collect_statistics:
        type: "boolean"
        description: "Boolean flag that decides if the current user can collect statistics."
      can_run_checks:
        type: "boolean"
        description: "Boolean flag that decides if the current user can run checks."
      can_delete_data:
        type: "boolean"
        description: "Boolean flag that decides if the current user can delete data\
          \ (results)."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Connection model for with a subset of parameters, excluding all\
      \ nested objects."
  ConnectionSpec:
    type: "object"
    properties:
      provider_type:
        type: "string"
        description: "Database provider type (required)."
        enum:
        - "bigquery"
        - "databricks"
        - "mysql"
        - "oracle"
        - "postgresql"
        - "duckdb"
        - "presto"
        - "redshift"
        - "snowflake"
        - "spark"
        - "sqlserver"
        - "trino"
      bigquery:
        description: "BigQuery connection parameters. Specify parameters in the bigquery\
          \ section."
        $ref: "#/definitions/BigQueryParametersSpec"
      snowflake:
        description: "Snowflake connection parameters. Specify parameters in the snowflake\
          \ section or set the url (which is the Snowflake JDBC url)."
        $ref: "#/definitions/SnowflakeParametersSpec"
      postgresql:
        description: "PostgreSQL connection parameters. Specify parameters in the\
          \ postgresql section or set the url (which is the PostgreSQL JDBC url)."
        $ref: "#/definitions/PostgresqlParametersSpec"
      duckdb:
        description: "DuckDB connection parameters. Specify parameters in the duckdb\
          \ section or set the url (which is the DuckDB JDBC url)."
        $ref: "#/definitions/DuckdbParametersSpec"
      redshift:
        description: "Redshift connection parameters. Specify parameters in the redshift\
          \ section or set the url (which is the Redshift JDBC url)."
        $ref: "#/definitions/RedshiftParametersSpec"
      sqlserver:
        description: "SQL Server connection parameters. Specify parameters in the\
          \ sqlserver section or set the url (which is the SQL Server JDBC url)."
        $ref: "#/definitions/SqlServerParametersSpec"
      presto:
        description: "Presto connection parameters. Specify parameters in the presto\
          \ section or set the url (which is the Presto JDBC url)."
        $ref: "#/definitions/PrestoParametersSpec"
      trino:
        description: "Trino connection parameters. Specify parameters in the trino\
          \ section or set the url (which is the Trino JDBC url)."
        $ref: "#/definitions/TrinoParametersSpec"
      mysql:
        description: "MySQL connection parameters. Specify parameters in the mysql\
          \ section or set the url (which is the MySQL JDBC url)."
        $ref: "#/definitions/MysqlParametersSpec"
      oracle:
        description: "Oracle connection parameters. Specify parameters in the oracle\
          \ section or set the url (which is the Oracle JDBC url)."
        $ref: "#/definitions/OracleParametersSpec"
      spark:
        description: "Spark connection parameters. Specify parameters in the spark\
          \ section or set the url (which is the Spark JDBC url)."
        $ref: "#/definitions/SparkParametersSpec"
      databricks:
        description: "Databricks connection parameters. Specify parameters in the\
          \ databricks section or set the url (which is the Databricks JDBC url)."
        $ref: "#/definitions/DatabricksParametersSpec"
      parallel_jobs_limit:
        type: "integer"
        format: "int32"
        description: "The concurrency limit for the maximum number of parallel SQL\
          \ queries executed on this connection."
      default_grouping_configuration:
        description: "Default data grouping configuration for all tables. The configuration\
          \ may be overridden on table, column and check level. Data groupings are\
          \ configured in two cases: (1) the data in the table should be analyzed\
          \ with a GROUP BY condition, to analyze different datasets using separate\
          \ time series, for example a table contains data from multiple countries\
          \ and there is a 'country' column used for partitioning. a static dimension\
          \ is assigned to a table, when the data is partitioned at a table level\
          \ (similar tables store the same information, but for different countries,\
          \ etc.). (2) a static dimension is assigned to a table, when the data is\
          \ partitioned at a table level (similar tables store the same information,\
          \ but for different countries, etc.). "
        $ref: "#/definitions/DataGroupingConfigurationSpec"
      schedules:
        description: "Configuration of the job scheduler that runs data quality checks.\
          \ The scheduler configuration is divided into types of checks that have\
          \ different schedules."
        $ref: "#/definitions/DefaultSchedulesSpec"
      incident_grouping:
        description: "Configuration of data quality incident grouping. Configures\
          \ how failed data quality checks are grouped into data quality incidents."
        $ref: "#/definitions/ConnectionIncidentGroupingSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      labels:
        type: "array"
        description: "Custom labels that were assigned to the connection. Labels are\
          \ used for searching for tables when filtered data quality checks are executed."
        items:
          type: "string"
  ConnectionSpecificationModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      connection_hash:
        type: "integer"
        format: "int64"
        description: "Connection hash that identifies the connection using a unique\
          \ hash code."
      spec:
        description: "Full connection specification, including all nested objects\
          \ (but not a list of tables)."
        $ref: "#/definitions/ConnectionSpec"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Full connection model"
  ConnectionTestModel:
    type: "object"
    properties:
      connectionTestResult:
        type: "string"
        description: "Connection test result"
        enum:
        - "SUCCESS"
        - "FAILURE"
        - "CONNECTION_ALREADY_EXISTS"
      errorMessage:
        type: "string"
        description: "Optional error message when the status is not \"SUCCESS\""
    description: "Connection test status result"
  CountBetweenRuleParametersSpec:
    type: "object"
    properties:
      min_count:
        type: "integer"
        format: "int64"
        description: "Minimum accepted count (inclusive), leave empty when the limit\
          \ is not assigned."
      max_count:
        type: "integer"
        format: "int64"
        description: "Maximum accepted count (inclusive), leave empty when the limit\
          \ is not assigned."
  CsvFileFormatSpec:
    type: "object"
    properties:
      all_varchar:
        type: "boolean"
        description: "Option to skip type detection for CSV parsing and assume all\
          \ columns to be of type VARCHAR."
      allow_quoted_nulls:
        type: "boolean"
        description: "Option to allow the conversion of quoted values to NULL values."
      auto_detect:
        type: "boolean"
        description: "Enables auto detection of CSV parameters."
      compression:
        type: "string"
        description: "The compression type for the file. By default this will be detected\
          \ automatically from the file extension (e.g., t.csv.gz will use gzip, t.csv\
          \ will use none). Options are none, gzip, zstd."
        enum:
        - "auto"
        - "none"
        - "gzip"
        - "zstd"
      dateformat:
        type: "string"
        description: "Specifies the date format to use when parsing dates."
      decimal_separator:
        type: "string"
        description: "The decimal separator of numbers."
      delim:
        type: "string"
        description: "Specifies the string that separates columns within each row\
          \ (line) of the file."
      escape:
        type: "string"
        description: "Specifies the string that should appear before a data character\
          \ sequence that matches the quote value."
      filename:
        type: "boolean"
        description: "Whether or not an extra filename column should be included in\
          \ the result."
      header:
        type: "boolean"
        description: "Specifies that the file contains a header line with the names\
          \ of each column in the file."
      hive_partitioning:
        type: "boolean"
        description: "Whether or not to interpret the path as a hive partitioned path."
      ignore_errors:
        type: "boolean"
        description: "Option to ignore any parsing errors encountered - and instead\
          \ ignore rows with errors."
      new_line:
        type: "string"
        description: "Set the new line character(s) in the file. Options are '\\r','\\\
          n', or '\\r\\n'."
        enum:
        - "cr"
        - "lf"
        - "crlf"
      quote:
        type: "string"
        description: "Specifies the quoting string to be used when a data value is\
          \ quoted."
      sample_size:
        type: "integer"
        format: "int64"
        description: "The number of sample rows for auto detection of parameters."
      skip:
        type: "integer"
        format: "int64"
        description: "The number of lines at the top of the file to skip."
      timestampformat:
        type: "string"
        description: "Specifies the date format to use when parsing timestamps."
  CustomCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      sensor_name:
        type: "string"
        description: "Optional custom sensor name. It is a folder name inside the\
          \ user's home 'sensors' folder or the DQOps Home (DQOps distribution) home/sensors\
          \ folder. Sample sensor name: table/volume/row_count. When this value is\
          \ set, it overrides the default sensor definition defined for the named\
          \ check definition."
      rule_name:
        type: "string"
        description: "Optional custom rule name. It is a path to a custom rule python\
          \ module that starts at the user's home 'rules' folder. The path should\
          \ not end with the .py file extension. Sample rule: myrules/my_custom_rule.\
          \ When this value is set, it overrides the default rule definition defined\
          \ for the named check definition."
      parameters:
        description: "Custom sensor parameters"
        $ref: "#/definitions/CustomSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/CustomRuleParametersSpec"
      error:
        description: "Default alerting thresholdthat raises a data quality issue at\
          \ an error severity level"
        $ref: "#/definitions/CustomRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/CustomRuleParametersSpec"
  CustomRuleParametersSpec:
    type: "object"
  CustomSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  DashboardSpec:
    type: "object"
    properties:
      dashboard_name:
        type: "string"
        description: "Dashboard name"
      url:
        type: "string"
        description: "Dashboard url"
      width:
        type: "integer"
        format: "int32"
        description: "Dashboard width (px)"
      height:
        type: "integer"
        format: "int32"
        description: "Dashboard height (px)"
      standard:
        type: "boolean"
        description: "Shows the dashboard always in the data quality dashboard section.\
          \ The dashboards that are not 'standard' are advanced dashboards, hidden\
          \ initially."
      disable_thumbnail:
        type: "boolean"
        description: "Disables showing a thumbnail. A thumbnail url for Looker Studio\
          \ dashboards is generated by adding /thumbnail to the end of the dashboard's\
          \ url. It is a Google generated thumbnail of the dashboard."
      parameters:
        type: "object"
        description: "Key/value dictionary of additional parameters to be passed to\
          \ the dashboard"
        additionalProperties:
          type: "string"
  DashboardsFolderSpec:
    type: "object"
    properties:
      folder_name:
        type: "string"
        description: "Folder name"
      standard:
        type: "boolean"
        description: "Always shows this schema tree node because it contains standard\
          \ dashboards. Set the value to false to show this folder only when advanced\
          \ dashboards are enabled."
      dashboards:
        type: "array"
        description: "List of data quality dashboard at this level."
        items:
          $ref: "#/definitions/DashboardSpec"
      folders:
        type: "array"
        description: "List of data quality dashboard folders at this level."
        items:
          $ref: "#/definitions/DashboardsFolderSpec"
  DataDeleteResultPartition:
    type: "object"
    properties:
      rowsAffectedCount:
        type: "integer"
        format: "int32"
        description: "The number of rows that were deleted from the partition."
      partitionDeleted:
        type: "boolean"
        description: "True if a whole partition (a parquet file) was deleted instead\
          \ of removing only selected rows."
  DataDictionaryListModel:
    type: "object"
    properties:
      dictionary_name:
        type: "string"
        description: "Dictionary name. It is the name of a file in the dictionaries/\
          \ folder inside the DQOps user's home folder."
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete the dictionary file."
      can_access_dictionary:
        type: "boolean"
        description: "Boolean flag that decides if the current user see or download\
          \ the dictionary file."
    description: "Data dictionary CSV file list model with the basic information about\
      \ the dictionary."
  DataDictionaryModel:
    type: "object"
    properties:
      dictionary_name:
        type: "string"
        description: "Dictionary name. It is the name of a file in the dictionaries/\
          \ folder inside the DQOps user's home folder."
      file_content:
        type: "string"
        description: "Dictionary CSV file content as a single file."
    description: "Data dictionary CSV file full model used to create and update the\
      \ dictionary. Contains the content of the CSV file as a text field."
  DataGroupingConfigurationListModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      schema_name:
        type: "string"
        description: "Schema name."
      table_name:
        type: "string"
        description: "Table name."
      data_grouping_configuration_name:
        type: "string"
        description: "Data grouping configuration name."
      default_data_grouping_configuration:
        type: "boolean"
        description: "True when this is the default data grouping configuration for\
          \ the table."
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
    description: "Data grouping configurations list model not containing nested objects,\
      \ but only the name of the grouping configuration."
  DataGroupingConfigurationModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      schema_name:
        type: "string"
        description: "Schema name."
      table_name:
        type: "string"
        description: "Table name."
      data_grouping_configuration_name:
        type: "string"
        description: "Data grouping configuration name."
      spec:
        description: "Data grouping specification with the definition of the list\
          \ of data grouping dimensions, the column names to use in a **GROUP BY**\
          \ clause or a value of a static tag to assign to every check result captured\
          \ from the table."
        $ref: "#/definitions/DataGroupingConfigurationSpec"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Data grouping configuration model containing nested objects and\
      \ the configuration of grouping dimensions."
  DataGroupingConfigurationSpec:
    type: "object"
    properties:
      level_1:
        description: "Data grouping dimension level 1 configuration."
        $ref: "#/definitions/DataGroupingDimensionSpec"
      level_2:
        description: "Data grouping dimension level 2 configuration."
        $ref: "#/definitions/DataGroupingDimensionSpec"
      level_3:
        description: "Data grouping dimension level 3 configuration."
        $ref: "#/definitions/DataGroupingDimensionSpec"
      level_4:
        description: "Data grouping dimension level 4 configuration."
        $ref: "#/definitions/DataGroupingDimensionSpec"
      level_5:
        description: "Data grouping dimension level 5 configuration."
        $ref: "#/definitions/DataGroupingDimensionSpec"
      level_6:
        description: "Data grouping dimension level 6 configuration."
        $ref: "#/definitions/DataGroupingDimensionSpec"
      level_7:
        description: "Data grouping dimension level 7 configuration."
        $ref: "#/definitions/DataGroupingDimensionSpec"
      level_8:
        description: "Data grouping dimension level 8 configuration."
        $ref: "#/definitions/DataGroupingDimensionSpec"
      level_9:
        description: "Data grouping dimension level 9 configuration."
        $ref: "#/definitions/DataGroupingDimensionSpec"
  DataGroupingConfigurationTrimmedModel:
    type: "object"
    properties:
      data_grouping_configuration_name:
        type: "string"
        description: "Data grouping configuration name."
      spec:
        description: "Data grouping configuration specification."
        $ref: "#/definitions/DataGroupingConfigurationSpec"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Data grouping configuration model with trimmed path"
  DataGroupingDimensionSpec:
    type: "object"
    properties:
      source:
        type: "string"
        description: "The source of the data grouping dimension value. The default\
          \ source of the grouping dimension is a tag. The tag should be assigned\
          \ when there are many similar tables that store the same data for different\
          \ areas (countries, etc.). It can be the name of the country if the table\
          \ or partition stores information for that country."
        enum:
        - "tag"
        - "column_value"
      tag:
        type: "string"
        description: "The value assigned to the data quality grouping dimension when\
          \ the source is 'tag'. Assign a hard-coded (static) value to the data grouping\
          \ dimension (tag) when there are multiple similar tables storing the same\
          \ data for different areas (countries, etc.). This can be the name of the\
          \ country if the table or partition stores information for that country."
      column:
        type: "string"
        description: "Column name that contains a dynamic data grouping dimension\
          \ value (for dynamic data-driven data groupings). Sensor queries will be\
          \ extended with a GROUP BY {data group level colum name}, sensors (and alerts)\
          \ will be calculated for each unique value of the specified column. Also\
          \ a separate time series will be tracked for each value."
      name:
        type: "string"
        description: "Data grouping dimension name."
  DatabricksParametersSpec:
    type: "object"
    properties:
      host:
        type: "string"
        description: "Databricks host name. Supports also a ${DATABRICKS_HOST} configuration\
          \ with a custom environment variable."
      port:
        type: "string"
        description: "Databricks port number. The default port is 443. Supports also\
          \ a ${DATABRICKS_PORT} configuration with a custom environment variable."
      catalog:
        type: "string"
        description: "Databricks catalog name. Supports also a ${DATABRICKS_CATALOG}\
          \ configuration with a custom environment variable."
      user:
        type: "string"
        description: "Databricks user name. Supports also a ${DATABRICKS_USER} configuration\
          \ with a custom environment variable."
      password:
        type: "string"
        description: "Databricks database password. Supports also a ${DATABRICKS_PASSWORD}\
          \ configuration with a custom environment variable."
      http_path:
        type: "string"
        description: "Databricks http path to the warehouse. For example: /sql/1.0/warehouses/<warehouse\
          \ instance id>. Supports also a ${DATABRICKS_HTTP_PATH} configuration with\
          \ a custom environment variable."
      access_token:
        type: "string"
        description: "Databricks access token the warehouse. Supports also a ${DATABRICKS_ACCESS_TOKEN}\
          \ configuration with a custom environment variable."
      properties:
        type: "object"
        description: "A dictionary of custom JDBC parameters that are added to the\
          \ JDBC connection string, a key/value dictionary."
        additionalProperties:
          type: "string"
      database:
        type: "string"
  DefaultColumnChecksPatternListModel:
    type: "object"
    properties:
      pattern_name:
        type: "string"
        description: "Pattern name."
      priority:
        type: "integer"
        format: "int32"
        description: "The priority of the pattern. Patterns with lower values are\
          \ applied before patterns with higher priority values."
      disabled:
        type: "boolean"
        description: "Disables this data quality check configuration. The checks will\
          \ not be activated."
      description:
        type: "string"
        description: "The description (documentation) of this data quality check configuration."
      target_column:
        description: "The filters for the target column."
        $ref: "#/definitions/TargetColumnPatternSpec"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Default column-level checks pattern list model"
  DefaultColumnChecksPatternModel:
    type: "object"
    properties:
      pattern_name:
        type: "string"
        description: "Pattern name"
      pattern_spec:
        description: "The default checks specification."
        $ref: "#/definitions/ColumnDefaultChecksPatternSpec"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Default column-level checks pattern model"
  DefaultSchedulesSpec:
    type: "object"
    properties:
      profiling:
        description: "Schedule for running profiling data quality checks."
        $ref: "#/definitions/MonitoringScheduleSpec"
      monitoring_daily:
        description: "Schedule for running daily monitoring checks."
        $ref: "#/definitions/MonitoringScheduleSpec"
      monitoring_monthly:
        description: "Schedule for running monthly monitoring checks."
        $ref: "#/definitions/MonitoringScheduleSpec"
      partitioned_daily:
        description: "Schedule for running daily partitioned checks."
        $ref: "#/definitions/MonitoringScheduleSpec"
      partitioned_monthly:
        description: "Schedule for running monthly partitioned checks."
        $ref: "#/definitions/MonitoringScheduleSpec"
  DefaultTableChecksPatternListModel:
    type: "object"
    properties:
      pattern_name:
        type: "string"
        description: "Pattern name."
      priority:
        type: "integer"
        format: "int32"
        description: "The priority of the pattern. Patterns with lower values are\
          \ applied before patterns with higher priority values."
      disabled:
        type: "boolean"
        description: "Disables this data quality check configuration. The checks will\
          \ not be activated."
      description:
        type: "string"
        description: "The description (documentation) of this data quality check configuration."
      target_table:
        description: "The filters for the target table."
        $ref: "#/definitions/TargetTablePatternSpec"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Default table-level checks pattern list model"
  DefaultTableChecksPatternModel:
    type: "object"
    properties:
      pattern_name:
        type: "string"
        description: "Pattern name"
      pattern_spec:
        description: "The default checks specification."
        $ref: "#/definitions/TableDefaultChecksPatternSpec"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Default table-level checks pattern model"
  DeleteStoredDataQueueJobParameters:
    type: "object"
    properties:
      connection:
        type: "string"
        description: "The connection name."
      fullTableName:
        type: "string"
        description: "The schema and table name. It is provided as *<schema_name>.<table_name>*,\
          \ for example *public.fact_sales*. This filter does not support patterns."
      dateStart:
        type: "string"
        format: "date"
        description: "The start date (inclusive) to delete the data, based on the\
          \ *time_period* column in Parquet files."
      dateEnd:
        type: "string"
        format: "date"
        description: "The end date (inclusive) to delete the data, based on the *time_period*\
          \ column in Parquet files."
      deleteErrors:
        type: "boolean"
        description: "Delete the data from the [errors](../../reference/parquetfiles/errors.md)\
          \ table. Because the default value is *false*, this parameter must be set\
          \ to *true* to delete the errors."
      deleteStatistics:
        type: "boolean"
        description: "Delete the data from the [statistics](../../reference/parquetfiles/statistics.md)\
          \ table. Because the default value is *false*, this parameter must be set\
          \ to *true* to delete the statistics."
      deleteCheckResults:
        type: "boolean"
        description: "Delete the data from the [check_results](../../reference/parquetfiles/check_results.md)\
          \ table. Because the default value is *false*, this parameter must be set\
          \ to *true* to delete the check results."
      deleteSensorReadouts:
        type: "boolean"
        description: "Delete the data from the [sensor_readouts](../../reference/parquetfiles/sensor_readouts.md)\
          \ table. Because the default value is *false*, this parameter must be set\
          \ to *true* to delete the sensor readouts."
      columnNames:
        type: "array"
        description: "The list of column names to delete the data for column level\
          \ results or errors only for selected columns."
        items:
          type: "string"
      checkCategory:
        type: "string"
        description: "The check category name, for example *volume* or *anomaly*."
      tableComparisonName:
        type: "string"
        description: "The name of a table comparison configuration. Deletes only table\
          \ comparison results (and errors) for a given comparison."
      checkName:
        type: "string"
        description: "The name of a data quality check. Uses the short check name,\
          \ for example *daily_row_count*."
      checkType:
        type: "string"
        description: "The type of checks whose results and errors should be deleted.\
          \ For example, use *monitoring* to delete only monitoring checks data."
      sensorName:
        type: "string"
        description: "The full sensor name whose results, checks based on the sensor,\
          \ statistics and errors generated by the sensor sound be deleted. Uses a\
          \ full sensor name, for example: *table/volume/row_count*."
      dataGroupTag:
        type: "string"
        description: "The names of data groups in any of the *grouping_level_1*...*grouping_level_9*\
          \ columns in the Parquet tables. Enables deleting data tagged for one data\
          \ source or a subset of results when the group level is captured from a\
          \ column in a monitored table."
      qualityDimension:
        type: "string"
        description: "The data quality dimension name, for example *Timeliness* or\
          \ *Completeness*."
      timeGradient:
        type: "string"
        description: "The time gradient (time scale) of the sensor and check results\
          \ that are captured."
      collectorCategory:
        type: "string"
        description: "The statistics collector category when statistics should be\
          \ deleted. A statistics category is a group of statistics, for example *sampling*\
          \ for the column value samples."
      collectorName:
        type: "string"
        description: "The statistics collector name when only statistics are deleted\
          \ for a selected collector, for example *sample_values*."
      collectorTarget:
        type: "string"
        description: "The type of the target object for which the basic statistics\
          \ are deleted. Supported values are *table* and *column*."
  DeleteStoredDataQueueJobResult:
    type: "object"
    properties:
      jobId:
        description: "Job id that identifies a job that was started on the DQOps job\
          \ queue."
        $ref: "#/definitions/DqoQueueJobId"
      result:
        description: "Optional result object that is returned only when the wait parameter\
          \ was true and the \"delete stored data\" job has finished. Contains a list\
          \ of partitions that were deleted or updated."
        $ref: "#/definitions/DeleteStoredDataResult"
      status:
        type: "string"
        description: "Job status"
        enum:
        - "queued"
        - "running"
        - "waiting"
        - "finished"
        - "failed"
        - "cancel_requested"
        - "cancelled"
    description: "Object returned from the operation that queues a \"delete stored\
      \ data\" job. The result contains the job id that was started and optionally\
      \ can also contain a dictionary of partitions that were cleared or deleted if\
      \ the operation was started with wait=true parameter to wait for the \"delete\
      \ stored data\" job to finish."
  DeleteStoredDataResult:
    type: "object"
    properties:
      partitionResults:
        type: "object"
        description: "Dictionary of partitions that where deleted or updated when\
          \ the rows were deleted."
        additionalProperties:
          $ref: "#/definitions/DataDeleteResultPartition"
  DetectedDatatypeEqualsRuleParametersSpec:
    type: "object"
    properties:
      expected_datatype:
        type: "string"
        description: "Expected data type code, the values for the sensor's actual\
          \ values are: 1 - integers, 2 - floats, 3 - dates, 4 - datetimes, 5 - timestamps,\
          \ 6 - booleans, 7 - texts, 8 - mixed data types."
        enum:
        - "integers"
        - "floats"
        - "dates"
        - "datetimes"
        - "booleans"
        - "texts"
        - "mixed"
  DimensionCurrentDataQualityStatusModel:
    type: "object"
    properties:
      dimension:
        type: "string"
        description: "Data quality dimension name. The most popular dimensions are:\
          \ Completeness, Uniqueness, Timeliness, Validity, Consistency, Accuracy,\
          \ Availability."
      current_severity:
        type: "string"
        description: "The most recent data quality issue severity for this table.\
          \ When the table is monitored using data grouping, it is the highest issue\
          \ severity of all recently analyzed data groups. For partitioned checks,\
          \ it is the highest severity of all results for all partitions (time periods)\
          \ in the analyzed time range."
        enum:
        - "valid"
        - "warning"
        - "error"
        - "fatal"
      highest_historical_severity:
        type: "string"
        description: "The highest severity of previous executions of this data quality\
          \ issue in the analyzed time range. It can be different from the *current_severity*\
          \ if the data quality issue was solved and the most recently data quality\
          \ issue did not detect it anymore. For partitioned checks, this field returns\
          \ the same value as the *current_severity*, because data quality issues\
          \ in older partitions are still valid."
        enum:
        - "valid"
        - "warning"
        - "error"
        - "fatal"
      last_check_executed_at:
        type: "integer"
        format: "int64"
        description: "The UTC timestamp when the most recent data quality check was\
          \ executed on the table."
      executed_checks:
        type: "integer"
        format: "int32"
        description: "The total number of most recent checks that were executed on\
          \ the table for one data quality dimension. Table comparison checks that\
          \ are comparing groups of data are counted as the number of compared data\
          \ groups."
      valid_results:
        type: "integer"
        format: "int32"
        description: "The number of most recent valid data quality checks that passed\
          \ without raising any issues."
      warnings:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising a warning severity data quality issue."
      errors:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising an error severity data quality issue."
      fatals:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising a fatal severity data quality issue."
      execution_errors:
        type: "integer"
        format: "int32"
        description: "The number of data quality check execution errors that were\
          \ reported due to access issues to the data source, invalid mapping in DQOps,\
          \ invalid queries in data quality sensors or invalid python rules. When\
          \ an execution error is reported, the configuration of a data quality check\
          \ on a table must be updated."
      data_quality_kpi:
        type: "number"
        format: "double"
        description: "Data quality KPI score for the data quality dimension, measured\
          \ as a percentage of passed data quality checks. DQOps counts data quality\
          \ issues at a warning severity level as passed checks. The data quality\
          \ KPI score is a value in the range 0..100."
    description: "The summary of the current data quality status for one data quality\
      \ dimension"
  DqoCloudUserModel:
    type: "object"
    properties:
      email:
        type: "string"
        description: "User's email that identifies the user."
      accountRole:
        type: "string"
        description: "Account role."
        enum:
        - "admin"
        - "editor"
        - "operator"
        - "viewer"
        - "none"
    description: "DQOps Cloud user model - identifies a user in a multi-user DQOps\
      \ deployment."
  DqoJobChangeModel:
    type: "object"
    properties:
      status:
        type: "string"
        enum:
        - "queued"
        - "running"
        - "waiting"
        - "finished"
        - "failed"
        - "cancel_requested"
        - "cancelled"
      jobId:
        $ref: "#/definitions/DqoQueueJobId"
      changeSequence:
        type: "integer"
        format: "int64"
      updatedModel:
        $ref: "#/definitions/DqoJobHistoryEntryModel"
      statusChangedAt:
        type: "integer"
        format: "int64"
  DqoJobEntryParametersModel:
    type: "object"
    properties:
      synchronizeRootFolderParameters:
        $ref: "#/definitions/SynchronizeRootFolderDqoQueueJobParameters"
      synchronizeMultipleFoldersParameters:
        $ref: "#/definitions/SynchronizeMultipleFoldersDqoQueueJobParameters"
      runScheduledChecksParameters:
        $ref: "#/definitions/MonitoringScheduleSpec"
      runChecksParameters:
        $ref: "#/definitions/RunChecksParameters"
      runChecksOnTableParameters:
        $ref: "#/definitions/RunChecksOnTableParameters"
      collectStatisticsParameters:
        $ref: "#/definitions/CollectStatisticsQueueJobParameters"
      collectStatisticsOnTableParameters:
        $ref: "#/definitions/CollectStatisticsOnTableQueueJobParameters"
      importSchemaParameters:
        $ref: "#/definitions/ImportSchemaQueueJobParameters"
      importTableParameters:
        $ref: "#/definitions/ImportTablesQueueJobParameters"
      deleteStoredDataParameters:
        $ref: "#/definitions/DeleteStoredDataQueueJobParameters"
      repairStoredDataParameters:
        $ref: "#/definitions/RepairStoredDataQueueJobParameters"
  DqoJobHistoryEntryModel:
    type: "object"
    properties:
      jobId:
        $ref: "#/definitions/DqoQueueJobId"
      jobType:
        type: "string"
        enum:
        - "run_checks"
        - "run_checks_on_table"
        - "collect_statistics"
        - "collect_statistics_on_table"
        - "queue_thread_shutdown"
        - "synchronize_folder"
        - "synchronize_multiple_folders"
        - "run_scheduled_checks_cron"
        - "import_schema"
        - "import_tables"
        - "delete_stored_data"
        - "repair_stored_data"
      parameters:
        $ref: "#/definitions/DqoJobEntryParametersModel"
      status:
        type: "string"
        enum:
        - "queued"
        - "running"
        - "waiting"
        - "finished"
        - "failed"
        - "cancel_requested"
        - "cancelled"
      errorMessage:
        type: "string"
      statusChangedAt:
        type: "integer"
        format: "int64"
  DqoJobQueueIncrementalSnapshotModel:
    type: "object"
    properties:
      jobChanges:
        type: "array"
        items:
          $ref: "#/definitions/DqoJobChangeModel"
      folderSynchronizationStatus:
        $ref: "#/definitions/CloudSynchronizationFoldersStatusModel"
      lastSequenceNumber:
        type: "integer"
        format: "int64"
  DqoJobQueueInitialSnapshotModel:
    type: "object"
    properties:
      jobs:
        type: "array"
        items:
          $ref: "#/definitions/DqoJobHistoryEntryModel"
      folderSynchronizationStatus:
        $ref: "#/definitions/CloudSynchronizationFoldersStatusModel"
      lastSequenceNumber:
        type: "integer"
        format: "int64"
  DqoQueueJobId:
    type: "object"
    properties:
      jobId:
        type: "integer"
        format: "int64"
        description: "Job id."
      jobBusinessKey:
        type: "string"
        description: "Optional job business key that was assigned to the job. A business\
          \ key is an alternative user assigned unique job identifier used to find\
          \ the status of a job finding it by the business key."
      parentJobId:
        description: "Parent job id. Filled only for nested jobs, for example a sub-job\
          \ that runs data quality checks on a single table."
        $ref: "#/definitions/DqoQueueJobId"
      createdAt:
        type: "integer"
        format: "int64"
        description: "The timestamp when the job was created."
    description: "Identifies a single job that was pushed to the job queue."
  DqoSettingsModel:
    type: "object"
    properties:
      properties:
        type: "object"
        description: "Dictionary of all effective DQOps system properties, retrieved\
          \ from the default configuration files, user configuration files, environment\
          \ variables and 'dqo' command arguments."
        additionalProperties:
          type: "object"
    description: "DQOps system settings"
  DqoUserProfileModel:
    type: "object"
    properties:
      user:
        type: "string"
        description: "User email."
      tenant:
        type: "string"
        description: "DQOps Cloud tenant."
      license_type:
        type: "string"
        description: "DQOps Cloud license type."
      trial_period_expires_at:
        type: "string"
        description: "The date and time when the trial period of a PERSONAL DQOps\
          \ license expires and the account is downgraded to a FREE license."
      connections_limit:
        type: "integer"
        format: "int32"
        description: "Limit of the number of connections that can be synchronized\
          \ to the DQOps Cloud data quality warehouse."
      users_limit:
        type: "integer"
        format: "int32"
        description: "Limit of the number of users that can be added to a DQOps environment."
      months_limit:
        type: "integer"
        format: "int32"
        description: "Limit of the number of recent months (excluding the current\
          \ month) that can be synchronized to the DQOps Cloud data quality warehouse."
      connection_tables_limit:
        type: "integer"
        format: "int32"
        description: "Limit of the number of tables inside each connection that can\
          \ be synchronized to the DQOps Cloud data quality warehouse."
      tables_limit:
        type: "integer"
        format: "int32"
        description: "Limit of the total number of tables that can be synchronized\
          \ to the DQOps Cloud data quality warehouse."
      jobs_limit:
        type: "integer"
        format: "int32"
        description: "Limit of the number of supported concurrent jobs that DQOps\
          \ can run in parallel on this instance."
      account_role:
        type: "string"
        description: "User role that limits possible operations that the current user\
          \ can perform."
        enum:
        - "admin"
        - "editor"
        - "operator"
        - "viewer"
        - "none"
      data_quality_data_warehouse_enabled:
        type: "boolean"
        description: "True when the account has access to the DQOps Cloud's data quality\
          \ data lake and data warehouse, allowing to synchronize files and use the\
          \ data quality data warehouse."
      can_manage_account:
        type: "boolean"
        description: "User is the administrator of the account and can perform security\
          \ related actions, such as managing users."
      can_view_any_object:
        type: "boolean"
        description: "User can view any object and view all results."
      can_manage_scheduler:
        type: "boolean"
        description: "User can start and stop the job scheduler."
      can_cancel_jobs:
        type: "boolean"
        description: "User can cancel running jobs."
      can_run_checks:
        type: "boolean"
        description: "User can run data quality checks."
      can_delete_data:
        type: "boolean"
        description: "User can delete data quality results."
      can_collect_statistics:
        type: "boolean"
        description: "User can collect statistics."
      can_manage_data_sources:
        type: "boolean"
        description: "User can manage data sources: create connections, import tables,\
          \ change the configuration of connections, tables, columns. Change any settings\
          \ in the Data Sources section."
      can_synchronize:
        type: "boolean"
        description: "User can trigger the synchronization with DQOps Cloud."
      can_edit_comments:
        type: "boolean"
        description: "User can edit comments on connections, tables, columns."
      can_edit_labels:
        type: "boolean"
        description: "User can edit labels on connections, tables, columns."
      can_manage_definitions:
        type: "boolean"
        description: "User can manage definitions of sensors, rules, checks and the\
          \ default data quality check configuration that is applied on imported tables."
      can_compare_tables:
        type: "boolean"
        description: "User can define table comparison configurations and compare\
          \ tables."
      can_manage_users:
        type: "boolean"
        description: "User can manage other users, add users to a multi-user account,\
          \ change access rights, reset passwords."
      can_manage_and_view_shared_credentials:
        type: "boolean"
        description: "User can manage shared credentials and view (or download) already\
          \ defined shared credentials."
      can_change_own_password:
        type: "boolean"
        description: "User can change his own password in DQOps Cloud, because the\
          \ DQOps Cloud Pairing API Key is valid and synchronization is enabled."
    description: "The model that describes the current user and his access rights."
  DuckdbParametersSpec:
    type: "object"
    properties:
      read_mode:
        type: "string"
        description: "DuckDB read mode."
        enum:
        - "in_memory"
        - "files"
      files_format_type:
        type: "string"
        description: "Type of source files format for DuckDB."
        enum:
        - "csv"
        - "json"
        - "parquet"
      database:
        type: "string"
        description: "DuckDB database name for in-memory read mode. The value can\
          \ be in the ${ENVIRONMENT_VARIABLE_NAME} format to use dynamic substitution."
      properties:
        type: "object"
        description: "A dictionary of custom JDBC parameters that are added to the\
          \ JDBC connection string, a key/value dictionary."
        additionalProperties:
          type: "string"
      csv:
        description: "Csv file format specification."
        $ref: "#/definitions/CsvFileFormatSpec"
      json:
        description: "Json file format specification."
        $ref: "#/definitions/JsonFileFormatSpec"
      parquet:
        description: "Parquet file format specification."
        $ref: "#/definitions/ParquetFileFormatSpec"
      directories:
        type: "object"
        description: "Virtual schema name to directory mappings. The path must be\
          \ an absolute path."
        additionalProperties:
          type: "string"
      storage_type:
        type: "string"
        description: "The storage type."
        enum:
        - "local"
        - "s3"
        - "azure"
      aws_authentication_mode:
        type: "string"
        description: "The authentication mode for AWS. Supports also a ${DUCKDB_AWS_AUTHENTICATION_MODE}\
          \ configuration with a custom environment variable."
        enum:
        - "iam"
        - "default_credentials"
      azure_authentication_mode:
        type: "string"
        description: "The authentication mode for Azure. Supports also a ${DUCKDB_AZURE_AUTHENTICATION_MODE}\
          \ configuration with a custom environment variable."
        enum:
        - "connection_string"
        - "credential_chain"
        - "service_principal"
        - "default_credentials"
      user:
        type: "string"
        description: "DuckDB user name for a remote storage type. The value can be\
          \ in the ${ENVIRONMENT_VARIABLE_NAME} format to use dynamic substitution."
      password:
        type: "string"
        description: "DuckDB password for a remote storage type. The value can be\
          \ in the ${ENVIRONMENT_VARIABLE_NAME} format to use dynamic substitution."
      region:
        type: "string"
        description: "The region for the storage credentials. The value can be in\
          \ the ${ENVIRONMENT_VARIABLE_NAME} format to use dynamic substitution."
      tenant_id:
        type: "string"
        description: "Azure Tenant ID used by DuckDB Secret Manager. The value can\
          \ be in the ${ENVIRONMENT_VARIABLE_NAME} format to use dynamic substitution."
      client_id:
        type: "string"
        description: "Azure Client ID used by DuckDB Secret Manager. The value can\
          \ be in the ${ENVIRONMENT_VARIABLE_NAME} format to use dynamic substitution."
      client_secret:
        type: "string"
        description: "Azure Client Secret used by DuckDB Secret Manager. The value\
          \ can be in the ${ENVIRONMENT_VARIABLE_NAME} format to use dynamic substitution."
      account_name:
        type: "string"
        description: "Azure Storage Account Name used by DuckDB Secret Manager. The\
          \ value can be in the ${ENVIRONMENT_VARIABLE_NAME} format to use dynamic\
          \ substitution."
  Duration:
    type: "object"
    properties:
      seconds:
        type: "integer"
        format: "int64"
      nano:
        type: "integer"
        format: "int32"
      negative:
        type: "boolean"
      zero:
        type: "boolean"
      units:
        type: "array"
        items:
          $ref: "#/definitions/TemporalUnit"
  EffectiveScheduleModel:
    type: "object"
    properties:
      schedule_group:
        type: "string"
        description: "Field value for a schedule group to which this schedule belongs."
        enum:
        - "profiling"
        - "monitoring_daily"
        - "monitoring_monthly"
        - "partitioned_daily"
        - "partitioned_monthly"
      schedule_level:
        type: "string"
        description: "Field value for the level at which the schedule has been configured."
        enum:
        - "connection"
        - "table_override"
        - "check_override"
      cron_expression:
        type: "string"
        description: "Field value for a CRON expression defining the scheduling."
      time_of_execution:
        type: "string"
        format: "date-time"
        description: "Field value for the time at which the scheduled checks will\
          \ be executed."
      time_until_execution:
        description: "Field value for the time left until the execution of scheduled\
          \ checks."
        $ref: "#/definitions/Duration"
      disabled:
        type: "boolean"
        description: "Field value stating if the schedule has been explicitly disabled."
    description: "Model of a configured schedule (enabled on connection or table)\
      \ or schedule override (on check). Describes the CRON expression and the time\
      \ of the upcoming execution, as well as the duration until this time."
  Equals1RuleParametersSpec:
    type: "object"
  EqualsIntegerRuleParametersSpec:
    type: "object"
    properties:
      expected_value:
        type: "integer"
        format: "int64"
        description: "Expected value for the actual_value returned by the sensor.\
          \ It must be an integer value."
  ErrorEntryModel:
    type: "object"
    properties:
      actualValue:
        type: "number"
        format: "double"
        description: "Actual value"
      expectedValue:
        type: "number"
        format: "double"
        description: "Expected value"
      columnName:
        type: "string"
        description: "Column name"
      dataGroup:
        type: "string"
        description: "Data group"
      checkType:
        type: "string"
        description: "Check type"
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      durationMs:
        type: "integer"
        format: "int32"
        description: "Duration (ms)"
      executedAt:
        type: "integer"
        format: "int64"
        description: "Executed at"
      timeGradient:
        type: "string"
        description: "Time gradient"
        enum:
        - "year"
        - "quarter"
        - "month"
        - "week"
        - "day"
        - "hour"
        - "millisecond"
      timePeriod:
        type: "string"
        format: "date-time"
        description: "Time period"
      provider:
        type: "string"
        description: "Provider name"
      qualityDimension:
        type: "string"
        description: "Data quality dimension"
      sensorName:
        type: "string"
        description: "Sensor name"
      readoutId:
        type: "string"
        description: "Sensor readout ID"
      errorMessage:
        type: "string"
        description: "Error message"
      errorSource:
        type: "string"
        description: "Error source"
      errorTimestamp:
        type: "string"
        format: "date-time"
        description: "Error timestamp"
      tableComparison:
        type: "string"
        description: "Table comparison name"
  ErrorsListModel:
    type: "object"
    properties:
      checkName:
        type: "string"
        description: "Check name"
      checkDisplayName:
        type: "string"
        description: "Check display name"
      checkType:
        type: "string"
        description: "Check type"
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      checkHash:
        type: "integer"
        format: "int64"
        description: "Check hash"
      checkCategory:
        type: "string"
        description: "Check category name"
      dataGroupsNames:
        type: "array"
        description: "Data groups list"
        items:
          type: "string"
      dataGroup:
        type: "string"
        description: "Selected data group"
      errorEntries:
        type: "array"
        description: "Error entries"
        items:
          $ref: "#/definitions/ErrorEntryModel"
  ExternalLogEntry:
    type: "object"
    properties:
      window_location:
        type: "string"
        description: "window.location value at the time when the log entry was reported."
      message:
        type: "string"
        description: "Log message that should be logged."
    description: "External log entry"
  FieldModel:
    type: "object"
    properties:
      definition:
        description: "Field name that matches the field name (snake_case) used in\
          \ the YAML specification."
        $ref: "#/definitions/ParameterDefinitionSpec"
      optional:
        type: "boolean"
        description: "Field value is optional and may be null, when false - the field\
          \ is required and must be filled."
      string_value:
        type: "string"
        description: "Field value for a string field."
      boolean_value:
        type: "boolean"
        description: "Field value for a boolean field."
      integer_value:
        type: "integer"
        format: "int32"
        description: "Field value for an integer (32-bit) field."
      long_value:
        type: "integer"
        format: "int64"
        description: "Field value for a long (64-bit) field."
      double_value:
        type: "number"
        format: "double"
        description: "Field value for a double field."
      datetime_value:
        type: "string"
        format: "date-time"
        description: "Field value for a date time field."
      column_name_value:
        type: "string"
        description: "Field value for a column name field."
      enum_value:
        type: "string"
        description: "Field value for an enum (choice) field."
      string_list_value:
        type: "array"
        description: "Field value for an array (list) of strings."
        items:
          type: "string"
      integer_list_value:
        type: "array"
        description: "Field value for an array (list) of integers, using 64 bit integers."
        items:
          type: "integer"
          format: "int64"
      date_value:
        type: "string"
        format: "date"
        description: "Field value for an date."
    description: "Model of a single field that is used to edit a parameter value for\
      \ a sensor or a rule. Describes the type of the field and the current value."
  FileFormatSpec:
    type: "object"
    properties:
      csv:
        description: "Csv file format specification."
        $ref: "#/definitions/CsvFileFormatSpec"
      json:
        description: "Json file format specification."
        $ref: "#/definitions/JsonFileFormatSpec"
      parquet:
        description: "Parquet file format specification."
        $ref: "#/definitions/ParquetFileFormatSpec"
      file_paths:
        type: "array"
        description: "The list of paths to files with data that are used as a source."
        items:
          type: "string"
  HierarchyIdModel:
    type: "object"
    properties:
      path:
        type: "array"
        items:
          type: "object"
  ImportSchemaQueueJobParameters:
    type: "object"
    properties:
      connectionName:
        type: "string"
      schemaName:
        type: "string"
      tableNamePattern:
        type: "string"
  ImportSeverityRuleParametersSpec:
    type: "object"
  ImportTablesQueueJobParameters:
    type: "object"
    properties:
      connectionName:
        type: "string"
        description: "Connection name"
      schemaName:
        type: "string"
        description: "Schema name"
      tableNames:
        type: "array"
        description: "Optional list of table names inside the schema. When the list\
          \ of tables is empty, all tables are imported."
        items:
          type: "string"
  ImportTablesQueueJobResult:
    type: "object"
    properties:
      jobId:
        description: "Job id that identifies a job that was started on the DQOps job\
          \ queue."
        $ref: "#/definitions/DqoQueueJobId"
      result:
        description: "Optional result object that is returned only when the wait parameter\
          \ was true and the \"import tables\" job has finished. Contains the summary\
          \ result of importing tables, including table and column schemas of imported\
          \ tables. "
        $ref: "#/definitions/ImportTablesResult"
      status:
        type: "string"
        description: "Job status"
        enum:
        - "queued"
        - "running"
        - "waiting"
        - "finished"
        - "failed"
        - "cancel_requested"
        - "cancelled"
    description: "Object returned from the operation that queues a \"import tables\"\
      \ job. The result contains the job id that was started and optionally can also\
      \ contain the result of importing the tables if the operation was started with\
      \ wait=true parameter to wait for the \"import tables\" job to finish."
  ImportTablesResult:
    type: "object"
    properties:
      source_table_specs:
        type: "array"
        description: "Table schemas (including column schemas) of imported tables."
        items:
          $ref: "#/definitions/TableSpec"
    description: "Result object returned from the \"import tables\" job. Contains\
      \ the original table schemas and column schemas of imported tables."
  IncidentDailyIssuesCount:
    type: "object"
    properties:
      warnings:
        type: "integer"
        format: "int32"
        description: "The number of failed data quality checks that generated a warning\
          \ severity data quality issue."
      errors:
        type: "integer"
        format: "int32"
        description: "The number of failed data quality checks that generated an error\
          \ severity data quality issue."
      fatals:
        type: "integer"
        format: "int32"
        description: "The number of failed data quality checks that generated a fatal\
          \ severity data quality issue."
      totalCount:
        type: "integer"
        format: "int32"
        description: "The total count of failed data quality checks on this day."
  IncidentIssueHistogramModel:
    type: "object"
    properties:
      hasProfilingIssues:
        type: "boolean"
        description: "True when this data quality incident is based on data quality\
          \ issues from profiling checks within the filters applied to search for\
          \ linked data quality issues."
      hasDailyMonitoringIssues:
        type: "boolean"
        description: "True when this data quality incident is based on data quality\
          \ issues from daily monitoring checks within the filters applied to search\
          \ for linked data quality issues."
      hasMonthlyMonitoringIssues:
        type: "boolean"
        description: "True when this data quality incident is based on data quality\
          \ issues from monthly monitoring checks within the filters applied to search\
          \ for linked data quality issues."
      hasDailyPartitionedIssues:
        type: "boolean"
        description: "True when this data quality incident is based on data quality\
          \ issues from daily partitioned checks within the filters applied to search\
          \ for linked data quality issues."
      hasMonthlyPartitionedIssues:
        type: "boolean"
        description: "True when this data quality incident is based on data quality\
          \ issues from monthly partitioned checks within the filters applied to search\
          \ for linked data quality issues."
      days:
        type: "object"
        description: "A map of the numbers of data quality issues per day, the day\
          \ uses the DQOps server timezone."
        additionalProperties:
          $ref: "#/definitions/IncidentDailyIssuesCount"
      columns:
        type: "object"
        description: "A map of column names with the most data quality issues related\
          \ to the incident. The map returns the count of issues as the value."
        additionalProperties:
          type: "integer"
          format: "int32"
      checks:
        type: "object"
        description: "A map of data quality check names with the most data quality\
          \ issues related to the incident. The map returns the count of issues as\
          \ the value."
        additionalProperties:
          type: "integer"
          format: "int32"
  IncidentModel:
    type: "object"
    properties:
      incidentId:
        type: "string"
        description: "Incident ID - the primary key that identifies each data quality\
          \ incident."
      connection:
        type: "string"
        description: "Connection name affected by a data quality incident."
      year:
        type: "integer"
        format: "int32"
        description: "The year when the incident was first seen. This value is required\
          \ to load an incident's monthly partition."
      month:
        type: "integer"
        format: "int32"
        description: "The month when the incident was first seen. This value is required\
          \ to load an incident's monthly partition."
      schema:
        type: "string"
        description: "Schema name affected by a data quality incident."
      table:
        type: "string"
        description: "Table name affected by a data quality incident."
      tablePriority:
        type: "integer"
        format: "int32"
        description: "Table priority of the table that was affected by a data quality\
          \ incident."
      incidentHash:
        type: "integer"
        format: "int64"
        description: "Data quality incident hash that identifies similar incidents\
          \ on the same incident grouping level."
      firstSeen:
        type: "integer"
        format: "int64"
        description: "The UTC timestamp when the data quality incident was first seen."
      lastSeen:
        type: "integer"
        format: "int64"
        description: "The UTC timestamp when the data quality incident was last seen."
      incidentUntil:
        type: "integer"
        format: "int64"
        description: "The UTC timestamp when the data quality incident is valid until.\
          \ All new failed data quality check results until that date will be included\
          \ in this incident, unless the incident status is changed to resolved, so\
          \ a new incident must be created."
      dataGroup:
        type: "string"
        description: "The data group that was affected by a data quality incident."
      qualityDimension:
        type: "string"
        description: "The data quality dimension that was affected by a data quality\
          \ incident."
      checkCategory:
        type: "string"
        description: "The data quality check category that was affected by a data\
          \ quality incident."
      checkType:
        type: "string"
        description: "The data quality check type that was affected by a data quality\
          \ incident."
      checkName:
        type: "string"
        description: "The data quality check name that was affected by a data quality\
          \ incident."
      highestSeverity:
        type: "integer"
        format: "int32"
        description: "The highest failed check severity that was detected as part\
          \ of this data quality incident. Possible values are: 1 - warning, 2 - error,\
          \ 3 - fatal."
      minimumSeverity:
        type: "integer"
        format: "int32"
        description: "The minimum severity of the data quality incident, copied from\
          \ the incident configuration at a connection or table at the time when the\
          \ incident was first seen. Possible values are: 1 - warning, 2 - error,\
          \ 3 - fatal."
      failedChecksCount:
        type: "integer"
        format: "int32"
        description: "The total number of failed data quality checks that were seen\
          \ when the incident was raised for the first time."
      issueUrl:
        type: "string"
        description: "The link (url) to a ticket in an external system that is tracking\
          \ this incident."
      status:
        type: "string"
        description: "Incident status."
        enum:
        - "open"
        - "acknowledged"
        - "resolved"
        - "muted"
  IncidentWebhookNotificationsSpec:
    type: "object"
    properties:
      incident_opened_webhook_url:
        type: "string"
        description: "Webhook URL where the notification messages describing new incidents\
          \ are pushed using a HTTP POST request. The format of the JSON message is\
          \ documented in the IncidentNotificationMessage object."
      incident_acknowledged_webhook_url:
        type: "string"
        description: "Webhook URL where the notification messages describing acknowledged\
          \ messages are pushed using a HTTP POST request. The format of the JSON\
          \ message is documented in the IncidentNotificationMessage object."
      incident_resolved_webhook_url:
        type: "string"
        description: "Webhook URL where the notification messages describing resolved\
          \ messages are pushed using a HTTP POST request. The format of the JSON\
          \ message is documented in the IncidentNotificationMessage object."
      incident_muted_webhook_url:
        type: "string"
        description: "Webhook URL where the notification messages describing muted\
          \ messages are pushed using a HTTP POST request. The format of the JSON\
          \ message is documented in the IncidentNotificationMessage object."
  IncidentsPerConnectionModel:
    type: "object"
    properties:
      connection:
        type: "string"
        description: "Connection (data source) name."
      openIncidents:
        type: "integer"
        format: "int32"
        description: "Count of open (new) data quality incidents."
      mostRecentFirstSeen:
        type: "integer"
        format: "int64"
        description: "The UTC timestamp when the most recent data quality incident\
          \ was first seen."
  JsonFileFormatSpec:
    type: "object"
    properties:
      auto_detect:
        type: "boolean"
        description: "Whether to auto-detect detect the names of the keys and data\
          \ types of the values automatically."
      compression:
        type: "string"
        description: "The compression type for the file. By default this will be detected\
          \ automatically from the file extension (e.g., t.json.gz will use gzip,\
          \ t.json will use none). Options are 'none', 'gzip', 'zstd', and 'auto'."
        enum:
        - "auto"
        - "none"
        - "gzip"
        - "zstd"
      convert_strings_to_integers:
        type: "boolean"
        description: "Whether strings representing integer values should be converted\
          \ to a numerical type."
      dateformat:
        type: "string"
        description: "Specifies the date format to use when parsing dates."
      filename:
        type: "boolean"
        description: "Whether or not an extra filename column should be included in\
          \ the result."
      format:
        type: "string"
        description: "Json format. Can be one of ['auto', 'unstructured', 'newline_delimited',\
          \ 'array']."
        enum:
        - "auto"
        - "unstructured"
        - "newline_delimited"
        - "array"
      hive_partitioning:
        type: "boolean"
        description: "Whether or not to interpret the path as a hive partitioned path."
      ignore_errors:
        type: "boolean"
        description: "Whether to ignore parse errors (only possible when format is\
          \ 'newline_delimited')."
      maximum_depth:
        type: "integer"
        format: "int64"
        description: "Maximum nesting depth to which the automatic schema detection\
          \ detects types. Set to -1 to fully detect nested JSON types."
      maximum_object_size:
        type: "integer"
        format: "int64"
        description: "The maximum size of a JSON object (in bytes)."
      records:
        type: "string"
        description: "Can be one of ['auto', 'true', 'false']."
        enum:
        - "auto"
        - "true"
        - "false"
      sample_size:
        type: "integer"
        format: "int64"
        description: "The number of sample rows for auto detection of parameters."
      timestampformat:
        type: "string"
        description: "Specifies the date format to use when parsing timestamps."
  LabelModel:
    type: "object"
    properties:
      label:
        type: "string"
        description: "Label text."
      labels_count:
        type: "integer"
        format: "int32"
        description: "The number of data assets tagged with this label."
      nested_labels_count:
        type: "integer"
        format: "int32"
        description: "The number of data assets tagged with nested labels below this\
          \ prefix node. For example, if the current label is \"address\", and there\
          \ are nested labels \"address/city\" and \"address/zipcode\", this value\
          \ returns the count of data assets tagged with these nested tags."
    description: "Label model that is returned by the REST API. A label is a tag that\
      \ was assigned to a data source, table, column or a single check. Labels play\
      \ the role of a business glossary."
  MaxCountRule0ErrorParametersSpec:
    type: "object"
    properties:
      max_count:
        type: "integer"
        format: "int64"
        description: "Maximum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MaxCountRule0WarningParametersSpec:
    type: "object"
    properties:
      max_count:
        type: "integer"
        format: "int64"
        description: "Maximum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MaxCountRule100ParametersSpec:
    type: "object"
    properties:
      max_count:
        type: "integer"
        format: "int64"
        description: "Maximum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MaxDaysRule1ParametersSpec:
    type: "object"
    properties:
      max_days:
        type: "number"
        format: "double"
        description: "Maximum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MaxDaysRule2ParametersSpec:
    type: "object"
    properties:
      max_days:
        type: "number"
        format: "double"
        description: "Maximum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MaxDaysRule7ParametersSpec:
    type: "object"
    properties:
      max_days:
        type: "number"
        format: "double"
        description: "Maximum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MaxDiffPercentRule0ParametersSpec:
    type: "object"
    properties:
      max_diff_percent:
        type: "number"
        format: "double"
        description: "Maximum accepted value for the percentage of difference between\
          \ expected_value and actual_value returned by the sensor (inclusive)."
  MaxDiffPercentRule1ParametersSpec:
    type: "object"
    properties:
      max_diff_percent:
        type: "number"
        format: "double"
        description: "Maximum accepted value for the percentage of difference between\
          \ expected_value and actual_value returned by the sensor (inclusive)."
  MaxDiffPercentRule5ParametersSpec:
    type: "object"
    properties:
      max_diff_percent:
        type: "number"
        format: "double"
        description: "Maximum accepted value for the percentage of difference between\
          \ expected_value and actual_value returned by the sensor (inclusive)."
  MaxFailuresRule0ParametersSpec:
    type: "object"
    properties:
      max_failures:
        type: "integer"
        format: "int64"
        description: "Maximum number of consecutive days with check failures. A check\
          \ is failed when a sensor query fails due to a connection error, missing\
          \ or corrupted table."
  MaxFailuresRule1ParametersSpec:
    type: "object"
    properties:
      max_failures:
        type: "integer"
        format: "int64"
        description: "Maximum number of consecutive days with check failures. A check\
          \ is failed when a sensor query fails due to a connection error, missing\
          \ or corrupted table."
  MaxFailuresRule5ParametersSpec:
    type: "object"
    properties:
      max_failures:
        type: "integer"
        format: "int64"
        description: "Maximum number of consecutive days with check failures. A check\
          \ is failed when a sensor query fails due to a connection error, missing\
          \ or corrupted table."
  MaxMissingRule0ErrorParametersSpec:
    type: "object"
    properties:
      max_missing:
        type: "integer"
        format: "int64"
        description: "The maximum number of values from the expected_values list that\
          \ were not found in the column (inclusive)."
  MaxMissingRule0WarningParametersSpec:
    type: "object"
    properties:
      max_missing:
        type: "integer"
        format: "int64"
        description: "The maximum number of values from the expected_values list that\
          \ were not found in the column (inclusive)."
  MaxMissingRule2ParametersSpec:
    type: "object"
    properties:
      max_missing:
        type: "integer"
        format: "int64"
        description: "The maximum number of values from the expected_values list that\
          \ were not found in the column (inclusive)."
  MaxPercentRule0ErrorParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Maximum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MaxPercentRule0WarningParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Maximum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MaxPercentRule5ParametersSpec:
    type: "object"
    properties:
      max_percent:
        type: "number"
        format: "double"
        description: "Maximum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MinCountRule1ParametersSpec:
    type: "object"
    properties:
      min_count:
        type: "integer"
        format: "int64"
        description: "Minimum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MinPercentRule100ErrorParametersSpec:
    type: "object"
    properties:
      min_percent:
        type: "number"
        format: "double"
        description: "Minimum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MinPercentRule100WarningParametersSpec:
    type: "object"
    properties:
      min_percent:
        type: "number"
        format: "double"
        description: "Minimum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MinPercentRule95ParametersSpec:
    type: "object"
    properties:
      min_percent:
        type: "number"
        format: "double"
        description: "Minimum accepted value for the actual_value returned by the\
          \ sensor (inclusive)."
  MonitoringScheduleSpec:
    type: "object"
    properties:
      cron_expression:
        type: "string"
        description: "Unix style cron expression that specifies when to execute scheduled\
          \ operations like running data quality checks or synchronizing the configuration\
          \ with the cloud."
      disabled:
        type: "boolean"
        description: "Disables the schedule. When the value of this 'disable' field\
          \ is false, the schedule is stored in the metadata but it is not activated\
          \ to run data quality checks."
  Mono:
    type: "object"
  MonoDqoQueueJobId:
    type: "object"
  MonoObject:
    type: "object"
  MonoVoid:
    type: "object"
  MysqlParametersSpec:
    type: "object"
    properties:
      host:
        type: "string"
        description: "MySQL host name. Supports also a ${MYSQL_HOST} configuration\
          \ with a custom environment variable."
      port:
        type: "string"
        description: "MySQL port number. The default port is 3306. Supports also a\
          \ ${MYSQL_PORT} configuration with a custom environment variable."
      database:
        type: "string"
        description: "MySQL database name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      user:
        type: "string"
        description: "MySQL user name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      password:
        type: "string"
        description: "MySQL database password. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      sslmode:
        type: "string"
        description: "SslMode MySQL connection parameter."
        enum:
        - "DISABLED"
        - "PREFERRED"
        - "REQUIRED"
        - "VERIFY_CA"
        - "VERIFY_IDENTITY"
      single_store_db_parameters_spec:
        description: "Single Store DB parameters spec."
        $ref: "#/definitions/SingleStoreDbParametersSpec"
      mysql_engine_type:
        type: "string"
        description: "MySQL engine type. Supports also a ${MYSQL_ENGINE} configuration\
          \ with a custom environment variable."
        enum:
        - "mysql"
        - "singlestoredb"
      properties:
        type: "object"
        description: "A dictionary of custom JDBC parameters that are added to the\
          \ JDBC connection string, a key/value dictionary."
        additionalProperties:
          type: "string"
  Optional:
    type: "object"
    properties:
      empty:
        type: "boolean"
      present:
        type: "boolean"
  OptionalIncidentWebhookNotificationsSpec:
    type: "object"
    properties:
      empty:
        type: "boolean"
      present:
        type: "boolean"
  OptionalMonitoringScheduleSpec:
    type: "object"
    properties:
      empty:
        type: "boolean"
      present:
        type: "boolean"
  OracleParametersSpec:
    type: "object"
    properties:
      host:
        type: "string"
        description: "Oracle host name. Supports also a ${ORACLE_HOST} configuration\
          \ with a custom environment variable."
      port:
        type: "string"
        description: "Oracle port number. The default port is 1521. Supports also\
          \ a ${ORACLE_PORT} configuration with a custom environment variable."
      database:
        type: "string"
        description: "Oracle database name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      user:
        type: "string"
        description: "Oracle user name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      password:
        type: "string"
        description: "Oracle database password. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      initialization_sql:
        type: "string"
        description: "Custom SQL that is executed after connecting to Oracle. This\
          \ SQL script can configure the default language, for example: alter session\
          \ set NLS_DATE_FORMAT='YYYY-DD-MM HH24:MI:SS'"
      properties:
        type: "object"
        description: "A dictionary of custom JDBC parameters that are added to the\
          \ JDBC connection string, a key/value dictionary."
        additionalProperties:
          type: "string"
  ParameterDefinitionSpec:
    type: "object"
    properties:
      field_name:
        type: "string"
        description: "Field name that matches the field name (snake_case) used in\
          \ the YAML specification."
      display_name:
        type: "string"
        description: "Field display name that should be shown as a label for the control."
      help_text:
        type: "string"
        description: "Help text (full description) that will be shown to the user\
          \ as a hint when the cursor is moved over the control."
      data_type:
        type: "string"
        description: "Parameter data type."
        enum:
        - "string"
        - "boolean"
        - "integer"
        - "long"
        - "double"
        - "date"
        - "datetime"
        - "column_name"
        - "enum"
        - "string_list"
        - "integer_list"
        - "object"
      display_hint:
        type: "string"
        description: "UI control display hint."
        enum:
        - "textarea"
      required:
        type: "boolean"
        description: "True when the value for the parameter must be provided."
      allowed_values:
        type: "array"
        description: "List of allowed values for a field that is of an enum type."
        items:
          type: "string"
      default_value:
        type: "string"
        description: "The default value for a parameter in a custom check or a custom\
          \ rule."
    description: "Defines a single field that is a sensor parameter or a rule parameter."
  ParquetFileFormatSpec:
    type: "object"
    properties:
      binary_as_string:
        type: "boolean"
        description: "Parquet files generated by legacy writers do not correctly set\
          \ the UTF8 flag for strings, causing string columns to be loaded as BLOB\
          \ instead. Set this to true to load binary columns as strings."
      filename:
        type: "boolean"
        description: "Whether or not an extra filename column should be included in\
          \ the result."
      file_row_number:
        type: "boolean"
        description: "Whether or not to include the file_row_number column."
      hive_partitioning:
        type: "boolean"
        description: "Whether or not to interpret the path as a hive partitioned path."
      union_by_name:
        type: "boolean"
        description: "Whether the columns of multiple schemas should be unified by\
          \ name, rather than by position."
  PartitionIncrementalTimeWindowSpec:
    type: "object"
    properties:
      daily_partitioning_recent_days:
        type: "integer"
        format: "int32"
        description: "The number of recent days analyzed by daily partition checks\
          \ in incremental mode. The default value is 7 last days."
      daily_partitioning_include_today:
        type: "boolean"
        description: "Analyze also today's data by daily partition checks in incremental\
          \ mode. The default value is false, which means that the today's and the\
          \ future partitions are not analyzed. Only yesterday's partition and previous\
          \ daily partitions are analyzed because today's data may still be incomplete.\
          \ Change the value to 'true' if the current day should also be analyzed.\
          \ This change may require you to configure the schedule for daily checks\
          \ correctly. The checks must run after the data load."
      monthly_partitioning_recent_months:
        type: "integer"
        format: "int32"
        description: "The number of recent days analyzed by monthly partition checks\
          \ in incremental mode. The default value is the previous calendar month."
      monthly_partitioning_include_current_month:
        type: "boolean"
        description: "Analyze also this month's data by monthly partition checks in\
          \ incremental mode. The default value is false, which means that the current\
          \ month is not analyzed. Future data is also filtered out because the current\
          \ month may be incomplete. Change the value to 'true' if the current month\
          \ should also be analyzed before the end of the month. This change may require\
          \ you to configure the schedule to run monthly checks more frequently (daily,\
          \ hourly, etc.)."
  PhysicalTableName:
    type: "object"
    properties:
      schema_name:
        type: "string"
        description: "Schema name"
      table_name:
        type: "string"
        description: "Table name"
  PostgresqlParametersSpec:
    type: "object"
    properties:
      host:
        type: "string"
        description: "PostgreSQL host name. Supports also a ${POSTGRESQL_HOST} configuration\
          \ with a custom environment variable."
      port:
        type: "string"
        description: "PostgreSQL port number. The default port is 5432. Supports also\
          \ a ${POSTGRESQL_PORT} configuration with a custom environment variable."
      database:
        type: "string"
        description: "PostgreSQL database name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      user:
        type: "string"
        description: "PostgreSQL user name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      password:
        type: "string"
        description: "PostgreSQL database password. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      options:
        type: "string"
        description: "PostgreSQL connection 'options' initialization parameter. For\
          \ example setting this to -c statement_timeout=5min would set the statement\
          \ timeout parameter for this session to 5 minutes. Supports also a ${POSTGRESQL_OPTIONS}\
          \ configuration with a custom environment variable."
      sslmode:
        type: "string"
        description: "Sslmode PostgreSQL connection parameter. The default value is\
          \ disabled."
        enum:
        - "disable"
        - "allow"
        - "prefer"
        - "require"
        - "verify-ca"
        - "verify-full"
      properties:
        type: "object"
        description: "A dictionary of custom JDBC parameters that are added to the\
          \ JDBC connection string, a key/value dictionary."
        additionalProperties:
          type: "string"
  PrestoParametersSpec:
    type: "object"
    properties:
      host:
        type: "string"
        description: "Presto host name. Supports also a ${PRESTO_HOST} configuration\
          \ with a custom environment variable."
      port:
        type: "string"
        description: "Presto port number. The default port is 8080. Supports also\
          \ a ${PRESTO_PORT} configuration with a custom environment variable."
      database:
        type: "string"
        description: "Presto database name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      user:
        type: "string"
        description: "Presto user name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      password:
        type: "string"
        description: "Presto database password. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      properties:
        type: "object"
        description: "A dictionary of custom JDBC parameters that are added to the\
          \ JDBC connection string, a key/value dictionary."
        additionalProperties:
          type: "string"
  ProviderSensorDefinitionSpec:
    type: "object"
    properties:
      type:
        type: "string"
        description: "Sensor implementation type"
        enum:
        - "sql_template"
        - "java_class"
      java_class_name:
        type: "string"
        description: "Java class name for a sensor runner that will execute the sensor.\
          \ The \"type\" must be \"java_class\"."
      supports_grouping:
        type: "boolean"
        description: "The sensor supports grouping, using the GROUP BY clause in SQL.\
          \ Sensors that support a GROUP BY condition can capture separate data quality\
          \ scores for each data group. The default value is true, because most of\
          \ the data quality sensor support grouping."
      supports_partitioned_checks:
        type: "boolean"
        description: "The sensor supports grouping by a partition date, using the\
          \ GROUP BY clause in SQL. Sensors that support grouping by a partition_by_column\
          \ can be used for partition checks, calculating separate data quality metrics\
          \ for each daily/monthly partition. The default value is true, because most\
          \ of the data quality sensor support partitioned checks."
      parameters:
        type: "object"
        description: "Additional provider specific sensor parameters"
        additionalProperties:
          type: "string"
      disable_merging_queries:
        type: "boolean"
        description: "Disables merging this sensor's SQL with other sensors. When\
          \ this parameter is 'true', the sensor's SQL will be executed as an independent\
          \ query."
  ProviderSensorListModel:
    type: "object"
    properties:
      provider_type:
        type: "string"
        description: "Provider type."
        enum:
        - "bigquery"
        - "databricks"
        - "mysql"
        - "oracle"
        - "postgresql"
        - "duckdb"
        - "presto"
        - "redshift"
        - "snowflake"
        - "spark"
        - "sqlserver"
        - "trino"
      custom:
        type: "boolean"
        description: "This connection specific template is a custom sensor template\
          \ or was customized by the user."
      built_in:
        type: "boolean"
        description: "This connection specific template is provided with DQOps as\
          \ a built-in sensor."
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
    description: "Provider sensor list model"
  ProviderSensorModel:
    type: "object"
    properties:
      providerType:
        type: "string"
        description: "Provider type."
        enum:
        - "bigquery"
        - "databricks"
        - "mysql"
        - "oracle"
        - "postgresql"
        - "duckdb"
        - "presto"
        - "redshift"
        - "snowflake"
        - "spark"
        - "sqlserver"
        - "trino"
      providerSensorDefinitionSpec:
        description: "Provider specific sensor definition specification"
        $ref: "#/definitions/ProviderSensorDefinitionSpec"
      sqlTemplate:
        type: "string"
        description: "Provider specific Jinja2 SQL template"
      custom:
        type: "boolean"
        description: "Whether the provider sensor is a User Home provider sensor"
      builtIn:
        type: "boolean"
        description: "This is a DQOps built-in provider sensor, whose parameters cannot\
          \ be changed."
      canEdit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yamlParsingError:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Provider sensor model"
  QualityCategoryModel:
    type: "object"
    properties:
      category:
        type: "string"
        description: "Data quality check category name."
      comparison_name:
        type: "string"
        description: "The name of the reference table configuration used for a cross\
          \ table data comparison (when the category is 'comparisons')."
      compare_to_column:
        type: "string"
        description: "The name of the column in the reference table that is compared."
      help_text:
        type: "string"
        description: "Help text that describes the category."
      checks:
        type: "array"
        description: "List of data quality checks within the category."
        items:
          $ref: "#/definitions/CheckModel"
      run_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to start the job."
        $ref: "#/definitions/CheckSearchFilters"
      data_clean_job_template:
        description: "Configured parameters for the \"data clean\" job that after\
          \ being supplied with a time range should be pushed to the job queue in\
          \ order to remove stored results connected with this quality category."
        $ref: "#/definitions/DeleteStoredDataQueueJobParameters"
    description: "Model that returns the form definition and the form data to edit\
      \ all checks within a single category."
  RedshiftParametersSpec:
    type: "object"
    properties:
      host:
        type: "string"
        description: "Redshift host name. Supports also a ${REDSHIFT_HOST} configuration\
          \ with a custom environment variable."
      port:
        type: "string"
        description: "Redshift port number. The default port is 5432. Supports also\
          \ a ${REDSHIFT_PORT} configuration with a custom environment variable."
      database:
        type: "string"
        description: "Redshift database name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      redshift_authentication_mode:
        type: "string"
        description: "The authentication mode for AWS. Supports also a ${REDSHIFT_AUTHENTICATION_MODE}\
          \ configuration with a custom environment variable."
        enum:
        - "iam"
        - "default_credentials"
        - "user_password"
      user:
        type: "string"
        description: "Redshift user name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      password:
        type: "string"
        description: "Redshift database password. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      properties:
        type: "object"
        description: "A dictionary of custom JDBC parameters that are added to the\
          \ JDBC connection string, a key/value dictionary."
        additionalProperties:
          type: "string"
  RemoteTableListModel:
    type: "object"
    properties:
      connectionName:
        type: "string"
        description: "Connection name."
      schemaName:
        type: "string"
        description: "Schema name."
      tableName:
        type: "string"
        description: "Table name."
      alreadyImported:
        type: "boolean"
        description: "A flag that tells if the table been already imported."
    description: "Table remote list model"
  RepairStoredDataQueueJobParameters:
    type: "object"
    properties:
      connectionName:
        type: "string"
      schemaTableName:
        type: "string"
      repairErrors:
        type: "boolean"
      repairStatistics:
        type: "boolean"
      repairCheckResults:
        type: "boolean"
      repairSensorReadouts:
        type: "boolean"
  RuleFolderModel:
    type: "object"
    properties:
      folders:
        type: "object"
        description: "A dictionary of nested folders with rules, the keys are the\
          \ folder names."
        additionalProperties:
          $ref: "#/definitions/RuleFolderModel"
      rules:
        type: "array"
        description: "List of rules defined in this folder."
        items:
          $ref: "#/definitions/RuleListModel"
      all_rules:
        type: "array"
        items:
          $ref: "#/definitions/RuleListModel"
    description: "Rule folder model with a list of rules defined in this folder and\
      \ nested folders that contain additional rules."
  RuleListModel:
    type: "object"
    properties:
      rule_name:
        type: "string"
        description: "Rule name without the folder."
      full_rule_name:
        type: "string"
        description: "Full rule name, including the folder within the \"rules\" rule\
          \ folder."
      custom:
        type: "boolean"
        description: "This rule has is a custom rule or was customized by the user.\
          \ This is a read-only value."
      built_in:
        type: "boolean"
        description: "This rule is provided with DQOps as a built-in rule. This is\
          \ a read-only value."
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Rule list model"
  RuleModel:
    type: "object"
    properties:
      rule_name:
        type: "string"
        description: "Rule name"
      rule_python_module_content:
        type: "string"
        description: "Rule Python module content"
      type:
        type: "string"
        description: "Rule runner type"
        enum:
        - "python"
        - "java_class"
      java_class_name:
        type: "string"
        description: "Java class name for a rule runner that will execute the sensor.\
          \ The \"type\" must be \"java_class\"."
      mode:
        type: "string"
        description: "Rule historic (past) values mode. A rule may require just the\
          \ current sensor readout or use sensor readouts from past periods to perform\
          \ prediction. The number of time windows is configured in the time_window\
          \ setting."
        enum:
        - "current_value"
        - "previous_readouts"
      time_window:
        description: "Rule time window configuration when the mode is previous_readouts.\
          \ Configures the number of past time windows (sensor readouts) that are\
          \ passes as a parameter to the rule. For example, to calculate the average\
          \ or perform prediction on historic data."
        $ref: "#/definitions/RuleTimeWindowSettingsSpec"
      fields:
        type: "array"
        description: "List of fields that are parameters of a custom rule. Those fields\
          \ are used by the DQOps UI to display the data quality check editing screens\
          \ with proper UI controls for all required fields."
        items:
          $ref: "#/definitions/ParameterDefinitionSpec"
      parameters:
        type: "object"
        description: "Additional rule parameters"
        additionalProperties:
          type: "string"
      custom:
        type: "boolean"
        description: "This rule has a custom (user level) definition."
      built_in:
        type: "boolean"
        description: "This rule has is a built-in rule."
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Rule model"
  RuleParametersModel:
    type: "object"
    properties:
      rule_name:
        type: "string"
        description: "Full rule name. This field is for information purposes and can\
          \ be used to create additional custom checks that reuse the same data quality\
          \ rule."
      rule_parameters:
        type: "array"
        description: "List of fields for editing the rule parameters like thresholds."
        items:
          $ref: "#/definitions/FieldModel"
      disabled:
        type: "boolean"
        description: "Disable the rule. The rule will not be evaluated. The sensor\
          \ will also not be executed if it has no enabled rules."
      configured:
        type: "boolean"
        description: "Returns true when the rule is configured (is not null), so it\
          \ should be shown in the UI as configured (having values)."
    description: "Model that returns the form definition and the form data to edit\
      \ parameters (thresholds) for a rule at a single severity level (low, medium,\
      \ high)."
  RuleThresholdsModel:
    type: "object"
    properties:
      error:
        description: "Rule parameters for the error severity rule."
        $ref: "#/definitions/RuleParametersModel"
      warning:
        description: "Rule parameters for the warning severity rule."
        $ref: "#/definitions/RuleParametersModel"
      fatal:
        description: "Rule parameters for the fatal severity rule."
        $ref: "#/definitions/RuleParametersModel"
    description: "Model that returns the form definition and the form data to edit\
      \ a single rule with all three threshold levels (low, medium, high)."
  RuleTimeWindowSettingsSpec:
    type: "object"
    properties:
      prediction_time_window:
        type: "integer"
        format: "int32"
        description: "Number of historic time periods to look back for results. Returns\
          \ results from previous time periods before the sensor readout timestamp\
          \ to be used in a rule. Time periods are used in rules that need historic\
          \ data to calculate an average to detect anomalies. e.g. when the sensor\
          \ is configured to use a 'day' time period, the rule will receive results\
          \ from the time_periods number of days before the time period in the sensor\
          \ readout. The default is 14 (days)."
      min_periods_with_readouts:
        type: "integer"
        format: "int32"
        description: "Minimum number of past time periods with a sensor readout that\
          \ must be present in the data in order to call the rule. The rule is not\
          \ called and the sensor readout is discarded as not analyzable (not enough\
          \ historic data to perform prediction) when the number of past sensor readouts\
          \ is not met. The default is 7."
      historic_data_point_grouping:
        type: "string"
        description: "Time period grouping for collecting previous data quality sensor\
          \ results for the data quality rules that use historic data for prediction.\
          \ For example, when the default time period grouping 'day' is used, DQOps\
          \ will find the most recent data quality sensor readout for each day and\
          \ pass an array of most recent days per day in an array of historic sensor\
          \ readout data points to a data quality rule for prediction."
        enum:
        - "year"
        - "quarter"
        - "month"
        - "week"
        - "day"
        - "hour"
        - "last_n_readouts"
  RunChecksOnTableParameters:
    type: "object"
    properties:
      connection:
        type: "string"
        description: "The name of the target connection."
      max_jobs_per_connection:
        type: "integer"
        format: "int32"
        description: "The maximum number of concurrent 'run checks on table' jobs\
          \ that can be run on this connection. Limits the number of concurrent jobs."
      table:
        description: "The full physical name (schema.table) of the target table."
        $ref: "#/definitions/PhysicalTableName"
      check_search_filters:
        description: "Target data quality checks filter."
        $ref: "#/definitions/CheckSearchFilters"
      time_window_filter:
        description: "Optional time window filter, configures the time range that\
          \ is analyzed or the number of recent days/months to analyze for day or\
          \ month partitioned data."
        $ref: "#/definitions/TimeWindowFilterParameters"
      dummy_execution:
        type: "boolean"
        description: "Set the value to true when the data quality checks should be\
          \ executed in a dummy mode (without running checks on the target systems\
          \ and storing the results). Only the jinja2 sensors will be rendered."
      run_checks_result:
        description: "The result of running the check, updated when the run checks\
          \ job finishes. Contains the count of executed checks."
        $ref: "#/definitions/RunChecksResult"
    description: "Run checks configuration for a job that will run checks on a single\
      \ table, specifies the target table and the target checks that should be executed\
      \ and an optional time window."
  RunChecksParameters:
    type: "object"
    properties:
      check_search_filters:
        description: "Target data quality checks filter."
        $ref: "#/definitions/CheckSearchFilters"
      time_window_filter:
        description: "Optional time window filter, configures the time range that\
          \ is analyzed or the number of recent days/months to analyze for day or\
          \ month partitioned data."
        $ref: "#/definitions/TimeWindowFilterParameters"
      dummy_execution:
        type: "boolean"
        description: "Set the value to true when the data quality checks should be\
          \ executed in a dummy mode (without running checks on the target systems\
          \ and storing the results). Only the jinja2 sensors will be rendered."
      run_checks_result:
        description: "The result of running the check, updated when the run checks\
          \ job finishes. Contains the count of executed checks."
        $ref: "#/definitions/RunChecksResult"
    description: "Run checks configuration, specifies the target checks that should\
      \ be executed and an optional time window."
  RunChecksQueueJobResult:
    type: "object"
    properties:
      jobId:
        description: "Job id that identifies a job that was started on the DQOps job\
          \ queue."
        $ref: "#/definitions/DqoQueueJobId"
      result:
        description: "Optional result object that is returned only when the wait parameter\
          \ was true and the \"run checks\" job has finished. Contains the summary\
          \ result of the data quality checks executed, including the severity of\
          \ the most severe issue detected. The calling code (the data pipeline) can\
          \ decide if further processing should be continued."
        $ref: "#/definitions/RunChecksResult"
      status:
        type: "string"
        description: "Job status"
        enum:
        - "queued"
        - "running"
        - "waiting"
        - "finished"
        - "failed"
        - "cancel_requested"
        - "cancelled"
    description: "Object returned from the operation that queues a \"run checks\"\
      \ job. The result contains the job id that was started and optionally can also\
      \ contain the result of running the checks if the operation was started with\
      \ wait=true parameter to wait for the \"run checks\" job to finish."
  RunChecksResult:
    type: "object"
    properties:
      highest_severity:
        type: "string"
        description: "The highest check severity for the data quality checks executed\
          \ in this batch."
        enum:
        - "valid"
        - "warning"
        - "error"
        - "fatal"
      executed_checks:
        type: "integer"
        format: "int32"
        description: "The total count of all executed checks."
      valid_results:
        type: "integer"
        format: "int32"
        description: "The total count of all checks that finished successfully (with\
          \ no data quality issues)."
      warnings:
        type: "integer"
        format: "int32"
        description: "The total count of all invalid data quality checks that finished\
          \ raising a warning."
      errors:
        type: "integer"
        format: "int32"
        description: "The total count of all invalid data quality checks that finished\
          \ raising an error."
      fatals:
        type: "integer"
        format: "int32"
        description: "The total count of all invalid data quality checks that finished\
          \ raising a fatal error."
      execution_errors:
        type: "integer"
        format: "int32"
        description: "The total number of checks that failed to execute due to some\
          \ execution errors."
    description: "Returns the result (highest data quality check severity and the\
      \ finished checks count) for the checks that were recently executed."
  SchemaModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      schema_name:
        type: "string"
        description: "Schema name."
      directory_prefix:
        type: "string"
        description: "Directory prefix."
      run_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run all checks within this schema."
        $ref: "#/definitions/CheckSearchFilters"
      run_profiling_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run profiling checks within this\
          \ schema."
        $ref: "#/definitions/CheckSearchFilters"
      run_monitoring_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run monitoring checks within this\
          \ schema."
        $ref: "#/definitions/CheckSearchFilters"
      run_partition_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run partition partitioned checks\
          \ within this schema."
        $ref: "#/definitions/CheckSearchFilters"
      collect_statistics_job_template:
        description: "Configured parameters for the \"collect statistics\" job that\
          \ should be pushed to the job queue in order to run all statistics collectors\
          \ within this schema."
        $ref: "#/definitions/StatisticsCollectorSearchFilters"
      import_table_job_parameters:
        description: "Job parameters for the import tables job that will import all\
          \ tables from this schema."
        $ref: "#/definitions/ImportTablesQueueJobParameters"
      data_clean_job_template:
        description: "Configured parameters for the \"data clean\" job that after\
          \ being supplied with a time range should be pushed to the job queue in\
          \ order to remove stored results connected with this schema."
        $ref: "#/definitions/DeleteStoredDataQueueJobParameters"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete the schema."
      can_collect_statistics:
        type: "boolean"
        description: "Boolean flag that decides if the current user can collect statistics."
      can_run_checks:
        type: "boolean"
        description: "Boolean flag that decides if the current user can run checks."
      can_delete_data:
        type: "boolean"
        description: "Boolean flag that decides if the current user can delete data\
          \ (results)."
      error_message:
        type: "string"
        description: "Field for error message."
    description: "Schema model"
  SchemaRemoteModel:
    type: "object"
    properties:
      connectionName:
        type: "string"
        description: "Connection name."
      schemaName:
        type: "string"
        description: "Schema name."
      alreadyImported:
        type: "boolean"
        description: "Has the schema been imported."
      importTableJobParameters:
        description: "Job parameters for the import tables job that will import all\
          \ tables from this schema."
        $ref: "#/definitions/ImportTablesQueueJobParameters"
    description: "Schema remote model"
  SensorDefinitionSpec:
    type: "object"
    properties:
      fields:
        type: "array"
        description: "List of fields that are parameters of a custom sensor. Those\
          \ fields are used by the DQOps UI to display the data quality check editing\
          \ screens with proper UI controls for all required fields."
        items:
          $ref: "#/definitions/ParameterDefinitionSpec"
      requires_event_timestamp:
        type: "boolean"
        description: "The data quality sensor depends on the configuration of the\
          \ event timestamp column name on the analyzed table. When true, the name\
          \ of the column that stores the event (transaction, etc.) timestamp must\
          \ be specified in the timestamp_columns.event_timestamp_column field on\
          \ the table."
      requires_ingestion_timestamp:
        type: "boolean"
        description: "The data quality sensor depends on the configuration of the\
          \ ingestion timestamp column name on the analyzed table. When true, the\
          \ name of the column that stores the ingestion (created_at, loaded_at, etc.)\
          \ timestamp must be specified in the timestamp_columns.ingestion_timestamp_column\
          \ field on the table."
      default_value:
        type: "number"
        format: "double"
        description: "Default value that is used when the sensor returns no rows.\
          \ A row count sensor may return no rows when a GROUP BY condition is added\
          \ to capture the database server's local time zone. In order to always return\
          \ a value, a sensor may have a default value configured."
      parameters:
        type: "object"
        description: "Additional sensor definition parameters"
        additionalProperties:
          type: "string"
  SensorFolderModel:
    type: "object"
    properties:
      folders:
        type: "object"
        description: "A dictionary of nested folders with sensors, the keys are the\
          \ folder names."
        additionalProperties:
          $ref: "#/definitions/SensorFolderModel"
      sensors:
        type: "array"
        description: "List of sensors defined in this folder."
        items:
          $ref: "#/definitions/SensorListModel"
      all_sensors:
        type: "array"
        items:
          $ref: "#/definitions/SensorListModel"
    description: "Sensor folder model that contains sensors defined in this folder\
      \ or a list of nested folders with sensors."
  SensorListModel:
    type: "object"
    properties:
      sensor_name:
        type: "string"
        description: "Sensor name, excluding the parent folder."
      full_sensor_name:
        type: "string"
        description: "Full sensor name, including the folder path within the \"sensors\"\
          \ folder where the sensor definitions are stored. This is the unique identifier\
          \ of the sensor."
      custom:
        type: "boolean"
        description: "This sensor has is a custom sensor or was customized by the\
          \ user. This is a read-only flag."
      built_in:
        type: "boolean"
        description: "This sensor is provided with DQOps as a built-in sensor. This\
          \ is a read-only flag."
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      provider_sensors:
        type: "array"
        description: "List of provider (database) specific models."
        items:
          $ref: "#/definitions/ProviderSensorListModel"
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Sensor list model"
  SensorModel:
    type: "object"
    properties:
      full_sensor_name:
        type: "string"
        description: "Full sensor name."
      sensor_definition_spec:
        description: "Sensor definition specification."
        $ref: "#/definitions/SensorDefinitionSpec"
      provider_sensor_list:
        type: "array"
        description: "Provider sensors list with provider specific sensor definitions."
        items:
          $ref: "#/definitions/ProviderSensorModel"
      custom:
        type: "boolean"
        description: "Whether the sensor is a User Home sensor"
      built_in:
        type: "boolean"
        description: "This is a DQOps built-in sensor, whose parameters cannot be\
          \ changed."
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Sensor model that describes the configuration of a single built-in\
      \ or custom sensor."
  SensorReadoutEntryModel:
    type: "object"
    properties:
      id:
        type: "string"
        description: "Sensor readout primary key"
      checkName:
        type: "string"
        description: "Check name"
      checkDisplayName:
        type: "string"
        description: "Check display name"
      checkType:
        type: "string"
        description: "Check type"
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      actualValue:
        type: "number"
        format: "double"
        description: "Actual value"
      expectedValue:
        type: "number"
        format: "double"
        description: "Expected value"
      columnName:
        type: "string"
        description: "Column name"
      dataGroup:
        type: "string"
        description: "Data group"
      durationMs:
        type: "integer"
        format: "int32"
        description: "Duration (ms)"
      executedAt:
        type: "integer"
        format: "int64"
        description: "Executed at"
      timeGradient:
        type: "string"
        description: "Time gradient"
        enum:
        - "year"
        - "quarter"
        - "month"
        - "week"
        - "day"
        - "hour"
        - "millisecond"
      timePeriod:
        type: "string"
        format: "date-time"
        description: "Time period"
      provider:
        type: "string"
        description: "Provider name"
      qualityDimension:
        type: "string"
        description: "Data quality dimension"
      tableComparison:
        type: "string"
        description: "Table comparison name"
  SensorReadoutsListModel:
    type: "object"
    properties:
      checkName:
        type: "string"
        description: "Check name"
      checkDisplayName:
        type: "string"
        description: "Check display name"
      checkType:
        type: "string"
        description: "Check type"
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      checkHash:
        type: "integer"
        format: "int64"
        description: "Check hash"
      checkCategory:
        type: "string"
        description: "Check category name"
      sensorName:
        type: "string"
        description: "Sensor name"
      dataGroupNames:
        type: "array"
        description: "List of data groups that have values for this sensor readout\
          \ (list of time series)"
        items:
          type: "string"
      dataGroup:
        type: "string"
        description: "Selected data group"
      sensorReadoutEntries:
        type: "array"
        description: "Sensor readout entries"
        items:
          $ref: "#/definitions/SensorReadoutEntryModel"
  SharedCredentialListModel:
    type: "object"
    properties:
      credential_name:
        type: "string"
        description: "Credential name. It is the name of a file in the .credentials/\
          \ folder inside the DQOps user's home folder."
      type:
        type: "string"
        description: "Credential type that is based on the detected format of the\
          \ file. If the file can be parsed as a valid utf-8 string, it is assumed\
          \ that the credential is a text. Otherwise, it is a binary file that can\
          \ only be retrieved as a base64 value."
        enum:
        - "text"
        - "binary"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete the shared credential file."
      can_access_credential:
        type: "boolean"
        description: "Boolean flag that decides if the current user see or download\
          \ the credential file."
    description: "Shared credentials list model with the basic information about the\
      \ credential."
  SharedCredentialModel:
    type: "object"
    properties:
      credential_name:
        type: "string"
        description: "Credential name. It is the name of a file in the .credentials/\
          \ folder inside the DQOps user's home folder."
      type:
        type: "string"
        description: "Credential type that is based on the detected format of the\
          \ file. If the file can be parsed as a valid utf-8 string, then it is assumed\
          \ that the credential is a text. Otherwise, it is a binary file that can\
          \ only be retrieved as a base64 value."
        enum:
        - "text"
        - "binary"
      text_value:
        type: "string"
        description: "Credential's value as a text. Only one value (the text_value\
          \ or binary_value) should be not empty."
      binary_value:
        type: "string"
        description: "Credential's value for a binary credential that is stored as\
          \ a base64 value. Only one value (the text_value or binary_value) should\
          \ be not empty."
    description: "Shared credentials full model used to create and update the credential.\
      \ Contains one of two forms of the credential's value: a text or a base64 binary\
      \ value."
  SimilarCheckModel:
    type: "object"
    properties:
      check_target:
        type: "string"
        description: "The check target (table or column)."
        enum:
        - "table"
        - "column"
      check_type:
        type: "string"
        description: "The check type."
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      time_scale:
        type: "string"
        description: "The time scale (daily, monthly). The time scale is optional\
          \ and can be null (for profiling checks)."
        enum:
        - "daily"
        - "monthly"
      category:
        type: "string"
        description: "The check's category."
      check_name:
        type: "string"
        description: "Similar check name in another category."
    description: "Model that identifies a similar check in another category or another\
      \ type of check (monitoring, partition)."
  SingleStoreDbParametersSpec:
    type: "object"
    properties:
      load_balancing_mode:
        type: "string"
        description: "SingleStoreDB Failover and Load-Balancing Modes for Single Store\
          \ DB. The value can be in the ${ENVIRONMENT_VARIABLE_NAME} format to use\
          \ dynamic substitution."
        enum:
        - "none"
        - "sequential"
        - "loadbalance"
      host_descriptions:
        type: "array"
        description: "SingleStoreDB Host descriptions. Supports also a ${SINGLE_STORE_HOST_DESCRIPTIONS}\
          \ configuration with a custom environment variable."
        items:
          type: "string"
      schema:
        type: "string"
        description: "SingleStoreDB database/schema name. The value can be in the\
          \ ${ENVIRONMENT_VARIABLE_NAME} format to use dynamic substitution."
      use_ssl:
        type: "boolean"
        description: "Force enables SSL/TLS on the connection. Supports also a ${SINGLE_STORE_USE_SSL}\
          \ configuration with a custom environment variable."
  SnowflakeParametersSpec:
    type: "object"
    properties:
      account:
        type: "string"
        description: "Snowflake account name, e.q. <account>, <account>-<locator>,\
          \ <account>.<region> or <account>.<region>.<platform>.. Supports also a\
          \ ${SNOWFLAKE_ACCOUNT} configuration with a custom environment variable."
      warehouse:
        type: "string"
        description: "Snowflake warehouse name. Supports also a ${SNOWFLAKE_WAREHOUSE}\
          \ configuration with a custom environment variable."
      database:
        type: "string"
        description: "Snowflake database name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      user:
        type: "string"
        description: "Snowflake user name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      password:
        type: "string"
        description: "Snowflake database password. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      role:
        type: "string"
        description: "Snowflake role name. Supports also ${SNOWFLAKE_ROLE} configuration\
          \ with a custom environment variable."
      properties:
        type: "object"
        description: "A dictionary of custom JDBC parameters that are added to the\
          \ JDBC connection string, a key/value dictionary."
        additionalProperties:
          type: "string"
  SparkParametersSpec:
    type: "object"
    properties:
      host:
        type: "string"
        description: "Spark host name. Supports also a ${SPARK_HOST} configuration\
          \ with a custom environment variable."
      port:
        type: "string"
        description: "Spark port number. The default port is 10000. Supports also\
          \ a ${SPARK_PORT} configuration with a custom environment variable."
      user:
        type: "string"
        description: "Spark user name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      password:
        type: "string"
        description: "Spark database password. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      properties:
        type: "object"
        description: "A dictionary of custom JDBC parameters that are added to the\
          \ JDBC connection string, a key/value dictionary."
        additionalProperties:
          type: "string"
      database:
        type: "string"
  SpringErrorPayload:
    type: "object"
    properties:
      timestamp:
        type: "integer"
        format: "int64"
        description: "Error timestamp as an epoch timestamp."
      status:
        type: "integer"
        format: "int32"
        description: "Optional status code."
      error:
        type: "string"
        description: "Error name."
      exception:
        type: "string"
        description: "Optional exception."
      message:
        type: "string"
        description: "Exception's message."
      path:
        type: "string"
        description: "Exception's stack trace (optional)."
    description: "Spring error payload that identifies the fields in the error returned\
      \ by the REST API in case of unexpected errors (exceptions)."
  SqlServerParametersSpec:
    type: "object"
    properties:
      host:
        type: "string"
        description: "SQL Server host name. Supports also a ${SQLSERVER_HOST} configuration\
          \ with a custom environment variable."
      port:
        type: "string"
        description: "SQL Server port number. The default port is 1433. Supports also\
          \ a ${SQLSERVER_PORT} configuration with a custom environment variable."
      database:
        type: "string"
        description: "SQL Server database name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      user:
        type: "string"
        description: "SQL Server user name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      password:
        type: "string"
        description: "SQL Server database password. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      disable_encryption:
        type: "boolean"
        description: "Disable SSL encryption parameter. The default value is false.\
          \ You may need to disable encryption when SQL Server is started in Docker."
      authentication_mode:
        type: "string"
        description: "Authenticaiton mode for the SQL Server. The value can be in\
          \ the ${ENVIRONMENT_VARIABLE_NAME} format to use dynamic substitution."
        enum:
        - "sql_password"
        - "active_directory_password"
        - "active_directory_service_principal"
        - "active_directory_default"
      properties:
        type: "object"
        description: "A dictionary of custom JDBC parameters that are added to the\
          \ JDBC connection string, a key/value dictionary."
        additionalProperties:
          type: "string"
  StatisticsCollectorSearchFilters:
    type: "object"
    properties:
      connection:
        type: "string"
        description: "The connection (data source) name. Supports search patterns\
          \ in the format: 'source\\*', '\\*_prod', 'prefix\\*suffix'."
      fullTableName:
        type: "string"
        description: "The schema and table name. It is provided as *<schema_name>.<table_name>*,\
          \ for example *public.fact_sales*. The schema and table name accept patterns\
          \ both in the schema name and table name parts. Sample patterns are: 'schema_name.tab_prefix_\\\
          *', 'schema_name.*', '*.*', 'schema_name.\\*_customer', 'schema_name.tab_\\\
          *_suffix'."
      enabled:
        type: "boolean"
        description: "A boolean flag to target enabled tables, columns or checks.\
          \ When the value of this field is not set, the default value of this field\
          \ is *true*, targeting only tables, columns and checks that are not implicitly\
          \ disabled."
      tags:
        type: "array"
        description: "An array of tags assigned to the table. All tags must be present\
          \ on a table to match. The tags can use patterns:  'prefix\\*', '\\*suffix',\
          \ 'prefix\\*suffix'. The tags are assigned to the table on the data grouping\
          \ screen when any of the data grouping hierarchy level is assigned a static\
          \ value, which is a tag."
        items:
          type: "string"
      labels:
        type: "array"
        description: "An array of labels assigned to the table. All labels must be\
          \ present on a table to match. The labels can use patterns:  'prefix\\*',\
          \ '\\*suffix', 'prefix\\*suffix'. The labels are assigned on the labels\
          \ screen and stored in the *labels* node in the *.dqotable.yaml* file."
        items:
          type: "string"
      maxResults:
        type: "integer"
        format: "int32"
        description: "Optional limit for the maximum number of results to return."
      columnNames:
        type: "array"
        description: "The list of column names or column name patters. This field\
          \ accepts search patterns in the format: 'fk_\\*', '\\*_id', 'prefix\\*suffix'."
        items:
          type: "string"
      collectorName:
        type: "string"
        description: "The target statistics collector name to capture only selected\
          \ statistics. Uses the short collector nameThis field supports search patterns\
          \ such as: 'prefix\\*', '\\*suffix', 'prefix_\\*_suffix'. In order to collect\
          \ only top 10 most common column samples, use 'column_samples'."
      sensorName:
        type: "string"
        description: "The target sensor name to run only data quality checks that\
          \ are using this sensor. Uses the full sensor name which is the full folder\
          \ path within the *sensors* folder. This field supports search patterns\
          \ such as: 'table/volume/row_\\*', '\\*_count', 'table/volume/prefix_\\\
          *_suffix'."
      collectorCategory:
        type: "string"
        description: "The target statistics collector category, for example: *nulls*,\
          \ *volume*, *sampling*."
      target:
        type: "string"
        description: "The target type of object to collect statistics from. Supported\
          \ values are: *table* to collect only table level statistics or *column*\
          \ to collect only column level statistics."
        enum:
        - "table"
        - "column"
      collectorsHierarchyIdsModels:
        type: "array"
        items:
          $ref: "#/definitions/HierarchyIdModel"
  StatisticsMetricModel:
    type: "object"
    properties:
      category:
        type: "string"
        description: "Statistics category"
      collector:
        type: "string"
        description: "Statistics (metric) name"
      resultDataType:
        type: "string"
        description: "Statistics result data type"
        enum:
        - "null"
        - "boolean"
        - "string"
        - "integer"
        - "float"
        - "date"
        - "datetime"
        - "instant"
        - "time"
      result:
        type: "object"
        description: "Statistics result for the metric"
      collectedAt:
        type: "string"
        format: "date-time"
        description: "The local timestamp when the metric was collected"
      sampleCount:
        type: "integer"
        format: "int64"
        description: "The number of the value samples for this result value. Filled\
          \ only by the column value sampling profilers."
      sampleIndex:
        type: "integer"
        format: "int32"
        description: "The index of the result that was returned. Filled only by the\
          \ column value sampling profilers to identify each column value sample."
  SynchronizeMultipleFoldersDqoQueueJobParameters:
    type: "object"
    properties:
      direction:
        type: "string"
        description: "File synchronization direction, the default is full synchronization\
          \ (push local changes and pull other changes from DQOps Cloud)."
        enum:
        - "full"
        - "download"
        - "upload"
      forceRefreshNativeTables:
        type: "boolean"
        description: "Force full refresh of native tables in the data quality data\
          \ warehouse. The default synchronization mode is to refresh only modified\
          \ data."
      detectCronSchedules:
        type: "boolean"
        description: "Scans the yaml files (with the configuration for connections\
          \ and tables) and detects new cron schedules. Detected cron schedules are\
          \ registered in the cron (Quartz) job scheduler."
      sources:
        type: "boolean"
        description: "Synchronize the \"sources\" folder."
      sensors:
        type: "boolean"
        description: "Synchronize the \"sensors\" folder."
      rules:
        type: "boolean"
        description: "Synchronize the \"rules\" folder."
      checks:
        type: "boolean"
        description: "Synchronize the \"checks\" folder."
      settings:
        type: "boolean"
        description: "Synchronize the \"settings\" folder."
      credentials:
        type: "boolean"
        description: "Synchronize the \".credentials\" folder."
      dictionaries:
        type: "boolean"
        description: "Synchronize the \"dictionaries\" folder."
      patterns:
        type: "boolean"
        description: "Synchronize the \"patterns\" folder."
      dataSensorReadouts:
        type: "boolean"
        description: "Synchronize the \".data/sensor_readouts\" folder."
      dataCheckResults:
        type: "boolean"
        description: "Synchronize the \".data/check_results\" folder."
      dataStatistics:
        type: "boolean"
        description: "Synchronize the \".data/statistics\" folder."
      dataErrors:
        type: "boolean"
        description: "Synchronize the \".data/errors\" folder."
      dataIncidents:
        type: "boolean"
        description: "Synchronize the \".data/incidents\" folder."
      synchronizeFolderWithLocalChanges:
        type: "boolean"
        description: "Synchronize all folders that have local changes. When this field\
          \ is set to true, there is no need to enable synchronization of single folders\
          \ because DQOps will decide which folders need synchronization (to be pushed\
          \ to the cloud)."
  SynchronizeMultipleFoldersQueueJobResult:
    type: "object"
    properties:
      jobId:
        description: "Job id that identifies a job that was started on the DQOps job\
          \ queue."
        $ref: "#/definitions/DqoQueueJobId"
      status:
        type: "string"
        description: "Job status"
        enum:
        - "queued"
        - "running"
        - "waiting"
        - "finished"
        - "failed"
        - "cancel_requested"
        - "cancelled"
    description: "Object returned from the operation that queues a \"synchronize multiple\
      \ folders\" job. The result contains the job id that was started and optionally\
      \ can also contain the job finish status if the operation was started with wait=true\
      \ parameter to wait for the \"synchronize multiple folders\" job to finish."
  SynchronizeRootFolderDqoQueueJobParameters:
    type: "object"
    properties:
      synchronizationParameter:
        $ref: "#/definitions/SynchronizeRootFolderParameters"
  SynchronizeRootFolderParameters:
    type: "object"
    properties:
      folder:
        type: "string"
        enum:
        - "data_sensor_readouts"
        - "data_check_results"
        - "data_statistics"
        - "data_errors"
        - "data_incidents"
        - "sources"
        - "sensors"
        - "rules"
        - "checks"
        - "settings"
        - "credentials"
        - "dictionaries"
        - "patterns"
        - "_indexes"
        - "_local_settings"
      direction:
        type: "string"
        enum:
        - "full"
        - "download"
        - "upload"
      forceRefreshNativeTable:
        type: "boolean"
  TableAccuracyDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_total_row_count_match_percent:
        description: "Verifies the total ow count of a tested table and compares it\
          \ to a row count of a reference table. Stores the most recent captured value\
          \ for each day when the data quality check was evaluated."
        $ref: "#/definitions/TableAccuracyTotalRowCountMatchPercentCheckSpec"
  TableAccuracyMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_total_row_count_match_percent:
        description: "Verifies the total row count of a tested table and compares\
          \ it to a row count of a reference table. Stores the most recent check result\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/TableAccuracyTotalRowCountMatchPercentCheckSpec"
  TableAccuracyProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_total_row_count_match_percent:
        description: "Verifies that the total row count of the tested table matches\
          \ the total row count of another (reference) table."
        $ref: "#/definitions/TableAccuracyTotalRowCountMatchPercentCheckSpec"
  TableAccuracyTotalRowCountMatchPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters. Fill the parameters to provide\
          \ the name of the referenced table."
        $ref: "#/definitions/TableAccuracyTotalRowCountMatchPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Default alerting threshold for a maximum percentage of difference\
          \ of row count of a table column and of a row count of another table column\
          \ that raises a data quality error (alert)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  TableAccuracyTotalRowCountMatchPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      referenced_table:
        type: "string"
        description: "The name of the reference table. DQOps accepts the name in two\
          \ forms: a fully qualified name including the schema name, for example landing_zone.customer_raw,\
          \ or only a table name. When only a table name is used, DQOps assumes that\
          \ the table is in the same schema as the analyzed table, and prefixes the\
          \ name with the schema and optionally database name."
  TableAvailabilityCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Table availability sensor parameters"
        $ref: "#/definitions/TableAvailabilitySensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxFailuresRule0ParametersSpec"
      error:
        description: "Default alerting threshold with the maximum number of consecutive\
          \ table availability issues that raises a data quality error (alert)"
        $ref: "#/definitions/MaxFailuresRule1ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxFailuresRule5ParametersSpec"
  TableAvailabilityDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_table_availability:
        description: "Verifies availability of a table in a monitored database using\
          \ a simple query. Stores the most recent table availability status for each\
          \ day when the data quality check was evaluated."
        $ref: "#/definitions/TableAvailabilityCheckSpec"
  TableAvailabilityMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_table_availability:
        description: "Verifies availability of a table in a monitored database using\
          \ a simple query. Stores the most recent table availability status for each\
          \ month when the data quality check was evaluated."
        $ref: "#/definitions/TableAvailabilityCheckSpec"
  TableAvailabilityProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_table_availability:
        description: "Verifies availability of a table in a monitored database using\
          \ a simple query."
        $ref: "#/definitions/TableAvailabilityCheckSpec"
  TableAvailabilitySensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  TableColumnCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  TableColumnListOrderedHashSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  TableColumnListUnorderedHashSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  TableColumnTypesHashSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  TableColumnsStatisticsModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      table:
        description: "Physical table name including the schema and table names."
        $ref: "#/definitions/PhysicalTableName"
      column_statistics:
        type: "array"
        description: "List of collected column level statistics for all columns."
        items:
          $ref: "#/definitions/ColumnStatisticsModel"
      collect_column_statistics_job_template:
        description: "Configured parameters for the \"collect statistics\" job that\
          \ should be pushed to the job queue in order to run all statistics collectors\
          \ for all columns on this table."
        $ref: "#/definitions/StatisticsCollectorSearchFilters"
      can_collect_statistics:
        type: "boolean"
        description: "Boolean flag that decides if the current user can collect statistics."
    description: "Model that returns a summary of the column statistics (the basic\
      \ profiling results) for a single table, showing statistics for all columns."
  TableComparisonColumnCountMatchCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Column count data quality sensor."
        $ref: "#/definitions/TableColumnCountSensorParametersSpec"
      warning:
        description: "Warning level threshold to raise a data quality incident with\
          \ a warning severity level when the column count in the parent table and\
          \ the reference table do not match. The alert is generated for every compared\
          \ group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Error level threshold to raise a data quality incident with\
          \ an error severity level when the column count in the parent table and\
          \ the reference table do not match. The alert is generated for every compared\
          \ group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Fatal level threshold to raise a data quality incident with\
          \ a fatal severity level when the column count in the parent table and the\
          \ reference table do not match. The alert is generated for every compared\
          \ group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  TableComparisonColumnResultsModel:
    type: "object"
    properties:
      column_name:
        type: "string"
        description: "Column name"
      column_comparison_results:
        type: "object"
        description: "The dictionary of comparison results between the tables for\
          \ the specific column. The keys for the dictionary are check names. The\
          \ values are summaries of the most recent comparison on this column."
        additionalProperties:
          $ref: "#/definitions/ComparisonCheckResultModel"
    description: "The table comparison column results model with the information about\
      \ the most recent table comparison relating to a single compared column."
  TableComparisonConfigurationModel:
    type: "object"
    properties:
      table_comparison_configuration_name:
        type: "string"
        description: "The name of the table comparison configuration that is defined\
          \ in the 'table_comparisons' node on the table specification."
      compared_connection:
        type: "string"
        description: "Compared connection name - the connection name to the data source\
          \ that is compared (verified)."
      compared_table:
        description: "The schema and table name of the compared table that is verified."
        $ref: "#/definitions/PhysicalTableName"
      reference_connection:
        type: "string"
        description: "Reference connection name - the connection name to the data\
          \ source that has the reference data to compare to."
      reference_table:
        description: "The schema and table name of the reference table that has the\
          \ expected data."
        $ref: "#/definitions/PhysicalTableName"
      check_type:
        type: "string"
        description: "The type of checks (profiling, monitoring, partitioned) that\
          \ this check comparison configuration is applicable. The default value is\
          \ 'profiling'."
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      time_scale:
        type: "string"
        description: "The time scale that this check comparison configuration is applicable.\
          \ Supported values are 'daily' and 'monthly' for monitoring and partitioned\
          \ checks or an empty value for profiling checks."
        enum:
        - "daily"
        - "monthly"
      grouping_columns:
        type: "array"
        description: "List of column pairs from both the compared table and the reference\
          \ table that are used in a GROUP BY clause  for grouping both the compared\
          \ table and the reference table (the source of truth). The columns are used\
          \ in the next of the table comparison to join the results of data groups\
          \ (row counts, sums of columns) between the compared table and the reference\
          \ table to compare the differences."
        items:
          $ref: "#/definitions/TableComparisonGroupingColumnPairModel"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete the table comparison."
      can_run_compare_checks:
        type: "boolean"
        description: "Boolean flag that decides if the current user can run comparison\
          \ checks."
      can_delete_data:
        type: "boolean"
        description: "Boolean flag that decides if the current user can delete data\
          \ (results)."
    description: "Model that contains the basic information about a table comparison\
      \ configuration that specifies how the current table can be compared with another\
      \ table that is a source of truth for comparison."
  TableComparisonConfigurationSpec:
    type: "object"
    properties:
      reference_table_connection_name:
        type: "string"
        description: "The name of the connection in DQOp where the reference table\
          \ (the source of truth) is configured. When the connection name is not provided,\
          \ DQOps will find the reference table on the connection of the parent table."
      reference_table_schema_name:
        type: "string"
        description: "The name of the schema where the reference table is imported\
          \ into DQOps. The reference table's metadata must be imported into DQOps."
      reference_table_name:
        type: "string"
        description: "The name of the reference table that is imported into DQOps.\
          \ The reference table's metadata must be imported into DQOps."
      compared_table_filter:
        type: "string"
        description: "Optional custom SQL filter expression that is added to the SQL\
          \ query that retrieves the data from the compared table. This expression\
          \ must be a SQL expression that will be added to the WHERE clause when querying\
          \ the compared table."
      reference_table_filter:
        type: "string"
        description: "Optional custom SQL filter expression that is added to the SQL\
          \ query that retrieves the data from the reference table (the source of\
          \ truth). This expression must be a SQL expression that will be added to\
          \ the WHERE clause when querying the reference table."
      check_type:
        type: "string"
        description: "The type of checks (profiling, monitoring, partitioned) that\
          \ this check comparison configuration is applicable. The default value is\
          \ 'profiling'."
        enum:
        - "profiling"
        - "monitoring"
        - "partitioned"
      time_scale:
        type: "string"
        description: "The time scale that this check comparison configuration is applicable.\
          \ Supported values are 'daily' and 'monthly' for monitoring and partitioned\
          \ checks or an empty value for profiling checks."
        enum:
        - "daily"
        - "monthly"
      grouping_columns:
        type: "array"
        description: "List of column pairs from both the compared table and the reference\
          \ table that are used in a GROUP BY clause  for grouping both the compared\
          \ table and the reference table (the source of truth). The columns are used\
          \ in the next of the table comparison to join the results of data groups\
          \ (row counts, sums of columns) between the compared table and the reference\
          \ table to compare the differences."
        items:
          $ref: "#/definitions/TableComparisonGroupingColumnsPairSpec"
  TableComparisonDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_row_count_match:
        description: "Verifies that the row count of the tested (parent) table matches\
          \ the row count of the reference table. Compares each group of data with\
          \ a GROUP BY clause. Stores the most recent captured value for each day\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/TableComparisonRowCountMatchCheckSpec"
      daily_column_count_match:
        description: "Verifies that the column count of the tested (parent) table\
          \ matches the column count of the reference table. Only one comparison result\
          \ is returned, without data grouping. Stores the most recent captured value\
          \ for each day when the data quality check was evaluated."
        $ref: "#/definitions/TableComparisonColumnCountMatchCheckSpec"
  TableComparisonDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_row_count_match:
        description: "Verifies that the row count of the tested (parent) table matches\
          \ the row count of the reference table. Compares each group of data with\
          \ a GROUP BY clause on the time period (the daily partition) and all other\
          \ data grouping columns. Stores the most recent captured value for each\
          \ daily partition that was analyzed."
        $ref: "#/definitions/TableComparisonRowCountMatchCheckSpec"
  TableComparisonGroupingColumnPairModel:
    type: "object"
    properties:
      compared_table_column_name:
        type: "string"
        description: "The name of the column on the compared table (the parent table)\
          \ that is used in the GROUP BY clause to group rows before compared aggregates\
          \ (row counts, sums, etc.) are calculated. This column is also used to join\
          \ (match) results to the reference table."
      reference_table_column_name:
        type: "string"
        description: "The name of the column on the reference table (the source of\
          \ truth) that is used in the GROUP BY clause to group rows before compared\
          \ aggregates (row counts, sums, etc.) are calculated. This column is also\
          \ used to join (match) results to the compared table."
    description: "Model that identifies a pair of column names used for grouping the\
      \ data on both the compared table and the reference table. The groups are then\
      \ matched (joined) by DQOps to compare aggregated results."
  TableComparisonGroupingColumnsPairSpec:
    type: "object"
    properties:
      compared_table_column_name:
        type: "string"
        description: "The name of the column on the compared table (the parent table)\
          \ that is used in the GROUP BY clause to group rows before compared aggregates\
          \ (row counts, sums, etc.) are calculated. This column is also used to join\
          \ (match) results to the reference table."
      reference_table_column_name:
        type: "string"
        description: "The name of the column on the reference table (the source of\
          \ truth) that is used in the GROUP BY clause to group rows before compared\
          \ aggregates (row counts, sums, etc.) are calculated. This column is also\
          \ used to join (match) results to the compared table."
  TableComparisonModel:
    type: "object"
    properties:
      table_comparison_configuration_name:
        type: "string"
        description: "The name of the table comparison configuration that is defined\
          \ in the 'table_comparisons' node on the table specification."
      compared_connection:
        type: "string"
        description: "Compared connection name - the connection name to the data source\
          \ that is compared (verified)."
      compared_table:
        description: "The schema and table name of the compared table that is verified."
        $ref: "#/definitions/PhysicalTableName"
      reference_connection:
        type: "string"
        description: "Reference connection name - the connection name to the data\
          \ source that has the reference data to compare to."
      reference_table:
        description: "The schema and table name of the reference table that has the\
          \ expected data."
        $ref: "#/definitions/PhysicalTableName"
      grouping_columns:
        type: "array"
        description: "List of column pairs from both the compared table and the reference\
          \ table that are used in a GROUP BY clause  for grouping both the compared\
          \ table and the reference table (the source of truth). The columns are used\
          \ in the next of the table comparison to join the results of data groups\
          \ (row counts, sums of columns) between the compared table and the reference\
          \ table to compare the differences."
        items:
          $ref: "#/definitions/TableComparisonGroupingColumnPairModel"
      default_compare_thresholds:
        description: "The template of the compare thresholds that should be applied\
          \ to all comparisons when the comparison is enabled."
        $ref: "#/definitions/CompareThresholdsModel"
      compare_row_count:
        description: "The row count comparison configuration."
        $ref: "#/definitions/CompareThresholdsModel"
      compare_column_count:
        description: "The column count comparison configuration."
        $ref: "#/definitions/CompareThresholdsModel"
      supports_compare_column_count:
        type: "boolean"
        description: "Boolean flag that decides if this comparison type supports comparing\
          \ the column count between tables. Partitioned table comparisons do not\
          \ support comparing the column counts."
      columns:
        type: "array"
        description: "The list of compared columns, their matching reference column\
          \ and the enabled comparisons."
        items:
          $ref: "#/definitions/ColumnComparisonModel"
      compare_table_run_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run the table comparison checks\
          \ for this table, using checks selected in this model."
        $ref: "#/definitions/CheckSearchFilters"
      compare_table_clean_data_job_template:
        description: "Configured parameters for the \"data clean\" job that after\
          \ being supplied with a time range should be pushed to the job queue in\
          \ order to remove stored check results for this table comparison."
        $ref: "#/definitions/DeleteStoredDataQueueJobParameters"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete the table comparison."
      can_run_compare_checks:
        type: "boolean"
        description: "Boolean flag that decides if the current user can run comparison\
          \ checks."
      can_delete_data:
        type: "boolean"
        description: "Boolean flag that decides if the current user can delete data\
          \ (results)."
    description: "Model that contains the all editable information about a table-to-table\
      \ comparison defined on a compared table."
  TableComparisonMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_row_count_match:
        description: "Verifies that the row count of the tested (parent) table matches\
          \ the row count of the reference table. Compares each group of data with\
          \ a GROUP BY clause. Stores the most recent captured value for each month\
          \ when the data quality check was evaluated."
        $ref: "#/definitions/TableComparisonRowCountMatchCheckSpec"
      monthly_column_count_match:
        description: "Verifies that the column count of the tested (parent) table\
          \ matches the column count of the reference table. Only one comparison result\
          \ is returned, without data grouping. Stores the most recent captured value\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/TableComparisonColumnCountMatchCheckSpec"
  TableComparisonMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_row_count_match:
        description: "Verifies that the row count of the tested (parent) table matches\
          \ the row count of the reference table, for each monthly partition (grouping\
          \ rows by the time period, truncated to the month). Compares each group\
          \ of data with a GROUP BY clause. Stores the most recent captured value\
          \ for each monthly partition and optionally data groups."
        $ref: "#/definitions/TableComparisonRowCountMatchCheckSpec"
  TableComparisonProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_row_count_match:
        description: "Verifies that the row count of the tested (parent) table matches\
          \ the row count of the reference table. Compares each group of data with\
          \ a GROUP BY clause."
        $ref: "#/definitions/TableComparisonRowCountMatchCheckSpec"
      profile_column_count_match:
        description: "Verifies that the column count of the tested (parent) table\
          \ matches the column count of the reference table. Only one comparison result\
          \ is returned, without data grouping."
        $ref: "#/definitions/TableComparisonColumnCountMatchCheckSpec"
  TableComparisonResultsModel:
    type: "object"
    properties:
      table_comparison_results:
        type: "object"
        description: "The dictionary of comparison results between the tables for\
          \ table level comparisons (e.g. row count). The keys for the dictionary\
          \ are the check names. The value in the dictionary is a summary information\
          \ about the most recent comparison."
        additionalProperties:
          $ref: "#/definitions/ComparisonCheckResultModel"
      column_comparison_results:
        type: "object"
        description: "The dictionary of comparison results between the tables for\
          \ each compared column. The keys for the dictionary are the column names.\
          \ The values are dictionaries of the data quality check names and their\
          \ results."
        additionalProperties:
          $ref: "#/definitions/TableComparisonColumnResultsModel"
    description: "The table comparison results model with the summary information\
      \ about the most recent table comparison that was performed."
  TableComparisonRowCountMatchCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Row count data quality sensor."
        $ref: "#/definitions/TableVolumeRowCountSensorParametersSpec"
      warning:
        description: "Warning level threshold to raise a data quality incident with\
          \ a warning severity level when the row count in the parent table and the\
          \ reference table do not match. The alert is generated for every compared\
          \ group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule0ParametersSpec"
      error:
        description: "Error level threshold to raise a data quality incident with\
          \ an error severity level when the row count in the parent table and the\
          \ reference table do not match. The alert is generated for every compared\
          \ group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule1ParametersSpec"
      fatal:
        description: "Fatal level threshold to raise a data quality incident with\
          \ a fatal severity level when the row count in the parent table and the\
          \ reference table do not match. The alert is generated for every compared\
          \ group of rows (when data grouping is enabled)."
        $ref: "#/definitions/MaxDiffPercentRule5ParametersSpec"
  TableCurrentDataQualityStatusModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "The connection name in DQOps."
      schema_name:
        type: "string"
        description: "The schema name."
      table_name:
        type: "string"
        description: "The table name."
      current_severity:
        type: "string"
        description: "The most recent data quality issue severity for this table.\
          \ When the table is monitored using data grouping, it is the highest issue\
          \ severity of all recently analyzed data groups. For partitioned checks,\
          \ it is the highest severity of all results for all partitions (time periods)\
          \ in the analyzed time range."
        enum:
        - "valid"
        - "warning"
        - "error"
        - "fatal"
      highest_historical_severity:
        type: "string"
        description: "The highest severity of previous executions of this data quality\
          \ issue in the analyzed time range. It can be different from the *current_severity*\
          \ if the data quality issue was solved and the most recently data quality\
          \ issue did not detect it anymore. For partitioned checks, this field returns\
          \ the same value as the *current_severity*, because data quality issues\
          \ in older partitions are still valid."
        enum:
        - "valid"
        - "warning"
        - "error"
        - "fatal"
      last_check_executed_at:
        type: "integer"
        format: "int64"
        description: "The UTC timestamp when the most recent data quality check was\
          \ executed on the table."
      executed_checks:
        type: "integer"
        format: "int32"
        description: "The total number of most recent checks that were executed on\
          \ the table. Table comparison checks that are comparing groups of data are\
          \ counted as the number of compared data groups."
      valid_results:
        type: "integer"
        format: "int32"
        description: "The number of most recent valid data quality checks that passed\
          \ without raising any issues."
      warnings:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising a warning severity data quality issue."
      errors:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising an error severity data quality issue."
      fatals:
        type: "integer"
        format: "int32"
        description: "The number of most recent data quality checks that failed by\
          \ raising a fatal severity data quality issue."
      execution_errors:
        type: "integer"
        format: "int32"
        description: "The number of data quality check execution errors that were\
          \ reported due to access issues to the data source, invalid mapping in DQOps,\
          \ invalid queries in data quality sensors or invalid python rules. When\
          \ an execution error is reported, the configuration of a data quality check\
          \ on a table must be updated."
      data_quality_kpi:
        type: "number"
        format: "double"
        description: "Data quality KPI score for the table, measured as a percentage\
          \ of passed data quality checks. DQOps counts data quality issues at a warning\
          \ severity level as passed checks. The data quality KPI score is a value\
          \ in the range 0..100."
      checks:
        type: "object"
        description: "The dictionary of statuses for data quality checks. The keys\
          \ are data quality check names, the values are the current data quality\
          \ check statuses that describe the most current status."
        additionalProperties:
          $ref: "#/definitions/CheckCurrentDataQualityStatusModel"
      columns:
        type: "object"
        description: "Dictionary of data statues for all columns that have any known\
          \ data quality results. The keys in the dictionary are the column names."
        additionalProperties:
          $ref: "#/definitions/ColumnCurrentDataQualityStatusModel"
      dimensions:
        type: "object"
        description: "Dictionary of the current data quality statues for each data\
          \ quality dimension."
        additionalProperties:
          $ref: "#/definitions/DimensionCurrentDataQualityStatusModel"
    description: "The table's most recent data quality status. It is a summary of\
      \ the results of the most recently executed data quality checks on the table.\
      \ Verify the value of the highest_severity_level to see if there are any data\
      \ quality issues on the table. The values of severity levels are: 0 - all data\
      \ quality checks passed, 1 - a warning was detected, 2 - an error was detected,\
      \ 3 - a fatal data quality issue was detected."
  TableCustomSqlDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_sql_condition_failed_on_table:
        description: "Verifies that a custom SQL expression is met for each row. Counts\
          \ the number of rows where the expression is not satisfied, and raises an\
          \ issue if too many failures were detected. This check is used also to compare\
          \ values between columns: `{alias}.col_price > {alias}.col_tax`. Stores\
          \ the most recent count of failed rows for each day when the data quality\
          \ check was evaluated."
        $ref: "#/definitions/TableSqlConditionFailedCheckSpec"
      daily_sql_condition_passed_percent_on_table:
        description: "Verifies that a minimum percentage of rows passed a custom SQL\
          \ condition (expression). Reference the current table by using tokens, for\
          \ example: `{alias}.col_price > {alias}.col_tax`. Stores the most recent\
          \ captured percentage for each day when the data quality check was evaluated."
        $ref: "#/definitions/TableSqlConditionPassedPercentCheckSpec"
      daily_sql_aggregate_expression_on_table:
        description: "Verifies that a custom aggregated SQL expression (MIN, MAX,\
          \ etc.) is not outside the expected range. Stores the most recent captured\
          \ value for each day when the data quality check was evaluated."
        $ref: "#/definitions/TableSqlAggregateExpressionCheckSpec"
      daily_import_custom_result_on_table:
        description: "Runs a custom query that retrieves a result of a data quality\
          \ check performed in the data engineering, whose result (the severity level)\
          \ is pulled from a separate table."
        $ref: "#/definitions/TableSqlImportCustomResultCheckSpec"
  TableCustomSqlDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_sql_condition_failed_on_table:
        description: "Verifies that a custom SQL expression is met for each row. Counts\
          \ the number of rows where the expression is not satisfied, and raises an\
          \ issue if too many failures were detected. This check is used also to compare\
          \ values between columns: `{alias}.col_price > {alias}.col_tax`. Stores\
          \ a separate data quality check result for each daily partition."
        $ref: "#/definitions/TableSqlConditionFailedCheckSpec"
      daily_partition_sql_condition_passed_percent_on_table:
        description: "Verifies that a minimum percentage of rows passed a custom SQL\
          \ condition (expression). Reference the current table by using tokens, for\
          \ example: `{alias}.col_price > {alias}.col_tax`. Stores a separate data\
          \ quality check result for each daily partition."
        $ref: "#/definitions/TableSqlConditionPassedPercentCheckSpec"
      daily_partition_sql_aggregate_expression_on_table:
        description: "Verifies that a custom aggregated SQL expression (MIN, MAX,\
          \ etc.) is not outside the expected range. Stores a separate data quality\
          \ check result for each daily partition."
        $ref: "#/definitions/TableSqlAggregateExpressionCheckSpec"
      daily_partition_import_custom_result_on_table:
        description: "Runs a custom query that retrieves a result of a data quality\
          \ check performed in the data engineering, whose result (the severity level)\
          \ is pulled from a separate table."
        $ref: "#/definitions/TableSqlImportCustomResultCheckSpec"
  TableCustomSqlMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_sql_condition_failed_on_table:
        description: "Verifies that a custom SQL expression is met for each row. Counts\
          \ the number of rows where the expression is not satisfied, and raises an\
          \ issue if too many failures were detected. This check is used also to compare\
          \ values between columns: `{alias}.col_price > {alias}.col_tax`. Stores\
          \ the most recent count of failed rows for each month when the data quality\
          \ check was evaluated."
        $ref: "#/definitions/TableSqlConditionFailedCheckSpec"
      monthly_sql_condition_passed_percent_on_table:
        description: "Verifies that a minimum percentage of rows passed a custom SQL\
          \ condition (expression). Reference the current table by using tokens, for\
          \ example: `{alias}.col_price > {alias}.col_tax`. Stores the most recent\
          \ value for each month when the data quality check was evaluated."
        $ref: "#/definitions/TableSqlConditionPassedPercentCheckSpec"
      monthly_sql_aggregate_expression_on_table:
        description: "Verifies that a custom aggregated SQL expression (MIN, MAX,\
          \ etc.) is not outside the expected range. Stores the most recent value\
          \ for each month when the data quality check was evaluated."
        $ref: "#/definitions/TableSqlAggregateExpressionCheckSpec"
      monthly_import_custom_result_on_table:
        description: "Runs a custom query that retrieves a result of a data quality\
          \ check performed in the data engineering, whose result (the severity level)\
          \ is pulled from a separate table."
        $ref: "#/definitions/TableSqlImportCustomResultCheckSpec"
  TableCustomSqlMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_sql_condition_failed_on_table:
        description: "Verifies that a custom SQL expression is met for each row. Counts\
          \ the number of rows where the expression is not satisfied, and raises an\
          \ issue if too many failures were detected. This check is used also to compare\
          \ values between columns: `{alias}.col_price > {alias}.col_tax`. Stores\
          \ a separate data quality check result for each monthly partition."
        $ref: "#/definitions/TableSqlConditionFailedCheckSpec"
      monthly_partition_sql_condition_passed_percent_on_table:
        description: "Verifies that a minimum percentage of rows passed a custom SQL\
          \ condition (expression). Reference the current table by using tokens, for\
          \ example: `{alias}.col_price > {alias}.col_tax`. Stores a separate data\
          \ quality check result for each monthly partition."
        $ref: "#/definitions/TableSqlConditionPassedPercentCheckSpec"
      monthly_partition_sql_aggregate_expression_on_table:
        description: "Verifies that a custom aggregated SQL expression (MIN, MAX,\
          \ etc.) is not outside the expected range. Stores a separate data quality\
          \ check result for each monthly partition."
        $ref: "#/definitions/TableSqlAggregateExpressionCheckSpec"
      monthly_partition_import_custom_result_on_table:
        description: "Runs a custom query that retrieves a result of a data quality\
          \ check performed in the data engineering, whose result (the severity level)\
          \ is pulled from a separate table."
        $ref: "#/definitions/TableSqlImportCustomResultCheckSpec"
  TableCustomSqlProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_sql_condition_failed_on_table:
        description: "Verifies that a minimum percentage of rows passed a custom SQL\
          \ condition (expression). Reference the current table by using tokens, for\
          \ example: `{alias}.col_price > {alias}.col_tax`."
        $ref: "#/definitions/TableSqlConditionFailedCheckSpec"
      profile_sql_condition_passed_percent_on_table:
        description: "Verifies that a custom SQL expression is met for each row. Counts\
          \ the number of rows where the expression is not satisfied, and raises an\
          \ issue if too many failures were detected. This check is used also to compare\
          \ values between columns: `{alias}.col_price > {alias}.col_tax`."
        $ref: "#/definitions/TableSqlConditionPassedPercentCheckSpec"
      profile_sql_aggregate_expression_on_table:
        description: "Verifies that a custom aggregated SQL expression (MIN, MAX,\
          \ etc.) is not outside the expected range."
        $ref: "#/definitions/TableSqlAggregateExpressionCheckSpec"
      profile_import_custom_result_on_table:
        description: "Runs a custom query that retrieves a result of a data quality\
          \ check performed in the data engineering, whose result (the severity level)\
          \ is pulled from a separate table."
        $ref: "#/definitions/TableSqlImportCustomResultCheckSpec"
  TableDailyMonitoringCheckCategoriesSpec:
    type: "object"
    properties:
      custom:
        type: "object"
        description: "Dictionary of custom checks. The keys are check names within\
          \ this category."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      volume:
        description: "Daily monitoring volume data quality checks"
        $ref: "#/definitions/TableVolumeDailyMonitoringChecksSpec"
      timeliness:
        description: "Daily monitoring timeliness checks"
        $ref: "#/definitions/TableTimelinessDailyMonitoringChecksSpec"
      accuracy:
        description: "Daily monitoring accuracy checks"
        $ref: "#/definitions/TableAccuracyDailyMonitoringChecksSpec"
      custom_sql:
        description: "Daily monitoring custom SQL checks"
        $ref: "#/definitions/TableCustomSqlDailyMonitoringChecksSpec"
      availability:
        description: "Daily monitoring table availability checks"
        $ref: "#/definitions/TableAvailabilityDailyMonitoringChecksSpec"
      schema:
        description: "Daily monitoring table schema checks"
        $ref: "#/definitions/TableSchemaDailyMonitoringChecksSpec"
      comparisons:
        type: "object"
        description: "Dictionary of configuration of checks for table comparisons.\
          \ The key that identifies each comparison must match the name of a data\
          \ comparison that is configured on the parent table."
        additionalProperties:
          $ref: "#/definitions/TableComparisonDailyMonitoringChecksSpec"
  TableDailyPartitionedCheckCategoriesSpec:
    type: "object"
    properties:
      custom:
        type: "object"
        description: "Dictionary of custom checks. The keys are check names within\
          \ this category."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      volume:
        description: "Volume daily partitioned data quality checks that verify the\
          \ quality of every day of data separately"
        $ref: "#/definitions/TableVolumeDailyPartitionedChecksSpec"
      timeliness:
        description: "Daily partitioned timeliness checks"
        $ref: "#/definitions/TableTimelinessDailyPartitionedChecksSpec"
      custom_sql:
        description: "Custom SQL daily partitioned data quality checks that verify\
          \ the quality of every day of data separately"
        $ref: "#/definitions/TableCustomSqlDailyPartitionedChecksSpec"
      comparisons:
        type: "object"
        description: "Dictionary of configuration of checks for table comparisons.\
          \ The key that identifies each comparison must match the name of a data\
          \ comparison that is configured on the parent table."
        additionalProperties:
          $ref: "#/definitions/TableComparisonDailyPartitionedChecksSpec"
  TableDataFreshnessCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Max days since most recent event sensor parameters"
        $ref: "#/definitions/TableTimelinessDataFreshnessSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxDaysRule1ParametersSpec"
      error:
        description: "Default alerting threshold for max days since most recent event\
          \ that raises a data quality error (alert)"
        $ref: "#/definitions/MaxDaysRule2ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxDaysRule7ParametersSpec"
  TableDataIngestionDelayCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Max number of days between event and ingestion sensor parameters"
        $ref: "#/definitions/TableTimelinessDataIngestionDelaySensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxDaysRule1ParametersSpec"
      error:
        description: "Default alerting threshold for a max number of days between\
          \ event and ingestion check that raises a data quality error (alert)"
        $ref: "#/definitions/MaxDaysRule2ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxDaysRule7ParametersSpec"
  TableDataStalenessCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Min number of days between event and ingestion sensor parameters"
        $ref: "#/definitions/TableTimelinessDataStalenessSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxDaysRule1ParametersSpec"
      error:
        description: "Default alerting threshold for a min number of days between\
          \ event and ingestion check that raises a data quality error (alert)"
        $ref: "#/definitions/MaxDaysRule2ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxDaysRule7ParametersSpec"
  TableDefaultChecksPatternSpec:
    type: "object"
    properties:
      priority:
        type: "integer"
        format: "int32"
        description: "The priority of the pattern. Patterns with lower values are\
          \ applied before patterns with higher priority values."
      disabled:
        type: "boolean"
        description: "Disables this data quality check configuration. The checks will\
          \ not be activated."
      description:
        type: "string"
        description: "The description (documentation) of this data quality check configuration."
      target:
        description: "The target table filter that are filtering the table and connection\
          \ on which the default checks are applied."
        $ref: "#/definitions/TargetTablePatternSpec"
      profiling_checks:
        description: "Configuration of data quality profiling checks that are enabled.\
          \ Pick a check from a category, apply the parameters and rules to enable\
          \ it."
        $ref: "#/definitions/TableProfilingCheckCategoriesSpec"
      monitoring_checks:
        description: "Configuration of table level monitoring checks. Monitoring checks\
          \ are data quality checks that are evaluated for each period of time (daily,\
          \ weekly, monthly, etc.). A monitoring check stores only the most recent\
          \ data quality check result for each period of time."
        $ref: "#/definitions/TableMonitoringCheckCategoriesSpec"
      partitioned_checks:
        description: "Configuration of table level date/time partitioned checks. Partitioned\
          \ data quality checks are evaluated for each partition separately, raising\
          \ separate alerts at a partition level. The table does not need to be physically\
          \ partitioned by date, it is possible to run data quality checks for each\
          \ day or month of data separately."
        $ref: "#/definitions/TablePartitionedCheckCategoriesSpec"
  TableIncidentGroupingSpec:
    type: "object"
    properties:
      grouping_level:
        type: "string"
        description: "Grouping level of failed data quality checks for creating higher\
          \ level data quality incidents. The default grouping level is by a table,\
          \ a data quality dimension and a check category (i.e. a datatype data quality\
          \ incident detected on a table X in the numeric checks category)."
        enum:
        - "table"
        - "table_dimension"
        - "table_dimension_category"
        - "table_dimension_category_type"
        - "table_dimension_category_name"
      minimum_severity:
        type: "string"
        description: "Minimum severity level of data quality issues that are grouped\
          \ into incidents. The default minimum severity level is 'warning'. Other\
          \ supported severity levels are 'error' and 'fatal'."
        enum:
        - "warning"
        - "error"
        - "fatal"
      divide_by_data_group:
        type: "boolean"
        description: "Create separate data quality incidents for each data group,\
          \ creating different incidents for different groups of rows. By default,\
          \ data groups are ignored for grouping data quality issues into data quality\
          \ incidents."
      disabled:
        type: "boolean"
        description: "Disables data quality incident creation for failed data quality\
          \ checks on the table."
  TableListModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      table_hash:
        type: "integer"
        format: "int64"
        description: "Table hash that identifies the table using a unique hash code."
      target:
        description: "Physical table details (a physical schema name and a physical\
          \ table name)."
        $ref: "#/definitions/PhysicalTableName"
      labels:
        type: "array"
        description: "List of labels applied to the table."
        items:
          type: "string"
      disabled:
        type: "boolean"
        description: "Disables all data quality checks on the table. Data quality\
          \ checks will not be executed."
      stage:
        type: "string"
        description: "Stage name."
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor queries."
      priority:
        type: "integer"
        format: "int32"
        description: "Table priority (1, 2, 3, 4, ...). The tables can be assigned\
          \ a priority level. The table priority is copied into each data quality\
          \ check result and a sensor result, enabling efficient grouping of more\
          \ and less important tables during a data quality improvement project, when\
          \ the data quality issues on higher priority tables are fixed before data\
          \ quality issues on less important tables."
      owner:
        description: "Table owner information like the data steward name or the business\
          \ application name."
        $ref: "#/definitions/TableOwnerSpec"
      profiling_checks_result_truncation:
        type: "string"
        description: "Defines how many profiling checks results are stored for the\
          \ table monthly. By default, DQOps will use the 'one_per_month' configuration\
          \ and store only the most recent profiling checks result executed during\
          \ the month. By changing this value, it is possible to store one value per\
          \ day or even store all profiling checks results."
        enum:
        - "store_the_most_recent_result_per_month"
        - "store_the_most_recent_result_per_week"
        - "store_the_most_recent_result_per_day"
        - "store_the_most_recent_result_per_hour"
        - "store_all_results_without_date_truncation"
      file_format:
        description: "File format for a file based table, such as a CSV or Parquet\
          \ file."
        $ref: "#/definitions/FileFormatSpec"
      data_quality_status:
        description: "The current data quality status for the table, grouped by data\
          \ quality dimensions. DQOps may return a null value when the results were\
          \ not yet loaded into the cache. In that case, the client should wait a\
          \ few seconds and retry a call to get the most recent data quality status\
          \ of the table."
        $ref: "#/definitions/TableCurrentDataQualityStatusModel"
      has_any_configured_checks:
        type: "boolean"
        description: "True when the table has any checks configured."
      has_any_configured_profiling_checks:
        type: "boolean"
        description: "True when the table has any profiling checks configured."
      has_any_configured_monitoring_checks:
        type: "boolean"
        description: "True when the table has any monitoring checks configured."
      has_any_configured_partition_checks:
        type: "boolean"
        description: "True when the table has any partition checks configured."
      partitioning_configuration_missing:
        type: "boolean"
        description: "True when the table has missing configuration of the \"partition_by_column\"\
          \ column, making any partition checks fail when executed."
      run_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run all checks within this table."
        $ref: "#/definitions/CheckSearchFilters"
      run_profiling_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run profiling checks within this\
          \ table."
        $ref: "#/definitions/CheckSearchFilters"
      run_monitoring_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run monitoring checks within this\
          \ table."
        $ref: "#/definitions/CheckSearchFilters"
      run_partition_checks_job_template:
        description: "Configured parameters for the \"check run\" job that should\
          \ be pushed to the job queue in order to run partition partitioned checks\
          \ within this table."
        $ref: "#/definitions/CheckSearchFilters"
      collect_statistics_job_template:
        description: "Configured parameters for the \"collect statistics\" job that\
          \ should be pushed to the job queue in order to run all statistics collectors\
          \ within this table."
        $ref: "#/definitions/StatisticsCollectorSearchFilters"
      data_clean_job_template:
        description: "Configured parameters for the \"data clean\" job that after\
          \ being supplied with a time range should be pushed to the job queue in\
          \ order to remove stored results connected with this table."
        $ref: "#/definitions/DeleteStoredDataQueueJobParameters"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      can_collect_statistics:
        type: "boolean"
        description: "Boolean flag that decides if the current user can collect statistics."
      can_run_checks:
        type: "boolean"
        description: "Boolean flag that decides if the current user can run checks."
      can_delete_data:
        type: "boolean"
        description: "Boolean flag that decides if the current user can delete data\
          \ (results)."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Table list model with a subset of parameters, excluding all nested\
      \ objects."
  TableModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      table_hash:
        type: "integer"
        format: "int64"
        description: "Table hash that identifies the table using a unique hash code."
      spec:
        description: "Full table specification including all nested information, the\
          \ table name is inside the 'target' property."
        $ref: "#/definitions/TableSpec"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
      yaml_parsing_error:
        type: "string"
        description: "Optional parsing error that was captured when parsing the YAML\
          \ file. This field is null when the YAML file is valid. If an error was\
          \ captured, this field returns the file parsing error message and the file\
          \ location."
    description: "Full table model, including all nested objects like columns or checks."
  TableMonitoringCheckCategoriesSpec:
    type: "object"
    properties:
      daily:
        description: "Configuration of daily monitoring evaluated at a table level."
        $ref: "#/definitions/TableDailyMonitoringCheckCategoriesSpec"
      monthly:
        description: "Configuration of monthly monitoring evaluated at a table level."
        $ref: "#/definitions/TableMonthlyMonitoringCheckCategoriesSpec"
  TableMonthlyMonitoringCheckCategoriesSpec:
    type: "object"
    properties:
      custom:
        type: "object"
        description: "Dictionary of custom checks. The keys are check names within\
          \ this category."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      volume:
        description: "Monthly monitoring of volume data quality checks"
        $ref: "#/definitions/TableVolumeMonthlyMonitoringChecksSpec"
      timeliness:
        description: "Monthly monitoring of timeliness checks"
        $ref: "#/definitions/TableTimelinessMonthlyMonitoringChecksSpec"
      accuracy:
        description: "Monthly monitoring accuracy checks"
        $ref: "#/definitions/TableAccuracyMonthlyMonitoringChecksSpec"
      custom_sql:
        description: "Monthly monitoring of custom SQL checks"
        $ref: "#/definitions/TableCustomSqlMonthlyMonitoringChecksSpec"
      availability:
        description: "Daily partitioned availability checks"
        $ref: "#/definitions/TableAvailabilityMonthlyMonitoringChecksSpec"
      schema:
        description: "Monthly monitoring table schema checks"
        $ref: "#/definitions/TableSchemaMonthlyMonitoringChecksSpec"
      comparisons:
        type: "object"
        description: "Dictionary of configuration of checks for table comparisons.\
          \ The key that identifies each comparison must match the name of a data\
          \ comparison that is configured on the parent table."
        additionalProperties:
          $ref: "#/definitions/TableComparisonMonthlyMonitoringChecksSpec"
  TableMonthlyPartitionedCheckCategoriesSpec:
    type: "object"
    properties:
      custom:
        type: "object"
        description: "Dictionary of custom checks. The keys are check names within\
          \ this category."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      volume:
        description: "Volume monthly partitioned data quality checks that verify the\
          \ quality of every month of data separately"
        $ref: "#/definitions/TableVolumeMonthlyPartitionedChecksSpec"
      timeliness:
        description: "Monthly partitioned timeliness checks"
        $ref: "#/definitions/TableTimelinessMonthlyPartitionedChecksSpec"
      custom_sql:
        description: "Custom SQL monthly partitioned data quality checks that verify\
          \ the quality of every month of data separately"
        $ref: "#/definitions/TableCustomSqlMonthlyPartitionedChecksSpec"
      comparisons:
        type: "object"
        description: "Dictionary of configuration of checks for table comparisons.\
          \ The key that identifies each comparison must match the name of a data\
          \ comparison that is configured on the parent table."
        additionalProperties:
          $ref: "#/definitions/TableComparisonMonthlyPartitionedChecksSpec"
  TableOwnerSpec:
    type: "object"
    properties:
      data_steward:
        type: "string"
        description: "Data steward name"
      application:
        type: "string"
        description: "Business application name"
  TablePartitionReloadLagCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Partition reload lag sensor parameters"
        $ref: "#/definitions/TableTimelinessPartitionReloadLagSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MaxDaysRule1ParametersSpec"
      error:
        description: "Default alerting threshold for partition reload lag that raises\
          \ a data quality error (alert)"
        $ref: "#/definitions/MaxDaysRule2ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MaxDaysRule7ParametersSpec"
  TablePartitionedCheckCategoriesSpec:
    type: "object"
    properties:
      daily:
        description: "Configuration of day partitioned data quality checks evaluated\
          \ at a table level."
        $ref: "#/definitions/TableDailyPartitionedCheckCategoriesSpec"
      monthly:
        description: "Configuration of monthly partitioned data quality checks evaluated\
          \ at a table level.."
        $ref: "#/definitions/TableMonthlyPartitionedCheckCategoriesSpec"
  TablePartitioningModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      target:
        description: "Physical table details (a physical schema name and a physical\
          \ table name)"
        $ref: "#/definitions/PhysicalTableName"
      timestamp_columns:
        description: "Column names that store the timestamps that identify the event\
          \ (transaction) timestamp and the ingestion (inserted / loaded at) timestamps.\
          \ Also configures the timestamp source for the date/time partitioned data\
          \ quality checks (event timestamp or ingestion timestamp)."
        $ref: "#/definitions/TimestampColumnsSpec"
      incremental_time_window:
        description: "Configuration of time windows for executing partition checks\
          \ incrementally, configures the number of recent days to analyze for daily\
          \ partitioned tables or the number of recent months for monthly partitioned\
          \ data."
        $ref: "#/definitions/PartitionIncrementalTimeWindowSpec"
      can_edit:
        type: "boolean"
        description: "Boolean flag that decides if the current user can update or\
          \ delete this object."
    description: "Table model with objects that describe the table partitioning."
  TableProfilingCheckCategoriesSpec:
    type: "object"
    properties:
      custom:
        type: "object"
        description: "Dictionary of custom checks. The keys are check names within\
          \ this category."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      result_truncation:
        type: "string"
        description: "Defines how many profiling checks results are stored for the\
          \ table monthly. By default, DQOps will use the 'one_per_month' configuration\
          \ and store only the most recent profiling checks result executed during\
          \ the month. By changing this value, it is possible to store one value per\
          \ day or even store all profiling checks results."
        enum:
        - "store_the_most_recent_result_per_month"
        - "store_the_most_recent_result_per_week"
        - "store_the_most_recent_result_per_day"
        - "store_the_most_recent_result_per_hour"
        - "store_all_results_without_date_truncation"
      volume:
        description: "Configuration of volume data quality checks on a table level."
        $ref: "#/definitions/TableVolumeProfilingChecksSpec"
      timeliness:
        description: "Configuration of timeliness checks on a table level. Timeliness\
          \ checks detect anomalies like rapid row count changes."
        $ref: "#/definitions/TableTimelinessProfilingChecksSpec"
      accuracy:
        description: "Configuration of accuracy checks on a table level. Accuracy\
          \ checks compare the tested table with another reference table."
        $ref: "#/definitions/TableAccuracyProfilingChecksSpec"
      custom_sql:
        description: "Configuration of data quality checks that are evaluating custom\
          \ SQL conditions and aggregated expressions."
        $ref: "#/definitions/TableCustomSqlProfilingChecksSpec"
      availability:
        description: "Configuration of the table availability data quality checks\
          \ on a table level."
        $ref: "#/definitions/TableAvailabilityProfilingChecksSpec"
      schema:
        description: "Configuration of schema (column count and schema) data quality\
          \ checks on a table level."
        $ref: "#/definitions/TableSchemaProfilingChecksSpec"
      comparisons:
        type: "object"
        description: "Dictionary of configuration of checks for table comparisons.\
          \ The key that identifies each comparison must match the name of a data\
          \ comparison that is configured on the parent table."
        additionalProperties:
          $ref: "#/definitions/TableComparisonProfilingChecksSpec"
  TableRowCountAnomalyDifferencingCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/TableVolumeRowCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyDifferencingPercentileMovingAverageRuleFatal01PctParametersSpec"
  TableRowCountAnomalyStationaryPartitionCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/TableVolumeRowCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleWarning1PctParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleError05PctParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/AnomalyStationaryPercentileMovingAverageRuleFatal01PctParametersSpec"
  TableRowCountChange1DayCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/TableVolumeRowCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent1DayRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent1DayRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent1DayRule50ParametersSpec"
  TableRowCountChange30DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/TableVolumeRowCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent30DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent30DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent30DaysRule50ParametersSpec"
  TableRowCountChange7DaysCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/TableVolumeRowCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercent7DaysRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercent7DaysRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercent7DaysRule50ParametersSpec"
  TableRowCountChangeCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Data quality check parameters"
        $ref: "#/definitions/TableVolumeRowCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ChangePercentRule10ParametersSpec"
      error:
        description: "Default alerting threshold for a set number of rows with negative\
          \ value in a column that raises a data quality alert"
        $ref: "#/definitions/ChangePercentRule20ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ChangePercentRule50ParametersSpec"
  TableRowCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Row count sensor parameters"
        $ref: "#/definitions/TableVolumeRowCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/MinCountRule1ParametersSpec"
      error:
        description: "Default alerting threshold that raises a data quality issue\
          \ at an error severity level"
        $ref: "#/definitions/MinCountRule1ParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/MinCountRule1ParametersSpec"
  TableSchemaColumnCountChangedCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Column count sensor parameters"
        $ref: "#/definitions/TableColumnCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      error:
        description: "Default alerting thresholdthat raises a data quality issue at\
          \ an error severity level"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
  TableSchemaColumnCountCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Column count sensor parameters"
        $ref: "#/definitions/TableColumnCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/EqualsIntegerRuleParametersSpec"
      error:
        description: "Default alerting thresholdthat raises a data quality issue at\
          \ an error severity level"
        $ref: "#/definitions/EqualsIntegerRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/EqualsIntegerRuleParametersSpec"
  TableSchemaColumnCountStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/TableColumnCountSensorParametersSpec"
  TableSchemaColumnListChangedCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Column list hash sensor parameters"
        $ref: "#/definitions/TableColumnListUnorderedHashSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      error:
        description: "Default alerting thresholdthat raises a data quality issue at\
          \ an error severity level"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
  TableSchemaColumnListOrOrderChangedCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Column list and order sensor parameters"
        $ref: "#/definitions/TableColumnListOrderedHashSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      error:
        description: "Default alerting thresholdthat raises a data quality issue at\
          \ an error severity level"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
  TableSchemaColumnTypesChangedCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Column list and types sensor parameters"
        $ref: "#/definitions/TableColumnTypesHashSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning that is\
          \ considered as a passed data quality check"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      error:
        description: "Default alerting thresholdthat raises a data quality issue at\
          \ an error severity level"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue which\
          \ indicates a serious data quality problem"
        $ref: "#/definitions/ValueChangedRuleParametersSpec"
  TableSchemaDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_column_count:
        description: "Detects if the number of column matches an expected number.\
          \ Retrieves the metadata of the monitored table, counts the number of columns\
          \ and compares it to an expected value (an expected number of columns).\
          \ Stores the most recent column count for each day when the data quality\
          \ check was evaluated."
        $ref: "#/definitions/TableSchemaColumnCountCheckSpec"
      daily_column_count_changed:
        description: "Detects if the count of columns has changed since the most recent\
          \ day. Retrieves the metadata of the monitored table, counts the number\
          \ of columns and compares it the last known column count that was captured\
          \ when this data quality check was executed the last time. Stores the most\
          \ recent column count for each day when the data quality check was evaluated."
        $ref: "#/definitions/TableSchemaColumnCountChangedCheckSpec"
      daily_column_list_changed:
        description: "Detects if new columns were added or existing columns were removed\
          \ since the most recent day. Retrieves the metadata of the monitored table\
          \ and calculates an unordered hash of the column names. Compares the current\
          \ hash to the previously known hash to detect any changes to the list of\
          \ columns."
        $ref: "#/definitions/TableSchemaColumnListChangedCheckSpec"
      daily_column_list_or_order_changed:
        description: "Detects if new columns were added, existing columns were removed\
          \ or the columns were reordered since the most recent day. Retrieves the\
          \ metadata of the monitored table and calculates an ordered hash of the\
          \ column names. Compares the current hash to the previously known hash to\
          \ detect any changes to the list of columns or their order."
        $ref: "#/definitions/TableSchemaColumnListOrOrderChangedCheckSpec"
      daily_column_types_changed:
        description: "Detects if new columns were added, removed or their data types\
          \ have changed since the most recent day. Retrieves the metadata of the\
          \ monitored table and calculates an unordered hash of the column names and\
          \ the data types (including the length, scale, precision, nullability).\
          \ Compares the current hash to the previously known hash to detect any changes\
          \ to the list of columns or their types."
        $ref: "#/definitions/TableSchemaColumnTypesChangedCheckSpec"
  TableSchemaMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_column_count:
        description: "Detects if the number of column matches an expected number.\
          \ Retrieves the metadata of the monitored table, counts the number of columns\
          \ and compares it to an expected value (an expected number of columns).\
          \ Stores the most recent column count for each month when the data quality\
          \ check was evaluated."
        $ref: "#/definitions/TableSchemaColumnCountCheckSpec"
      monthly_column_count_changed:
        description: "Detects if the count of columns has changed since the last month.\
          \ Retrieves the metadata of the monitored table, counts the number of columns\
          \ and compares it the last known column count that was captured when this\
          \ data quality check was executed the last time. Stores the most recent\
          \ column count for each month when the data quality check was evaluated."
        $ref: "#/definitions/TableSchemaColumnCountChangedCheckSpec"
      monthly_column_list_changed:
        description: "Detects if new columns were added or existing columns were removed\
          \ since the last month. Retrieves the metadata of the monitored table and\
          \ calculates an unordered hash of the column names. Compares the current\
          \ hash to the previously known hash to detect any changes to the list of\
          \ columns."
        $ref: "#/definitions/TableSchemaColumnListChangedCheckSpec"
      monthly_column_list_or_order_changed:
        description: "Detects if new columns were added, existing columns were removed\
          \ or the columns were reordered since the last month. Retrieves the metadata\
          \ of the monitored table and calculates an ordered hash of the column names.\
          \ Compares the current hash to the previously known hash to detect any changes\
          \ to the list of columns or their order."
        $ref: "#/definitions/TableSchemaColumnListOrOrderChangedCheckSpec"
      monthly_column_types_changed:
        description: "Detects if new columns were added, removed or their data types\
          \ have changed since the last month. Retrieves the metadata of the monitored\
          \ table and calculates an unordered hash of the column names and the data\
          \ types (including the length, scale, precision, nullability). Compares\
          \ the current hash to the previously known hash to detect any changes to\
          \ the list of columns or their types."
        $ref: "#/definitions/TableSchemaColumnTypesChangedCheckSpec"
  TableSchemaProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_column_count:
        description: "Detects if the number of column matches an expected number.\
          \ Retrieves the metadata of the monitored table, counts the number of columns\
          \ and compares it to an expected value (an expected number of columns)."
        $ref: "#/definitions/TableSchemaColumnCountCheckSpec"
      profile_column_count_changed:
        description: "Detects if the count of columns has changed. Retrieves the metadata\
          \ of the monitored table, counts the number of columns and compares it the\
          \ last known column count that was captured when this data quality check\
          \ was executed the last time."
        $ref: "#/definitions/TableSchemaColumnCountChangedCheckSpec"
      profile_column_list_changed:
        description: "Detects if new columns were added or existing columns were removed.\
          \ Retrieves the metadata of the monitored table and calculates an unordered\
          \ hash of the column names. Compares the current hash to the previously\
          \ known hash to detect any changes to the list of columns."
        $ref: "#/definitions/TableSchemaColumnListChangedCheckSpec"
      profile_column_list_or_order_changed:
        description: "Detects if new columns were added, existing columns were removed\
          \ or the columns were reordered. Retrieves the metadata of the monitored\
          \ table and calculates an ordered hash of the column names. Compares the\
          \ current hash to the previously known hash to detect any changes to the\
          \ list of columns or their order."
        $ref: "#/definitions/TableSchemaColumnListOrOrderChangedCheckSpec"
      profile_column_types_changed:
        description: "Detects if new columns were added, removed or their data types\
          \ have changed. Retrieves the metadata of the monitored table and calculates\
          \ an unordered hash of the column names and the data types (including the\
          \ length, scale, precision, nullability). Compares the current hash to the\
          \ previously known hash to detect any changes to the list of columns or\
          \ their types."
        $ref: "#/definitions/TableSchemaColumnTypesChangedCheckSpec"
  TableSchemaStatisticsCollectorsSpec:
    type: "object"
    properties:
      column_count:
        description: "Configuration of the column count profiler."
        $ref: "#/definitions/TableSchemaColumnCountStatisticsCollectorSpec"
  TableSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables all data quality checks on the table. Data quality\
          \ checks will not be executed."
      stage:
        type: "string"
        description: "Stage name."
      priority:
        type: "integer"
        format: "int32"
        description: "Table priority (1, 2, 3, 4, ...). The tables can be assigned\
          \ a priority level. The table priority is copied into each data quality\
          \ check result and a sensor result, enabling efficient grouping of more\
          \ and less important tables during a data quality improvement project, when\
          \ the data quality issues on higher priority tables are fixed before data\
          \ quality issues on less important tables."
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor queries. Use replacement\
          \ tokens {table} to replace the content with the full table name, {alias}\
          \ to replace the content with the table alias of an analyzed table or {column}\
          \ to replace the content with the analyzed column name."
      timestamp_columns:
        description: "Column names that store the timestamps that identify the event\
          \ (transaction) timestamp and the ingestion (inserted / loaded at) timestamps.\
          \ Also configures the timestamp source for the date/time partitioned data\
          \ quality checks (event timestamp or ingestion timestamp)."
        $ref: "#/definitions/TimestampColumnsSpec"
      incremental_time_window:
        description: "Configuration of the time window for analyzing daily or monthly\
          \ partitions. Specifies the number of recent days and recent months that\
          \ are analyzed when the partitioned data quality checks are run in an incremental\
          \ mode (the default mode)."
        $ref: "#/definitions/PartitionIncrementalTimeWindowSpec"
      default_grouping_name:
        type: "string"
        description: "The name of the default data grouping configuration that is\
          \ applied on data quality checks. When a default data grouping is selected,\
          \ all data quality checks run SQL queries with a GROUP BY clause, calculating\
          \ separate data quality checks for each group of data. The data groupings\
          \ are defined in the 'groupings' dictionary (indexed by the data grouping\
          \ name)."
      groupings:
        type: "object"
        description: "Data grouping configurations list. Data grouping configurations\
          \ are configured in two cases: (1) the data in the table should be analyzed\
          \ with a GROUP BY condition, to analyze different datasets using separate\
          \ time series, for example a table contains data from multiple countries\
          \ and there is a 'country' column used for partitioning. (2) a tag is assigned\
          \ to a table (within a data grouping level hierarchy), when the data is\
          \ segmented at a table level (similar tables store the same information,\
          \ but for different countries, etc.)."
        additionalProperties:
          $ref: "#/definitions/DataGroupingConfigurationSpec"
      table_comparisons:
        type: "object"
        description: "Dictionary of data comparison configurations. Data comparison\
          \ configurations are used for comparisons between data sources to compare\
          \ this table (called the compared table) with other reference tables (the\
          \ source of truth). The reference table's metadata must be imported into\
          \ DQOps, but the reference table may be located in another data source.\
          \ DQOps will compare metrics calculated for groups of rows (using the GROUP\
          \ BY clause). For each comparison, the user must specify a name of a data\
          \ grouping. The number of data grouping dimensions in the parent table and\
          \ the reference table defined in the selected data grouping configurations\
          \ must match. DQOps will run the same data quality sensors on both the parent\
          \ table (table under test) and the reference table (the source of truth),\
          \ comparing the measures (sensor readouts) captured from both tables."
        additionalProperties:
          $ref: "#/definitions/TableComparisonConfigurationSpec"
      incident_grouping:
        description: "Incident grouping configuration with the overridden configuration\
          \ at a table level. The configured field value in this object will override\
          \ the default configuration from the connection level. Incident grouping\
          \ level can be changed or incident creation can be disabled."
        $ref: "#/definitions/TableIncidentGroupingSpec"
      owner:
        description: "Table owner information like the data steward name or the business\
          \ application name."
        $ref: "#/definitions/TableOwnerSpec"
      profiling_checks:
        description: "Configuration of data quality profiling checks that are enabled.\
          \ Pick a check from a category, apply the parameters and rules to enable\
          \ it."
        $ref: "#/definitions/TableProfilingCheckCategoriesSpec"
      monitoring_checks:
        description: "Configuration of table level monitoring checks. Monitoring checks\
          \ are data quality checks that are evaluated for each period of time (daily,\
          \ weekly, monthly, etc.). A monitoring check stores only the most recent\
          \ data quality check result for each period of time."
        $ref: "#/definitions/TableMonitoringCheckCategoriesSpec"
      partitioned_checks:
        description: "Configuration of table level date/time partitioned checks. Partitioned\
          \ data quality checks are evaluated for each partition separately, raising\
          \ separate alerts at a partition level. The table does not need to be physically\
          \ partitioned by date, it is possible to run data quality checks for each\
          \ day or month of data separately."
        $ref: "#/definitions/TablePartitionedCheckCategoriesSpec"
      statistics:
        description: "Configuration of table level data statistics collector (a basic\
          \ profiler). Configures which statistics collectors are enabled and how\
          \ they are configured."
        $ref: "#/definitions/TableStatisticsCollectorsRootCategoriesSpec"
      schedules_override:
        description: "Configuration of the job scheduler that runs data quality checks.\
          \ The scheduler configuration is divided into types of checks that have\
          \ different schedules."
        $ref: "#/definitions/DefaultSchedulesSpec"
      columns:
        type: "object"
        description: "Dictionary of columns, indexed by a physical column name. Column\
          \ specification contains the expected column data type and a list of column\
          \ level data quality checks that are enabled for a column."
        additionalProperties:
          $ref: "#/definitions/ColumnSpec"
      labels:
        type: "array"
        description: "Custom labels that were assigned to the table. Labels are used\
          \ for searching for tables when filtered data quality checks are executed."
        items:
          type: "string"
      comments:
        type: "array"
        description: "Comments used for change tracking and documenting changes directly\
          \ in the table data quality specification file."
        items:
          $ref: "#/definitions/CommentSpec"
      file_format:
        description: "File format with the specification used as a source data. It\
          \ overrides the connection spec's file format when it is set"
        $ref: "#/definitions/FileFormatSpec"
  TableSqlAggregateExpressionCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sensor parameters with the custom SQL aggregate expression that\
          \ is evaluated on a table. Use an {alias} token to reference the tested\
          \ table."
        $ref: "#/definitions/TableSqlAggregatedExpressionSensorParametersSpec"
      warning:
        description: "Default alerting threshold for warnings raised when the aggregated\
          \ value is above the maximum accepted value."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      error:
        description: "Default alerting threshold for errors raised when the aggregated\
          \ value is above the maximum accepted value."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
      fatal:
        description: "Default alerting threshold for fatal data quality issues raised\
          \ when the aggregated value is above the maximum accepted value."
        $ref: "#/definitions/BetweenFloatsRuleParametersSpec"
  TableSqlAggregatedExpressionSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      sql_expression:
        type: "string"
        description: "SQL aggregate expression that returns a numeric value calculated\
          \ from rows. The expression is evaluated for the entire table or within\
          \ a GROUP BY clause for daily partitions and/or data groups. The expression\
          \ can use a {table} placeholder that is replaced with a full table name."
  TableSqlConditionFailedCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sensor parameters with the custom SQL condition (an expression\
          \ that returns true/false) which is evaluated on a each row."
        $ref: "#/definitions/TableSqlConditionFailedCountSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning when a\
          \ given number of rows failed the custom SQL condition (expression). The\
          \ warning is considered as a passed data quality check."
        $ref: "#/definitions/MaxCountRule0WarningParametersSpec"
      error:
        description: "Default alerting threshold for a maximum number of rows failing\
          \ the custom SQL condition (expression) that raises a data quality error\
          \ (alert)."
        $ref: "#/definitions/MaxCountRule0ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue when\
          \ a given number of rows failed the custom SQL condition (expression). A\
          \ fatal issue indicates a serious data quality problem that should result\
          \ in stopping the data pipelines."
        $ref: "#/definitions/MaxCountRule100ParametersSpec"
  TableSqlConditionFailedCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      sql_condition:
        type: "string"
        description: "SQL condition (expression) that returns true or false. The condition\
          \ is evaluated for each row. The expression can use a {table} placeholder\
          \ that is replaced with a full table name."
  TableSqlConditionPassedPercentCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sensor parameters with the custom SQL condition (an expression\
          \ that returns true/false) which is evaluated on a each row"
        $ref: "#/definitions/TableSqlConditionPassedPercentSensorParametersSpec"
      warning:
        description: "Alerting threshold that raises a data quality warning when a\
          \ minimum acceptable percentage of rows did not pass the custom SQL condition\
          \ (expression). The warning is considered as a passed data quality check."
        $ref: "#/definitions/MinPercentRule100WarningParametersSpec"
      error:
        description: "Default alerting threshold for a minimum acceptable percentage\
          \ of rows passing the custom SQL condition (expression) that raises a data\
          \ quality error (alert)."
        $ref: "#/definitions/MinPercentRule100ErrorParametersSpec"
      fatal:
        description: "Alerting threshold that raises a fatal data quality issue when\
          \ a minimum acceptable percentage of rows did not pass the custom SQL condition\
          \ (expression). A fatal issue indicates a serious data quality problem that\
          \ should result in stopping the data pipelines."
        $ref: "#/definitions/MinPercentRule95ParametersSpec"
  TableSqlConditionPassedPercentSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      sql_condition:
        type: "string"
        description: "SQL condition (expression) that returns true or false. The condition\
          \ is evaluated for each row. The expression can use a {table} placeholder\
          \ that is replaced with a full table name."
  TableSqlImportCustomResultCheckSpec:
    type: "object"
    properties:
      schedule_override:
        description: "Run check scheduling configuration. Specifies the schedule (a\
          \ cron expression) when the data quality checks are executed by the scheduler."
        $ref: "#/definitions/MonitoringScheduleSpec"
      comments:
        type: "array"
        description: "Comments for change tracking. Please put comments in this collection\
          \ because YAML comments may be removed when the YAML file is modified by\
          \ the tool (serialization and deserialization will remove non tracked comments)."
        items:
          $ref: "#/definitions/CommentSpec"
      disabled:
        type: "boolean"
        description: "Disables the data quality check. Only enabled data quality checks\
          \ and monitorings are executed. The check should be disabled if it should\
          \ not work, but the configuration of the sensor and rules should be preserved\
          \ in the configuration."
      exclude_from_kpi:
        type: "boolean"
        description: "Data quality check results (alerts) are included in the data\
          \ quality KPI calculation by default. Set this field to true in order to\
          \ exclude this data quality check from the data quality KPI calculation."
      include_in_sla:
        type: "boolean"
        description: "Marks the data quality check as part of a data quality SLA (Data\
          \ Contract). The data quality SLA is a set of critical data quality checks\
          \ that must always pass and are considered as a Data Contract for the dataset."
      quality_dimension:
        type: "string"
        description: "Configures a custom data quality dimension name that is different\
          \ than the built-in dimensions (Timeliness, Validity, etc.)."
      display_name:
        type: "string"
        description: "Data quality check display name that can be assigned to the\
          \ check, otherwise the check_display_name stored in the parquet result files\
          \ is the check_name."
      data_grouping:
        type: "string"
        description: "Data grouping configuration name that should be applied to this\
          \ data quality check. The data grouping is used to group the check's result\
          \ by a GROUP BY clause in SQL, evaluating the data quality check for each\
          \ group of rows. Use the name of one of data grouping configurations defined\
          \ on the parent table."
      parameters:
        description: "Sensor parameters with the custom SQL SELECT statement that\
          \ queries a log table to get a result of a custom query that retrieves results\
          \ from other data quality libraries."
        $ref: "#/definitions/TableSqlImportCustomResultSensorParametersSpec"
      warning:
        description: "Warning severity import rule. Activate the rule with no parameters\
          \ to import custom data quality results when the custom query returns a\
          \ value **1** in the *severity* result column."
        $ref: "#/definitions/ImportSeverityRuleParametersSpec"
      error:
        description: "Error severity import rule. Activate the rule with no parameters\
          \ to import custom data quality results when the custom query returns a\
          \ value **2** in the *severity* result column."
        $ref: "#/definitions/ImportSeverityRuleParametersSpec"
      fatal:
        description: "Fatal severity import rule. Activate the rule with no parameters\
          \ to import custom data quality results when the custom query returns a\
          \ value **3** in the *severity* result column."
        $ref: "#/definitions/ImportSeverityRuleParametersSpec"
  TableSqlImportCustomResultSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
      sql_query:
        type: "string"
        description: "A custom SELECT statement that queries a logging table with\
          \ custom results of data quality checks executed by the data pipeline. The\
          \ query must return a result column named *severity*. The values of the\
          \ *severity* column must be: 0 - data quality check passed, 1 - warning\
          \ issue, 2 - error severity issue, 3 - fatal severity issue. The query can\
          \ return *actual_value* and *expected_value* results that are imported into\
          \ DQOps data lake. The query can use a {table_name} placeholder that is\
          \ replaced with a table name for which the results are imported."
  TableStatisticsCollectorsRootCategoriesSpec:
    type: "object"
    properties:
      volume:
        description: "Configuration of volume statistics collectors on a table level."
        $ref: "#/definitions/TableVolumeStatisticsCollectorsSpec"
      schema:
        $ref: "#/definitions/TableSchemaStatisticsCollectorsSpec"
  TableStatisticsModel:
    type: "object"
    properties:
      connection_name:
        type: "string"
        description: "Connection name."
      table:
        description: "Physical table name including the schema and table names."
        $ref: "#/definitions/PhysicalTableName"
      statistics:
        type: "array"
        description: "List of collected table level statistics."
        items:
          $ref: "#/definitions/StatisticsMetricModel"
      collect_table_statistics_job_template:
        description: "Configured parameters for the \"collect statistics\" job that\
          \ should be pushed to the job queue in order to run all statistics collectors\
          \ within this table, limited only to the table level statistics (row count,\
          \ etc)."
        $ref: "#/definitions/StatisticsCollectorSearchFilters"
      collect_table_and_column_statistics_job_template:
        description: "Configured parameters for the \"collect statistics\" job that\
          \ should be pushed to the job queue in order to run all statistics collectors\
          \ within this table, including statistics for all columns."
        $ref: "#/definitions/StatisticsCollectorSearchFilters"
      can_collect_statistics:
        type: "boolean"
        description: "Boolean flag that decides if the current user can collect statistics."
    description: "Model that returns a summary of the table level statistics (the\
      \ basic profiling results)."
  TableTimelinessDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_data_freshness:
        description: "Daily  calculating the number of days since the most recent\
          \ event timestamp (freshness)"
        $ref: "#/definitions/TableDataFreshnessCheckSpec"
      daily_data_staleness:
        description: "Daily  calculating the time difference in days between the current\
          \ date and the most recent data ingestion timestamp (staleness)"
        $ref: "#/definitions/TableDataStalenessCheckSpec"
      daily_data_ingestion_delay:
        description: "Daily  calculating the time difference in days between the most\
          \ recent event timestamp and the most recent ingestion timestamp"
        $ref: "#/definitions/TableDataIngestionDelayCheckSpec"
  TableTimelinessDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_data_ingestion_delay:
        description: "Daily partitioned check calculating the time difference in days\
          \ between the most recent event timestamp and the most recent ingestion\
          \ timestamp"
        $ref: "#/definitions/TableDataIngestionDelayCheckSpec"
      daily_partition_reload_lag:
        description: "Daily partitioned check calculating the longest time a row waited\
          \ to be loaded, it is the maximum difference in days between the ingestion\
          \ timestamp and the event timestamp column on any row in the monitored partition"
        $ref: "#/definitions/TablePartitionReloadLagCheckSpec"
  TableTimelinessDataFreshnessSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  TableTimelinessDataIngestionDelaySensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  TableTimelinessDataStalenessSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  TableTimelinessMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_data_freshness:
        description: "Monthly monitoring calculating the number of days since the\
          \ most recent event timestamp (freshness)"
        $ref: "#/definitions/TableDataFreshnessCheckSpec"
      monthly_data_staleness:
        description: "Monthly monitoring calculating the time difference in days between\
          \ the current date and the most recent data ingestion timestamp (staleness)"
        $ref: "#/definitions/TableDataStalenessCheckSpec"
      monthly_data_ingestion_delay:
        description: "Monthly monitoring calculating the time difference in days between\
          \ the most recent event timestamp and the most recent ingestion timestamp"
        $ref: "#/definitions/TableDataIngestionDelayCheckSpec"
  TableTimelinessMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_data_ingestion_delay:
        description: "Monthly partitioned check calculating the time difference in\
          \ days between the most recent event timestamp and the most recent ingestion\
          \ timestamp"
        $ref: "#/definitions/TableDataIngestionDelayCheckSpec"
      monthly_partition_reload_lag:
        description: "Monthly partitioned check calculating the longest time a row\
          \ waited to be loaded, it is the maximum difference in days between the\
          \ ingestion timestamp and the event timestamp column on any row in the monitored\
          \ partition"
        $ref: "#/definitions/TablePartitionReloadLagCheckSpec"
  TableTimelinessPartitionReloadLagSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  TableTimelinessProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_data_freshness:
        description: "Calculates the number of days since the most recent event timestamp\
          \ (freshness)"
        $ref: "#/definitions/TableDataFreshnessCheckSpec"
      profile_data_staleness:
        description: "Calculates the time difference in days between the current date\
          \ and the most recent data ingestion timestamp (staleness)"
        $ref: "#/definitions/TableDataStalenessCheckSpec"
      profile_data_ingestion_delay:
        description: "Calculates the time difference in days between the most recent\
          \ event timestamp and the most recent ingestion timestamp"
        $ref: "#/definitions/TableDataIngestionDelayCheckSpec"
  TableVolumeDailyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_row_count:
        description: "Verifies that the tested table has at least a minimum accepted\
          \ number of rows. The default configuration of the warning, error and fatal\
          \ severity rules verifies a minimum row count of one row, which ensures\
          \ that the table is not empty. Stores the most recent captured row count\
          \ value for each day when the row count was evaluated."
        $ref: "#/definitions/TableRowCountCheckSpec"
      daily_row_count_anomaly:
        description: "Detects when the row count has changed too much since the previous\
          \ day. It uses time series anomaly detection to find the biggest volume\
          \ changes during the last 90 days."
        $ref: "#/definitions/TableRowCountAnomalyDifferencingCheckSpec"
      daily_row_count_change:
        description: "Detects when the volume's (row count) change since the last\
          \ known row count exceeds the maximum accepted change percentage."
        $ref: "#/definitions/TableRowCountChangeCheckSpec"
      daily_row_count_change_1_day:
        description: "Detects when the volume's change (increase or decrease of the\
          \ row count) since the previous day exceeds the maximum accepted change\
          \ percentage. "
        $ref: "#/definitions/TableRowCountChange1DayCheckSpec"
      daily_row_count_change_7_days:
        description: "This check verifies that the percentage of change in the table's\
          \ volume (row count) since seven days ago is below the maximum accepted\
          \ percentage. Verifying a volume change since a value a week ago overcomes\
          \ the effect of weekly seasonability."
        $ref: "#/definitions/TableRowCountChange7DaysCheckSpec"
      daily_row_count_change_30_days:
        description: "This check verifies that the percentage of change in the table's\
          \ volume (row count) since thirty days ago is below the maximum accepted\
          \ percentage. Comparing the current row count to a value 30 days ago overcomes\
          \ the effect of monthly seasonability."
        $ref: "#/definitions/TableRowCountChange30DaysCheckSpec"
  TableVolumeDailyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      daily_partition_row_count:
        description: "Verifies that each daily partition in the tested table has at\
          \ least a minimum accepted number of rows. The default configuration of\
          \ the warning, error and fatal severity rules verifies a minimum row count\
          \ of one row, which ensures that the partition is not empty."
        $ref: "#/definitions/TableRowCountCheckSpec"
      daily_partition_row_count_anomaly:
        description: "Detects outstanding partitions whose volume (the row count)\
          \ differs too much from the average daily partition size. It uses time series\
          \ anomaly detection to find the outliers in the partition volume during\
          \ the last 90 days."
        $ref: "#/definitions/TableRowCountAnomalyStationaryPartitionCheckSpec"
      daily_partition_row_count_change:
        description: "Detects when the partition's volume (row count) change between\
          \ the current daily partition and the previous partition exceeds the maximum\
          \ accepted change percentage."
        $ref: "#/definitions/TableRowCountChangeCheckSpec"
      daily_partition_row_count_change_1_day:
        description: "Detects when the partition volume change (increase or decrease\
          \ of the row count) since yesterday's daily partition exceeds the maximum\
          \ accepted change percentage. "
        $ref: "#/definitions/TableRowCountChange1DayCheckSpec"
      daily_partition_row_count_change_7_days:
        description: "This check verifies that the percentage of change in the partition's\
          \ volume (row count) since seven days ago is below the maximum accepted\
          \ percentage. Verifying a volume change since a value a week ago overcomes\
          \ the effect of weekly seasonability."
        $ref: "#/definitions/TableRowCountChange7DaysCheckSpec"
      daily_partition_row_count_change_30_days:
        description: "This check verifies that the percentage of change in the partition's\
          \ volume (row count) since thirty days ago is below the maximum accepted\
          \ percentage. Comparing the current row count to a value 30 days ago overcomes\
          \ the effect of monthly seasonability."
        $ref: "#/definitions/TableRowCountChange30DaysCheckSpec"
  TableVolumeMonthlyMonitoringChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_row_count:
        description: "Verifies that the tested table has at least a minimum accepted\
          \ number of rows. The default configuration of the warning, error and fatal\
          \ severity rules verifies a minimum row count of one row, which ensures\
          \ that the table is not empty. Stores the most recent captured row count\
          \ value for each month when the row count was evaluated."
        $ref: "#/definitions/TableRowCountCheckSpec"
      monthly_row_count_change:
        description: "Detects when the volume (row count) changes since the last known\
          \ row count from a previous month exceeds the maximum accepted change percentage."
        $ref: "#/definitions/TableRowCountChangeCheckSpec"
  TableVolumeMonthlyPartitionedChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      monthly_partition_row_count:
        description: "Verifies that each monthly partition in the tested table has\
          \ at least a minimum accepted number of rows. The default configuration\
          \ of the warning, error and fatal severity rules verifies a minimum row\
          \ count of one row, which ensures that the partition is not empty."
        $ref: "#/definitions/TableRowCountCheckSpec"
      monthly_partition_row_count_change:
        description: "Detects when the partition's volume (row count) change between\
          \ the current monthly partition and the previous partition exceeds the maximum\
          \ accepted change percentage."
        $ref: "#/definitions/TableRowCountChangeCheckSpec"
  TableVolumeProfilingChecksSpec:
    type: "object"
    properties:
      custom_checks:
        type: "object"
        description: "Dictionary of additional custom checks within this category.\
          \ The keys are check names defined in the definition section. The sensor\
          \ parameters and rules should match the type of the configured sensor and\
          \ rule for the custom check."
        additionalProperties:
          $ref: "#/definitions/CustomCheckSpec"
      profile_row_count:
        description: "Verifies that the tested table has at least a minimum accepted\
          \ number of rows. The default configuration of the warning, error and fatal\
          \ severity rules verifies a minimum row count of one row, which ensures\
          \ that the table is not empty."
        $ref: "#/definitions/TableRowCountCheckSpec"
      profile_row_count_anomaly:
        description: "Detects when the row count has changed too much since the previous\
          \ day. It uses time series anomaly detection to find the biggest volume\
          \ changes during the last 90 days."
        $ref: "#/definitions/TableRowCountAnomalyDifferencingCheckSpec"
      profile_row_count_change:
        description: "Detects when the volume's (row count) change since the last\
          \ known row count exceeds the maximum accepted change percentage."
        $ref: "#/definitions/TableRowCountChangeCheckSpec"
      profile_row_count_change_1_day:
        description: "Detects when the volume's change (increase or decrease of the\
          \ row count) since the previous day exceeds the maximum accepted change\
          \ percentage."
        $ref: "#/definitions/TableRowCountChange1DayCheckSpec"
      profile_row_count_change_7_days:
        description: "This check verifies that the percentage of change in the table's\
          \ volume (row count) since seven days ago is below the maximum accepted\
          \ percentage. Verifying a volume change since a value a week ago overcomes\
          \ the effect of weekly seasonability. "
        $ref: "#/definitions/TableRowCountChange7DaysCheckSpec"
      profile_row_count_change_30_days:
        description: "This check verifies that the percentage of change in the table's\
          \ volume (row count) since thirty days ago is below the maximum accepted\
          \ percentage. Comparing the current row count to a value 30 days ago overcomes\
          \ the effect of monthly seasonability."
        $ref: "#/definitions/TableRowCountChange30DaysCheckSpec"
  TableVolumeRowCountSensorParametersSpec:
    type: "object"
    properties:
      filter:
        type: "string"
        description: "SQL WHERE clause added to the sensor query. Both the table level\
          \ filter and a sensor query filter are added, separated by an AND operator."
  TableVolumeRowCountStatisticsCollectorSpec:
    type: "object"
    properties:
      disabled:
        type: "boolean"
        description: "Disables this profiler. Only enabled profilers are executed\
          \ during a profiling process."
      parameters:
        description: "Profiler parameters"
        $ref: "#/definitions/TableVolumeRowCountSensorParametersSpec"
  TableVolumeStatisticsCollectorsSpec:
    type: "object"
    properties:
      row_count:
        description: "Configuration of the row count profiler."
        $ref: "#/definitions/TableVolumeRowCountStatisticsCollectorSpec"
  TargetColumnPatternSpec:
    type: "object"
    properties:
      connection:
        type: "string"
        description: "The data source connection name filter. Accepts wildcards in\
          \ the format: *conn, *, conn*."
      schema:
        type: "string"
        description: "The schema name filter. Accepts wildcards in the format: *_prod,\
          \ *, pub*."
      table:
        type: "string"
        description: "The table name filter. Accepts wildcards in the format: *_customers,\
          \ *, fact_*."
      stage:
        type: "string"
        description: "The table stage filter. Accepts wildcards in the format: *_landing,\
          \ *, staging_*."
      table_priority:
        type: "integer"
        format: "int32"
        description: "The maximum table priority (inclusive) for tables that are covered\
          \ by the default checks."
      label:
        type: "string"
        description: "The label filter. Accepts wildcards in the format: *_customers,\
          \ *, fact_*. The label must be present on the connection or table."
      column:
        type: "string"
        description: "The target column name filter. Accepts wildcards in the format:\
          \ *id, *, c_*."
      data_type:
        type: "string"
        description: "The target column data type filter. Filters by a physical (database\
          \ specific) data type name imported from the data source. Accepts wildcards\
          \ in the format: *int, *, big*."
      data_type_category:
        type: "string"
        description: "The filter for a target data type category."
        enum:
        - "numeric_integer"
        - "numeric_decimal"
        - "numeric_float"
        - "datetime_timestamp"
        - "datetime_datetime"
        - "datetime_date"
        - "datetime_time"
        - "text"
        - "clob"
        - "json"
        - "bool"
        - "binary"
        - "array"
        - "other"
  TargetTablePatternSpec:
    type: "object"
    properties:
      connection:
        type: "string"
        description: "The data source connection name filter. Accepts wildcards in\
          \ the format: *conn, *, conn*."
      schema:
        type: "string"
        description: "The schema name filter. Accepts wildcards in the format: *_prod,\
          \ *, pub*."
      table:
        type: "string"
        description: "The table name filter. Accepts wildcards in the format: *_customers,\
          \ *, fact_*."
      stage:
        type: "string"
        description: "The table stage filter. Accepts wildcards in the format: *_landing,\
          \ *, staging_*."
      table_priority:
        type: "integer"
        format: "int32"
        description: "The maximum table priority (inclusive) for tables that are covered\
          \ by the default checks."
      label:
        type: "string"
        description: "The label filter. Accepts wildcards in the format: *_customers,\
          \ *, fact_*. The label must be present on the connection or table."
  TemporalUnit:
    type: "object"
    properties:
      dateBased:
        type: "boolean"
      timeBased:
        type: "boolean"
      duration:
        $ref: "#/definitions/Duration"
      durationEstimated:
        type: "boolean"
  TimeWindowFilterParameters:
    type: "object"
    properties:
      daily_partitioning_recent_days:
        type: "integer"
        format: "int32"
        description: "The number of recent days to analyze incrementally by daily\
          \ partitioned data quality checks."
      daily_partitioning_include_today:
        type: "boolean"
        description: "Analyze also today and later days when running daily partitioned\
          \ checks. By default, daily partitioned checks will not analyze today and\
          \ future dates. Setting true will disable filtering the end dates."
      monthly_partitioning_recent_months:
        type: "integer"
        format: "int32"
        description: "The number of recent months to analyze incrementally by monthly\
          \ partitioned data quality checks."
      monthly_partitioning_include_current_month:
        type: "boolean"
        description: "Analyze also the current month and later months when running\
          \ monthly partitioned checks. By default, monthly partitioned checks will\
          \ not analyze the current month and future months. Setting true will disable\
          \ filtering the end dates."
      from_date:
        type: "string"
        format: "date"
        description: "Analyze the data since the given date (inclusive). The date\
          \ should be an ISO 8601 date (yyyy-MM-dd). The analyzed table must have\
          \ the timestamp column properly configured, it is the column that is used\
          \ for filtering the date and time ranges. Setting the beginning date overrides\
          \ recent days and recent months."
      from_date_time:
        type: "string"
        format: "date-time"
        description: "Analyze the data since the given date and time (inclusive).\
          \ The date and time should be an ISO 8601 local date and time without the\
          \ time zone (yyyy-MM-dd HH:mm:ss). The analyzed table must have the timestamp\
          \ column properly configured, it is the column that is used for filtering\
          \ the date and time ranges. Setting the beginning date and time overrides\
          \ recent days and recent months."
      from_date_time_offset:
        type: "string"
        format: "date-time"
        description: "Analyze the data since the given date and time with a time zone\
          \ offset (inclusive). The date and time should be an ISO 8601 date and time\
          \ followed by a time zone offset (yyyy-MM-dd HH:mm:ss). For example: 2023-02-20\
          \ 14:10:00+02. The analyzed table must have the timestamp column properly\
          \ configured, it is the column that is used for filtering the date and time\
          \ ranges. Setting the beginning date and time overrides recent days and\
          \ recent months."
      to_date:
        type: "string"
        format: "date"
        description: "Analyze the data until the given date (exclusive, the given\
          \ date and the following dates are not analyzed). The date should be an\
          \ ISO 8601 date (YYYY-MM-DD). The analyzed table must have the timestamp\
          \ column properly configured, it is the column that is used for filtering\
          \ the date and time ranges. Setting the end date overrides the parameters\
          \ to disable analyzing today or the current month."
      to_date_time:
        type: "string"
        format: "date-time"
        description: "Analyze the data until the given date and time (exclusive).\
          \ The date should be an ISO 8601 date (yyyy-MM-dd). The analyzed table must\
          \ have the timestamp column properly configured, it is the column that is\
          \ used for filtering the date and time ranges. Setting the end date and\
          \ time overrides the parameters to disable analyzing today or the current\
          \ month."
      to_date_time_offset:
        type: "string"
        format: "date-time"
        description: "Analyze the data until the given date and time with a time zone\
          \ offset (exclusive). The date and time should be an ISO 8601 date and time\
          \ followed by a time zone offset (yyyy-MM-dd HH:mm:ss). For example: 2023-02-20\
          \ 14:10:00+02. The analyzed table must have the timestamp column properly\
          \ configured, it is the column that is used for filtering the date and time\
          \ ranges. Setting the end date and time overrides the parameters to disable\
          \ analyzing today or the current month."
    description: "Time window configuration for partitioned checks (the number of\
      \ recent days or months to analyze in an incremental mode) or an absolute time\
      \ range to analyze."
  TimestampColumnsSpec:
    type: "object"
    properties:
      event_timestamp_column:
        type: "string"
        description: "Column name that identifies an event timestamp (date/time),\
          \ such as a transaction timestamp, impression timestamp, event timestamp."
      ingestion_timestamp_column:
        type: "string"
        description: "Column name that contains the timestamp (or date/time) when\
          \ the row was ingested (loaded, inserted) into the table. Use a column that\
          \ is filled by the data pipeline or ETL process at the time of the data\
          \ loading."
      partition_by_column:
        type: "string"
        description: "Column name that contains the date, datetime or timestamp column\
          \ for date/time partitioned data. Partition checks (daily partition checks\
          \ and monthly partition checks) use this column in a GROUP BY clause in\
          \ order to detect data quality issues in each partition separately. It should\
          \ be a DATE type, DATETIME type (using a local server time zone) or a TIMESTAMP\
          \ type (a UTC absolute time)."
  TrinoParametersSpec:
    type: "object"
    properties:
      trino_engine_type:
        type: "string"
        description: "Trino engine type. Supports also a ${TRINO_ENGINE} configuration\
          \ with a custom environment variable."
        enum:
        - "trino"
        - "athena"
      host:
        type: "string"
        description: "Trino host name. Supports also a ${TRINO_HOST} configuration\
          \ with a custom environment variable."
      port:
        type: "string"
        description: "Trino port number. The default port is 8080. Supports also a\
          \ ${TRINO_PORT} configuration with a custom environment variable."
      user:
        type: "string"
        description: "Trino user name. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      password:
        type: "string"
        description: "Trino database password. The value can be in the ${ENVIRONMENT_VARIABLE_NAME}\
          \ format to use dynamic substitution."
      aws_authentication_mode:
        type: "string"
        description: "The authentication mode for AWS Athena. Supports also a ${ATHENA_AWS_AUTHENTICATION_MODE}\
          \ configuration with a custom environment variable."
        enum:
        - "iam"
        - "default_credentials"
      athena_region:
        type: "string"
        description: "The AWS Region where queries will be run. Supports also a ${ATHENA_REGION}\
          \ configuration with a custom environment variable."
      catalog:
        type: "string"
        description: "The catalog that contains the databases and the tables that\
          \ will be accessed with the driver. Supports also a ${TRINO_CATALOG} configuration\
          \ with a custom environment variable."
      athena_work_group:
        type: "string"
        description: "The workgroup in which queries will run. Supports also a ${ATHENA_WORK_GROUP}\
          \ configuration with a custom environment variable."
      athena_output_location:
        type: "string"
        description: "The location in Amazon S3 where query results will be stored.\
          \ Supports also a ${ATHENA_OUTPUT_LOCATION} configuration with a custom\
          \ environment variable."
      properties:
        type: "object"
        description: "A dictionary of custom JDBC parameters that are added to the\
          \ JDBC connection string, a key/value dictionary."
        additionalProperties:
          type: "string"
      database:
        type: "string"
  ValueChangedRuleParametersSpec:
    type: "object"
